[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Us",
    "section": "",
    "text": "Need more information from everyone…\n\n\nXiaxin Tang\nXiaxin (Joey) concentrates in Smart City of the Master of City Planning program. He conducted the crash and weather analysis in this project.\nJiyan Wang\nJiyan (William) concentrates in the Sustainable Transportation of the Master of City Planning program. He conducted the traffic analysis in this project.\nYuan Ji\nYuan is concentrates in the Urban Design of the Master of City Planning program. His main role is the webpage visualization.\n\n\nYou can find more information on: https://github.com/Xiaxin-Tang/final."
  },
  {
    "objectID": "analysis/4-folium.html",
    "href": "analysis/4-folium.html",
    "title": "Interactive Maps with Folium",
    "section": "",
    "text": "This page is generated from a Jupyter notebook and shows examples of embedding interactive maps produced using Folium."
  },
  {
    "objectID": "analysis/4-folium.html#finding-the-shortest-route",
    "href": "analysis/4-folium.html#finding-the-shortest-route",
    "title": "Interactive Maps with Folium",
    "section": "Finding the shortest route",
    "text": "Finding the shortest route\nThis example finds the shortest route between the Art Musuem and the Liberty Bell using osmnx.\n\nimport osmnx as ox\n\nFirst, identify the lat/lng coordinates for our places of interest. Use osmnx to download the geometries for the Libery Bell and Art Museum.\n\nphilly_tourism = ox.features_from_place(\"Philadelphia, PA\", tags={\"tourism\": True})\n\n\nart_museum = philly_tourism.query(\"name == 'Philadelphia Museum of Art'\").squeeze()\n\nart_museum.geometry\n\n\n\n\n\nliberty_bell = philly_tourism.query(\"name == 'Liberty Bell'\").squeeze()\n\nliberty_bell.geometry\n\n\n\n\nNow, extract the lat and lng coordinates\nFor the Art Museum geometry, we can use the .geometry.centroid attribute to calculate the centroid of the building footprint.\n\nliberty_bell_x = liberty_bell.geometry.x\nliberty_bell_y = liberty_bell.geometry.y\n\n\nart_museum_x = art_museum.geometry.centroid.x\nart_museum_y = art_museum.geometry.centroid.y\n\nNext, use osmnx to download the street graph around Center City.\n\nG_cc = ox.graph_from_address(\n    \"City Hall, Philadelphia, USA\", dist=1500, network_type=\"drive\"\n)\n\nNext, identify the nodes in the graph closest to our points of interest.\n\n# Get the origin node (Liberty Bell)\norig_node = ox.nearest_nodes(G_cc, liberty_bell_x, liberty_bell_y)\n\n# Get the destination node (Art Musuem)\ndest_node = ox.nearest_nodes(G_cc, art_museum_x, art_museum_y)\n\nFind the shortest path, based on the distance of the edges:\n\n# Get the shortest path --&gt; just a list of node IDs\nroute = ox.shortest_path(G_cc, orig_node, dest_node, weight=\"length\")\n\nHow about an interactive version?\nosmnx has a helper function ox.utils_graph.route_to_gdf() to convert a route to a GeoDataFrame of edges.\n\nox.utils_graph.route_to_gdf(G_cc, route, weight=\"length\").explore(\n    tiles=\"cartodb positron\",\n    color=\"red\",\n)\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "analysis/4-folium.html#examining-trash-related-311-requests",
    "href": "analysis/4-folium.html#examining-trash-related-311-requests",
    "title": "Interactive Maps with Folium",
    "section": "Examining Trash-Related 311 Requests",
    "text": "Examining Trash-Related 311 Requests\nFirst, let’s load the dataset from a CSV file and convert to a GeoDataFrame:\n\n\nCode\n# Load the data from a CSV file into a pandas DataFrame\ntrash_requests_df = pd.read_csv(\n    \"https://raw.githubusercontent.com/MUSA-550-Fall-2023/week-4/main/data/trash_311_requests_2020.csv\"\n)\n\n# Remove rows with missing geometry\ntrash_requests_df = trash_requests_df.dropna(subset=[\"lat\", \"lon\"])\n\n\n# Create our GeoDataFrame with geometry column created from lon/lat\ntrash_requests = gpd.GeoDataFrame(\n    trash_requests_df,\n    geometry=gpd.points_from_xy(trash_requests_df[\"lon\"], trash_requests_df[\"lat\"]),\n    crs=\"EPSG:4326\",\n)\n\n\nLoad neighborhoods and do the spatial join to associate a neighborhood with each ticket:\n\n\nCode\n# Load the neighborhoods\nneighborhoods = gpd.read_file(\n    \"https://raw.githubusercontent.com/MUSA-550-Fall-2023/week-4/main/data/zillow_neighborhoods.geojson\"\n)\n\n# Do the spatial join to add the \"ZillowName\" column\nrequests_with_hood = gpd.sjoin(\n    trash_requests,\n    neighborhoods.to_crs(trash_requests.crs),\n    predicate=\"within\",\n)\n\n\nLet’s explore the 311 requests in the Greenwich neighborhood of the city:\n\n# Extract out the point tickets for Greenwich\ngreenwich_tickets = requests_with_hood.query(\"ZillowName == 'Greenwich'\")\n\n\n# Get the neighborhood boundary for Greenwich\ngreenwich_geo = neighborhoods.query(\"ZillowName == 'Greenwich'\")\n\ngreenwich_geo.squeeze().geometry\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuarto has callout blocks that you can use to emphasize content in different ways. This is a “Note” callout block. More info is available on the Quarto documentation.\n\n\nImport the packages we need:\n\nimport folium\nimport xyzservices\n\nCombine the tickets as markers and the neighborhood boundary on the same Folium map:\n\n# Plot the neighborhood boundary\nm = greenwich_geo.explore(\n    style_kwds={\"weight\": 4, \"color\": \"black\", \"fillColor\": \"none\"},\n    name=\"Neighborhood boundary\",\n    tiles=xyzservices.providers.CartoDB.Voyager,\n)\n\n\n# Add the individual tickets as circle markers and style them\ngreenwich_tickets.explore(\n    m=m,  # Add to the existing map!\n    marker_kwds={\"radius\": 7, \"fill\": True, \"color\": \"crimson\"},\n    marker_type=\"circle_marker\", # or 'marker' or 'circle'\n    name=\"Tickets\",\n)\n\n# Hse folium to add layer control\nfolium.LayerControl().add_to(m)\n\nm  # show map\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "analysis/1-python-code-blocks.html",
    "href": "analysis/1-python-code-blocks.html",
    "title": "Python code blocks",
    "section": "",
    "text": "This is an example from the Quarto documentation that shows how to mix executable Python code blocks into a markdown file in a “Quarto markdown” .qmd file.\nFor a demonstration of a line plot on a polar axis, see Figure 1.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\nFigure 1: A line plot on a polar axis"
  },
  {
    "objectID": "analysis/3-altair-hvplot.html",
    "href": "analysis/3-altair-hvplot.html",
    "title": "Altair and Hvplot Charts",
    "section": "",
    "text": "This page is generated from a Jupyter notebook and shows examples of embedding interactive charts produced using Altair and hvPlot."
  },
  {
    "objectID": "analysis/3-altair-hvplot.html#example-measles-incidence-in-altair",
    "href": "analysis/3-altair-hvplot.html#example-measles-incidence-in-altair",
    "title": "Altair and Hvplot Charts",
    "section": "Example: Measles Incidence in Altair",
    "text": "Example: Measles Incidence in Altair\nFirst, let’s load the data for measles incidence in wide format:\n\n\nCode\nurl = \"https://raw.githubusercontent.com/MUSA-550-Fall-2023/week-2/main/data/measles_incidence.csv\"\ndata = pd.read_csv(url, skiprows=2, na_values=\"-\")\n\n\n\n\n\n\n\n\n\n\n\nYEAR\nWEEK\nALABAMA\nALASKA\nARIZONA\nARKANSAS\nCALIFORNIA\nCOLORADO\nCONNECTICUT\nDELAWARE\n...\nSOUTH DAKOTA\nTENNESSEE\nTEXAS\nUTAH\nVERMONT\nVIRGINIA\nWASHINGTON\nWEST VIRGINIA\nWISCONSIN\nWYOMING\n\n\n\n\n0\n1928\n1\n3.67\nNaN\n1.90\n4.11\n1.38\n8.38\n4.50\n8.58\n...\n5.69\n22.03\n1.18\n0.4\n0.28\nNaN\n14.83\n3.36\n1.54\n0.91\n\n\n1\n1928\n2\n6.25\nNaN\n6.40\n9.91\n1.80\n6.02\n9.00\n7.30\n...\n6.57\n16.96\n0.63\nNaN\n0.56\nNaN\n17.34\n4.19\n0.96\nNaN\n\n\n2\n1928\n3\n7.95\nNaN\n4.50\n11.15\n1.31\n2.86\n8.81\n15.88\n...\n2.04\n24.66\n0.62\n0.2\n1.12\nNaN\n15.67\n4.19\n4.79\n1.36\n\n\n3\n1928\n4\n12.58\nNaN\n1.90\n13.75\n1.87\n13.71\n10.40\n4.29\n...\n2.19\n18.86\n0.37\n0.2\n6.70\nNaN\n12.77\n4.66\n1.64\n3.64\n\n\n4\n1928\n5\n8.03\nNaN\n0.47\n20.79\n2.38\n5.13\n16.80\n5.58\n...\n3.94\n20.05\n1.57\n0.4\n6.70\nNaN\n18.83\n7.37\n2.91\n0.91\n\n\n\n\n5 rows × 53 columns\n\n\n\nThen, use the pandas.melt() function to convert it to tidy format:\n\n\nCode\nannual = data.drop(\"WEEK\", axis=1)\nmeasles = annual.groupby(\"YEAR\").sum().reset_index()\nmeasles = measles.melt(id_vars=\"YEAR\", var_name=\"state\", value_name=\"incidence\")\n\n\n\n\n\n\n\n\n\n\n\nYEAR\nstate\nincidence\n\n\n\n\n0\n1928\nALABAMA\n334.99\n\n\n1\n1929\nALABAMA\n111.93\n\n\n2\n1930\nALABAMA\n157.00\n\n\n3\n1931\nALABAMA\n337.29\n\n\n4\n1932\nALABAMA\n10.21\n\n\n\n\n\n\n\nFinally, load altair:\n\nimport altair as alt\n\nAnd generate our final data viz:\n\n# use a custom color map\ncolormap = alt.Scale(\n    domain=[0, 100, 200, 300, 1000, 3000],\n    range=[\n        \"#F0F8FF\",\n        \"cornflowerblue\",\n        \"mediumseagreen\",\n        \"#FFEE00\",\n        \"darkorange\",\n        \"firebrick\",\n    ],\n    type=\"sqrt\",\n)\n\n# Vertical line for vaccination year\nthreshold = pd.DataFrame([{\"threshold\": 1963}])\n\n# plot YEAR vs state, colored by incidence\nchart = (\n    alt.Chart(measles)\n    .mark_rect()\n    .encode(\n        x=alt.X(\"YEAR:O\", axis=alt.Axis(title=None, ticks=False)),\n        y=alt.Y(\"state:N\", axis=alt.Axis(title=None, ticks=False)),\n        color=alt.Color(\"incidence:Q\", sort=\"ascending\", scale=colormap, legend=None),\n        tooltip=[\"state\", \"YEAR\", \"incidence\"],\n    )\n    .properties(width=650, height=500)\n)\n\nrule = alt.Chart(threshold).mark_rule(strokeWidth=4).encode(x=\"threshold:O\")\n\nout = chart + rule\nout"
  },
  {
    "objectID": "analysis/3-altair-hvplot.html#example-measles-incidence-in-hvplot",
    "href": "analysis/3-altair-hvplot.html#example-measles-incidence-in-hvplot",
    "title": "Altair and Hvplot Charts",
    "section": "Example: Measles Incidence in hvplot",
    "text": "Example: Measles Incidence in hvplot\n\n\n\n\n\n\n\n\n\n\n\n\nGenerate the same data viz in hvplot:\n\n# Make the heatmap with hvplot\nheatmap = measles.hvplot.heatmap(\n    x=\"YEAR\",\n    y=\"state\",\n    C=\"incidence\", # color each square by the incidence\n    reduce_function=np.sum, # sum the incidence for each state/year\n    frame_height=450,\n    frame_width=600,\n    flip_yaxis=True,\n    rot=90,\n    colorbar=False,\n    cmap=\"viridis\",\n    xlabel=\"\",\n    ylabel=\"\",\n)\n\n# Some additional formatting using holoviews \n# For more info: http://holoviews.org/user_guide/Customizing_Plots.html\nheatmap = heatmap.redim(state=\"State\", YEAR=\"Year\")\nheatmap = heatmap.opts(fontsize={\"xticks\": 0, \"yticks\": 6}, toolbar=\"above\")\nheatmap"
  },
  {
    "objectID": "analysis/index.html",
    "href": "analysis/index.html",
    "title": "Analysis",
    "section": "",
    "text": "Like other big cities, Philadelphia also experiences daily traffic congestions, particularly during peak commuting hours. Congestion not only increases travel times but also contributes to higher fuel consumption, air pollution, and commuter frustration. The city’s aging traffic signal infrastructure often relies on static timing plans that fail to adapt to real-time traffic conditions, exacerbating delays at critical intersections. By leveraging real-time traffic data, machine learning, and geospatial analysis, Philadelphia can adopt adaptive traffic signal control systems to dynamically adjust signal timings based on current traffic conditions. Such a system would not only reduce congestion but also improve safety, enhance air quality, and support the city’s broader goals of sustainable and efficient urban mobility. This project aims to develop an adaptive traffic signal optimization system through machine learning tools, using real-time traffic sensor data, historical traffic patterns, and transportation data.\n\n\n\nFirst, we will use street network data from OpenStreetMap data via OSMnx to analyze traffic flow and identify key intersections for optimization. Second, we plan to collect real-time traffic sensor data via APIs such as Google Maps Traffic API, HERE Traffic API, or TomTom Traffic API. Third, we will add Historical Traffic from traffic sensor APIs or public datasets for model training and time-series analysis to predict traffic conditions. The data contains historical traffic patterns, including peak hours, seasonal trends, and congestion hotspots. Finally, we plan to add data for the machine learning model for optimizing traffic signal times. The data includes weather, Traffic Analysis Zones, household travel survey, amenity data etc. to make the model more precise.\n\n\n\nWhat are the traffic flow patterns across different intersections and times of day in Philadelphia? Which intersections or regions experience the highest congestion, and how can they be prioritized for optimization? How can real-time traffic data be used to optimize signal timings and reduce congestion through machine learning?\n\n\n\nIn the data collection and preprocessing phase, we would collect real-time traffic data using APIs and aggregate historical data for analysis. Then, we plan to use OSMnx to model the road network and analyze traffic flow at intersections and identify critical intersections with high congestion levels. We will also analyze historical traffic data to identify trends, peak hours, and seasonal variations. Finally, we will use predictive models like scikit-learn to estimate traffic flow and adjust signal timings dynamically.\n\n\n\nFirst, this project will satisfy the scraping and API requirement through gathering real-time traffic data. Then, It combines data collected from 3 or more different sources. This project also involves OSMnx to perform an analysis of street network data. We also want to perform a machine learning analysis with scikit-learn as part of the analysis. Finally, The project includes multiple interactive visualizations that include a significant interactive component.",
    "crumbs": [
      "Analysis"
    ]
  },
  {
    "objectID": "analysis/2-static-images.html",
    "href": "analysis/2-static-images.html",
    "title": "Showing static visualizations",
    "section": "",
    "text": "This page is generated from a Jupyter notebook and demonstrates how to generate static visualizations with matplotlib, pandas, and seaborn.\nStart by importing the packages we need:\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nLoad the “Palmer penguins” dataset from week 2:\n# Load data on Palmer penguins\npenguins = pd.read_csv(\"https://raw.githubusercontent.com/MUSA-550-Fall-2023/week-2/main/data/penguins.csv\")\n# Show the first ten rows\npenguins.head(n=10)    \n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n\n\n6\nAdelie\nTorgersen\n38.9\n17.8\n181.0\n3625.0\nfemale\n2007\n\n\n7\nAdelie\nTorgersen\n39.2\n19.6\n195.0\n4675.0\nmale\n2007\n\n\n8\nAdelie\nTorgersen\n34.1\n18.1\n193.0\n3475.0\nNaN\n2007\n\n\n9\nAdelie\nTorgersen\n42.0\n20.2\n190.0\n4250.0\nNaN\n2007"
  },
  {
    "objectID": "analysis/2-static-images.html#a-simple-visualization-3-different-ways",
    "href": "analysis/2-static-images.html#a-simple-visualization-3-different-ways",
    "title": "Showing static visualizations",
    "section": "A simple visualization, 3 different ways",
    "text": "A simple visualization, 3 different ways\n\nI want to scatter flipper length vs. bill length, colored by the penguin species\n\n\nUsing matplotlib\n\n# Setup a dict to hold colors for each species\ncolor_map = {\"Adelie\": \"#1f77b4\", \"Gentoo\": \"#ff7f0e\", \"Chinstrap\": \"#D62728\"}\n\n# Initialize the figure \"fig\" and axes \"ax\"\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# Group the data frame by species and loop over each group\n# NOTE: \"group\" will be the dataframe holding the data for \"species\"\nfor species, group_df in penguins.groupby(\"species\"):\n\n    # Plot flipper length vs bill length for this group\n    # Note: we are adding this plot to the existing \"ax\" object\n    ax.scatter(\n        group_df[\"flipper_length_mm\"],\n        group_df[\"bill_length_mm\"],\n        marker=\"o\",\n        label=species,\n        color=color_map[species],\n        alpha=0.75,\n        zorder=10\n    )\n\n# Plotting is done...format the axes!\n\n## Add a legend to the axes\nax.legend(loc=\"best\")\n\n## Add x-axis and y-axis labels\nax.set_xlabel(\"Flipper Length (mm)\")\nax.set_ylabel(\"Bill Length (mm)\")\n\n## Add the grid of lines\nax.grid(True);\n\n\n\n\n\n\nHow about in pandas?\nDataFrames have a built-in “plot” function that can make all of the basic type of matplotlib plots!\nFirst, we need to add a new “color” column specifying the color to use for each species type.\nUse the pd.replace() function: it use a dict to replace values in a DataFrame column.\n\n# Calculate a list of colors\ncolor_map = {\"Adelie\": \"#1f77b4\", \"Gentoo\": \"#ff7f0e\", \"Chinstrap\": \"#D62728\"}\n\n# Map species name to color \npenguins[\"color\"] = penguins[\"species\"].replace(color_map)\n\npenguins.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\ncolor\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n#1f77b4\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n#1f77b4\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n#1f77b4\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n#1f77b4\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n#1f77b4\n\n\n\n\n\n\n\nNow plot!\n\n# Same as before: Start by initializing the figure and axes\nfig, myAxes = plt.subplots(figsize=(10, 6))\n\n# Scatter plot two columns, colored by third\n# Use the built-in pandas plot.scatter function\npenguins.plot.scatter(\n    x=\"flipper_length_mm\",\n    y=\"bill_length_mm\",\n    c=\"color\",\n    alpha=0.75,\n    ax=myAxes, # IMPORTANT: Make sure to plot on the axes object we created already!\n    zorder=10\n)\n\n# Format the axes finally\nmyAxes.set_xlabel(\"Flipper Length (mm)\")\nmyAxes.set_ylabel(\"Bill Length (mm)\")\nmyAxes.grid(True);\n\n\n\n\nNote: no easy way to get legend added to the plot in this case…\n\n\nSeaborn: statistical data visualization\nSeaborn is designed to plot two columns colored by a third column…\n\n# Initialize the figure and axes\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# style keywords as dict\ncolor_map = {\"Adelie\": \"#1f77b4\", \"Gentoo\": \"#ff7f0e\", \"Chinstrap\": \"#D62728\"}\nstyle = dict(palette=color_map, s=60, edgecolor=\"none\", alpha=0.75, zorder=10)\n\n# use the scatterplot() function\nsns.scatterplot(\n    x=\"flipper_length_mm\",  # the x column\n    y=\"bill_length_mm\",  # the y column\n    hue=\"species\",  # the third dimension (color)\n    data=penguins,  # pass in the data\n    ax=ax,  # plot on the axes object we made\n    **style  # add our style keywords\n)\n\n# Format with matplotlib commands\nax.set_xlabel(\"Flipper Length (mm)\")\nax.set_ylabel(\"Bill Length (mm)\")\nax.grid(True)\nax.legend(loc=\"best\");"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mapping Crash Data and Predicting Traffic Volume in New York City Using OSMnx and Machine Learning",
    "section": "",
    "text": "This webpage is dedicated to presenting our final project for class MUSA 550: Geospatial Data Science in Python (Fall 2024).\nYou can learn more information on the class website.\nThis project is the culmination of work undertaken in a course that bridges the power of data science with urban planning. The course equips students with the skills to transform raw data into actionable insights, employing the latest Python tools and a structured “pipeline” approach. Through real-world case studies, it provides hands-on experience in gathering, analyzing, and visualizing data, with a final focus on crafting compelling, interactive narratives. Key modules cover everything from exploratory data science and geospatial analysis to advanced machine learning applications, laying a strong foundation for innovative urban research.\nUrban mobility challenges are a pressing issue for cities worldwide, and Philadelphia is no exception. Like many metropolitan areas, it faces significant traffic congestion, particularly during peak hours. This congestion is exacerbated by an aging traffic signal system that relies on static timing plans, incapable of adapting to real-time conditions. The consequences are far-reaching: increased travel times, higher emissions, and frustrated commuters. Addressing these challenges requires a forward-thinking approach, combining modern technology and data-driven decision-making.\n\n\n\nImage: Traffic in University of Pennsylvania. Source: Penn Today\n\n\nOur project tackles these issues by exploring how adaptive traffic signal optimization can enhance urban mobility. Using New York City crash data as a case study, we apply machine learning tools and geospatial analysis to model traffic volume and patterns. With real-time traffic data and historical insights, we demonstrate the potential of dynamic traffic signal systems to alleviate congestion, improve safety, and reduce environmental impacts. By leveraging tools such as OSMnx and Python-based machine learning, we aim to contribute to the broader conversation on sustainable and efficient urban transportation systems.\nWe invite you to explore our findings, methodologies, and visualizations that highlight how data science can transform the way cities address traffic management and urban mobility challenges.\n\n\n\n\n\n\nImportant\n\n\n\n辣椒炒肉!",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Traffic Signal Optimization",
    "section": "",
    "text": "Like other big cities, Philadelphia also experiences daily traffic congestion, particularly during peak commuting hours. Congestion not only increases travel times but also contributes to higher fuel consumption, air pollution, and commuter frustration. The city’s aging traffic signal infrastructure often relies on static timing plans that fail to adapt to real-time traffic conditions, exacerbating delays at critical intersections. By leveraging real-time traffic data, machine learning, and geospatial analysis, Philadelphia can adopt adaptive traffic signal control systems to dynamically adjust signal timings based on current traffic conditions. Such a system would not only reduce congestion but also improve safety, enhance air quality, and support the city’s broader goals of sustainable and efficient urban mobility.\n\n\n\nScreenshots of Manhattan crash maps from the project.\n\n\nThis project aims to develop an adaptive traffic signal optimization system through machine learning tools, using real-time traffic sensor data, historical traffic patterns, and transportation data.\n\n\n\n\n\n\nImportant\n\n\n\nEric is the best!",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "analysis/Script.html",
    "href": "analysis/Script.html",
    "title": "Part 1: Street Network with OSMnx",
    "section": "",
    "text": "# The usual imports\nimport altair as alt\nimport geopandas as gpd\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n\n# Show all columns in dataframes\npd.options.display.max_columns = 999\n\n# Hide warnings due to issue in shapely package \n# See: https://github.com/shapely/shapely/issues/1345\nnp.seterr(invalid=\"ignore\");\nimport osmnx as ox\n\nNYC = gpd.read_file(\"new-york-city-boroughs.geojson\")\nNYC_M = NYC[NYC[\"name\"] == \"Manhattan\"]\n\nNYC_M\n\n\n\n\n\n\n\n\nname\ncartodb_id\ncreated_at\nupdated_at\ngeometry\n\n\n\n\n3\nManhattan\n4\n2013-03-09 02:42:03.692000+00:00\n2013-03-09 02:42:03.989000+00:00\nMULTIPOLYGON (((-74.01093 40.68449, -74.01193 ...\n\n\n\n\n\n\n\n\n\n\n\n# Project it to Web Mercator first and plot\nax = NYC_M.to_crs(epsg=4326).plot(facecolor=\"none\", edgecolor=\"black\")\nax.set_axis_off()\n\n\n\n\n\n\n\n\n\n\n\n\n# Define your polygon boundary (replace with your actual polygon)\n# For example, if you have a GeoDataFrame with your area boundary:\npolygon = NYC_M.unary_union  \n\n# Create a street network graph\nG = ox.graph_from_polygon(polygon, network_type='drive')\n\n# Convert graph edges to a GeoDataFrame\nedges_gdf = ox.graph_to_gdfs(G, nodes=False, edges=True)\n\n# Display the first few rows of the GeoDataFrame\nprint(edges_gdf.head())\n\n# Plot the edges GeoDataFrame\nfig, ax = plt.subplots(figsize=(20, 20))\nedges_gdf.plot(ax=ax, linewidth=1, edgecolor='black')\nplt.show()\n\n                                                 osmid               name  \\\nu        v        key                                                       \n42421728 42435337 0                          195743153  Central Park West   \n         42421731 0    [420625565, 420625573, 5668966]  West 106th Street   \n         42432736 0           [1271523197, 1271523198]  Central Park West   \n42421731 42437916 0                            5671485   Manhattan Avenue   \n         42432737 0                          195743186   Manhattan Avenue   \n\n                           highway maxspeed  oneway reversed   length  \\\nu        v        key                                                   \n42421728 42435337 0      secondary   25 mph   False     True   85.345   \n         42421731 0      secondary      NaN   False    False  138.033   \n         42432736 0      secondary   25 mph   False    False   86.275   \n42421731 42437916 0    residential      NaN   False     True   86.149   \n         42432737 0    residential      NaN   False    False   85.968   \n\n                                                                geometry  \\\nu        v        key                                                      \n42421728 42435337 0    LINESTRING (-73.96004 40.79805, -73.96011 40.7...   \n         42421731 0    LINESTRING (-73.96004 40.79805, -73.96017 40.7...   \n         42432736 0    LINESTRING (-73.96004 40.79805, -73.95997 40.7...   \n42421731 42437916 0    LINESTRING (-73.96147 40.79865, -73.96154 40.7...   \n         42432737 0    LINESTRING (-73.96147 40.79865, -73.96140 40.7...   \n\n                      lanes  ref access bridge tunnel width junction  \nu        v        key                                                 \n42421728 42435337 0     NaN  NaN    NaN    NaN    NaN   NaN      NaN  \n         42421731 0     NaN  NaN    NaN    NaN    NaN   NaN      NaN  \n         42432736 0     NaN  NaN    NaN    NaN    NaN   NaN      NaN  \n42421731 42437916 0     NaN  NaN    NaN    NaN    NaN   NaN      NaN  \n         42432737 0     NaN  NaN    NaN    NaN    NaN   NaN      NaN  \n\n\n\n\n\n\n\n\n\n\n\n\n\n# Load data into a pandas DataFrame\ndata = pd.read_csv(\"Motor_Vehicle_Collisions_Crashes.csv\")\n\n\ndata\n\n\n\n\n\n\n\n\nCRASH DATE\nCRASH TIME\nBOROUGH\nZIP CODE\nLATITUDE\nLONGITUDE\nLOCATION\nON STREET NAME\nCROSS STREET NAME\nOFF STREET NAME\nNUMBER OF PERSONS INJURED\nNUMBER OF PERSONS KILLED\nNUMBER OF PEDESTRIANS INJURED\nNUMBER OF PEDESTRIANS KILLED\nNUMBER OF CYCLIST INJURED\nNUMBER OF CYCLIST KILLED\nNUMBER OF MOTORIST INJURED\nNUMBER OF MOTORIST KILLED\nCONTRIBUTING FACTOR VEHICLE 1\nCONTRIBUTING FACTOR VEHICLE 2\nCONTRIBUTING FACTOR VEHICLE 3\nCONTRIBUTING FACTOR VEHICLE 4\nCONTRIBUTING FACTOR VEHICLE 5\nCOLLISION_ID\nVEHICLE TYPE CODE 1\nVEHICLE TYPE CODE 2\nVEHICLE TYPE CODE 3\nVEHICLE TYPE CODE 4\nVEHICLE TYPE CODE 5\n\n\n\n\n0\n05/01/2021\n13:30\nMANHATTAN\n10029.0\n40.796300\n-73.938290\n(40.7963, -73.93829)\nEAST 115 STREET\n2 AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nPassing or Lane Usage Improper\nUnspecified\nNaN\nNaN\nNaN\n4412937\nBus\nSedan\nNaN\nNaN\nNaN\n\n\n1\n05/01/2021\n17:50\nMANHATTAN\n10012.0\n40.720936\n-73.993805\n(40.720936, -73.993805)\nBOWERY\nSPRING STREET\nNaN\n1\n0\n0\n0\n0\n0\n1\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4412445\nSedan\nSedan\nNaN\nNaN\nNaN\n\n\n2\n05/01/2021\n13:30\nMANHATTAN\n10128.0\n40.780693\n-73.946600\n(40.780693, -73.9466)\nEAST 92 STREET\n1 AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4414390\nAMBULANCE\nSedan\nNaN\nNaN\nNaN\n\n\n3\n05/01/2021\n9:40\nMANHATTAN\n10026.0\n40.800537\n-73.948360\n(40.800537, -73.94836)\nNaN\nNaN\n40 WEST 115 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nBacking Unsafely\nUnspecified\nNaN\nNaN\nNaN\n4417017\nStation Wagon/Sport Utility Vehicle\nNaN\nNaN\nNaN\nNaN\n\n\n4\n05/01/2021\n23:03\nMANHATTAN\n10009.0\n40.726864\n-73.979910\n(40.726864, -73.97991)\nAVENUE B\nEAST 10 STREET\nNaN\n1\n0\n0\n0\n1\n0\n0\n0\nDriver Inattention/Distraction\nDriver Inattention/Distraction\nNaN\nNaN\nNaN\n4412243\nBike\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n32364\n12/31/2023\n23:18\nMANHATTAN\n10030.0\n40.819670\n-73.944240\n(40.81967, -73.94424)\n8 AVENUE\nWEST 140 STREET\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nDriver Inattention/Distraction\nNaN\nNaN\nNaN\nNaN\n4692572\nSedan\nNaN\nNaN\nNaN\nNaN\n\n\n32365\n12/31/2023\n18:03\nMANHATTAN\n10039.0\n40.824130\n-73.940980\n(40.82413, -73.94098)\n8 AVENUE\nWEST 147 STREET\nNaN\n1\n0\n1\n0\n0\n0\n0\n0\nUnspecified\nNaN\nNaN\nNaN\nNaN\n4692571\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n32366\n12/31/2023\n14:00\nMANHATTAN\n10028.0\n40.777890\n-73.955890\n(40.77789, -73.95589)\nNaN\nNaN\n160 EAST 84 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4692524\nSedan\nSedan\nNaN\nNaN\nNaN\n\n\n32367\n12/31/2023\n21:34\nMANHATTAN\n10033.0\n40.849308\n-73.931920\n(40.849308, -73.93192)\nWEST 182 STREET\nAUDUBON AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nUnspecified\nUnspecified\nNaN\nNaN\nNaN\n4692192\nStation Wagon/Sport Utility Vehicle\nSedan\nNaN\nNaN\nNaN\n\n\n32368\n12/31/2023\n0:38\nMANHATTAN\n10006.0\n40.709496\n-74.013900\n(40.709496, -74.0139)\nALBANY STREET\nWASHINGTON STREET\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nOther Vehicular\nUnspecified\nNaN\nNaN\nNaN\n4692585\nSedan\nPick-up Truck\nNaN\nNaN\nNaN\n\n\n\n\n32369 rows × 29 columns\n\n\n\n\n\n\n\nfrom shapely.geometry import Point\n\n# Check if the necessary columns exist\nif 'LATITUDE' in data.columns and 'LONGITUDE' in data.columns:\n    # Create a geometry column using the DEC_LAT and DEC_LONG columns\n    geometry = [Point(xy) for xy in zip(data['LONGITUDE'], data['LATITUDE'])]\n    \n    # Create a GeoDataFrame\n    gdf = gpd.GeoDataFrame(data, geometry=geometry)\n\n    # Set the coordinate reference system (CRS) to WGS 84 (EPSG:4326)\n    gdf.set_crs(epsg=4326, inplace=True)\n\n    # Display the first few rows of the GeoDataFrame\n    print(gdf.head())\nelse:\n    print(\"The DataFrame does not contain 'DEC_LAT' and 'DEC_LONG' columns.\")\n\n   CRASH DATE CRASH TIME    BOROUGH  ZIP CODE   LATITUDE  LONGITUDE  \\\n0  05/01/2021      13:30  MANHATTAN   10029.0  40.796300 -73.938290   \n1  05/01/2021      17:50  MANHATTAN   10012.0  40.720936 -73.993805   \n2  05/01/2021      13:30  MANHATTAN   10128.0  40.780693 -73.946600   \n3  05/01/2021       9:40  MANHATTAN   10026.0  40.800537 -73.948360   \n4  05/01/2021      23:03  MANHATTAN   10009.0  40.726864 -73.979910   \n\n                  LOCATION   ON STREET NAME CROSS STREET NAME  \\\n0     (40.7963, -73.93829)  EAST 115 STREET          2 AVENUE   \n1  (40.720936, -73.993805)           BOWERY     SPRING STREET   \n2    (40.780693, -73.9466)   EAST 92 STREET          1 AVENUE   \n3   (40.800537, -73.94836)              NaN               NaN   \n4   (40.726864, -73.97991)         AVENUE B    EAST 10 STREET   \n\n             OFF STREET NAME  NUMBER OF PERSONS INJURED  \\\n0                        NaN                          0   \n1                        NaN                          1   \n2                        NaN                          0   \n3  40        WEST 115 STREET                          0   \n4                        NaN                          1   \n\n   NUMBER OF PERSONS KILLED  NUMBER OF PEDESTRIANS INJURED  \\\n0                         0                              0   \n1                         0                              0   \n2                         0                              0   \n3                         0                              0   \n4                         0                              0   \n\n   NUMBER OF PEDESTRIANS KILLED  NUMBER OF CYCLIST INJURED  \\\n0                             0                          0   \n1                             0                          0   \n2                             0                          0   \n3                             0                          0   \n4                             0                          1   \n\n   NUMBER OF CYCLIST KILLED  NUMBER OF MOTORIST INJURED  \\\n0                         0                           0   \n1                         0                           1   \n2                         0                           0   \n3                         0                           0   \n4                         0                           0   \n\n   NUMBER OF MOTORIST KILLED   CONTRIBUTING FACTOR VEHICLE 1  \\\n0                          0  Passing or Lane Usage Improper   \n1                          0  Driver Inattention/Distraction   \n2                          0  Driver Inattention/Distraction   \n3                          0                Backing Unsafely   \n4                          0  Driver Inattention/Distraction   \n\n    CONTRIBUTING FACTOR VEHICLE 2 CONTRIBUTING FACTOR VEHICLE 3  \\\n0                     Unspecified                           NaN   \n1                     Unspecified                           NaN   \n2                     Unspecified                           NaN   \n3                     Unspecified                           NaN   \n4  Driver Inattention/Distraction                           NaN   \n\n  CONTRIBUTING FACTOR VEHICLE 4 CONTRIBUTING FACTOR VEHICLE 5  COLLISION_ID  \\\n0                           NaN                           NaN       4412937   \n1                           NaN                           NaN       4412445   \n2                           NaN                           NaN       4414390   \n3                           NaN                           NaN       4417017   \n4                           NaN                           NaN       4412243   \n\n                   VEHICLE TYPE CODE 1 VEHICLE TYPE CODE 2  \\\n0                                  Bus               Sedan   \n1                                Sedan               Sedan   \n2                            AMBULANCE               Sedan   \n3  Station Wagon/Sport Utility Vehicle                 NaN   \n4                                 Bike                 NaN   \n\n  VEHICLE TYPE CODE 3 VEHICLE TYPE CODE 4 VEHICLE TYPE CODE 5  \\\n0                 NaN                 NaN                 NaN   \n1                 NaN                 NaN                 NaN   \n2                 NaN                 NaN                 NaN   \n3                 NaN                 NaN                 NaN   \n4                 NaN                 NaN                 NaN   \n\n                     geometry  \n0  POINT (-73.93829 40.79630)  \n1  POINT (-73.99380 40.72094)  \n2  POINT (-73.94660 40.78069)  \n3  POINT (-73.94836 40.80054)  \n4  POINT (-73.97991 40.72686)  \n\n\n\n\n\n\n# Assuming edges_gdf is your GeoDataFrame from part 1.3\nmanhattan_boundary = edges_gdf.geometry.unary_union.convex_hull\n\n# Filter the crash GeoDataFrame to only include crashes within the boundary\nmanhattan_crashes = gdf[gdf.geometry.within(manhattan_boundary)]\n\n# Display the number of crashes within the Center City boundary\nprint(f\"Number of crashes within manhattan: {len(manhattan_crashes)}\")\n\n# Display the first few rows of the filtered GeoDataFrame\nmanhattan_crashes.head()\n\nNumber of crashes within manhattan: 31042\n\n\n\n\n\n\n\n\n\nCRASH DATE\nCRASH TIME\nBOROUGH\nZIP CODE\nLATITUDE\nLONGITUDE\nLOCATION\nON STREET NAME\nCROSS STREET NAME\nOFF STREET NAME\nNUMBER OF PERSONS INJURED\nNUMBER OF PERSONS KILLED\nNUMBER OF PEDESTRIANS INJURED\nNUMBER OF PEDESTRIANS KILLED\nNUMBER OF CYCLIST INJURED\nNUMBER OF CYCLIST KILLED\nNUMBER OF MOTORIST INJURED\nNUMBER OF MOTORIST KILLED\nCONTRIBUTING FACTOR VEHICLE 1\nCONTRIBUTING FACTOR VEHICLE 2\nCONTRIBUTING FACTOR VEHICLE 3\nCONTRIBUTING FACTOR VEHICLE 4\nCONTRIBUTING FACTOR VEHICLE 5\nCOLLISION_ID\nVEHICLE TYPE CODE 1\nVEHICLE TYPE CODE 2\nVEHICLE TYPE CODE 3\nVEHICLE TYPE CODE 4\nVEHICLE TYPE CODE 5\ngeometry\n\n\n\n\n0\n05/01/2021\n13:30\nMANHATTAN\n10029.0\n40.796300\n-73.938290\n(40.7963, -73.93829)\nEAST 115 STREET\n2 AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nPassing or Lane Usage Improper\nUnspecified\nNaN\nNaN\nNaN\n4412937\nBus\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.93829 40.79630)\n\n\n1\n05/01/2021\n17:50\nMANHATTAN\n10012.0\n40.720936\n-73.993805\n(40.720936, -73.993805)\nBOWERY\nSPRING STREET\nNaN\n1\n0\n0\n0\n0\n0\n1\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4412445\nSedan\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.99380 40.72094)\n\n\n2\n05/01/2021\n13:30\nMANHATTAN\n10128.0\n40.780693\n-73.946600\n(40.780693, -73.9466)\nEAST 92 STREET\n1 AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4414390\nAMBULANCE\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.94660 40.78069)\n\n\n3\n05/01/2021\n9:40\nMANHATTAN\n10026.0\n40.800537\n-73.948360\n(40.800537, -73.94836)\nNaN\nNaN\n40 WEST 115 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nBacking Unsafely\nUnspecified\nNaN\nNaN\nNaN\n4417017\nStation Wagon/Sport Utility Vehicle\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.94836 40.80054)\n\n\n4\n05/01/2021\n23:03\nMANHATTAN\n10009.0\n40.726864\n-73.979910\n(40.726864, -73.97991)\nAVENUE B\nEAST 10 STREET\nNaN\n1\n0\n0\n0\n1\n0\n0\n0\nDriver Inattention/Distraction\nDriver Inattention/Distraction\nNaN\nNaN\nNaN\n4412243\nBike\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.97991 40.72686)\n\n\n\n\n\n\n\n\n\n\n\nimport osmnx as ox\n\n# Assuming G is your graph object\n# Project the graph to the Philadelphia state plane CRS (EPSG:2272)\nG_projected = ox.project_graph(G, to_crs='EPSG:2263')\n\n# Project the crash GeoDataFrame to the Philadelphia state plane CRS (EPSG:2272)\nmanhattan_crashes_projected = manhattan_crashes.to_crs(epsg=2263)\n\n# Display the first few rows of the projected GeoDataFrame\nmanhattan_crashes_projected.head()\n\n# Create a plot\nfig, ax = plt.subplots(figsize=(12, 12))\n\n# Plot the street network\nedges_gdf_projected = ox.graph_to_gdfs(G_projected, nodes=False)\nedges_gdf_projected.plot(ax=ax, linewidth=1, edgecolor='gray', label='Street Network')\n\n# Plot the crash locations\nmanhattan_crashes_projected.plot(ax=ax, marker='o', color='red', markersize=5, label='Crashes')\n\n# Add a title and legend\nplt.title('Crash Locations in Manhattan with Street Network')\nplt.legend()\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nSee: ox.distance.nearest_edges(). It takes three arguments:\nthe network graph the longitude of your crash data (the x attribute of the geometry column) the latitude of your crash data (the y attribute of the geometry column) You will get a numpy array with 3 columns that represent (u, v, key) where each u and v are the node IDs that the edge links together. We will ignore the key value for our analysis.\n\n# Extract x and y coordinates from the geometry column\ncrash_x = manhattan_crashes_projected.geometry.x\ncrash_y = manhattan_crashes_projected.geometry.y\n\n# Find the nearest edges for each crash\nnearest_edges = ox.distance.nearest_edges(G_projected, crash_x, crash_y)\n\n# Convert the result to a numpy array\nnearest_edges_array = np.array(nearest_edges)\n\n# Display the first few results\nprint(nearest_edges_array[:5])\n\n# Extract only the u and v columns, ignoring the key\nnearest_edges_uv = nearest_edges_array[:, :2]\n\n# Display the first few u, v pairs\nprint(nearest_edges_uv[:5])\n\n[[4207962275   42443081          0]\n [  42437605 1773076509          0]\n [  42443048   42448745          0]\n [  42435387   42446772          0]\n [  42430924   42430938          0]]\n[[4207962275   42443081]\n [  42437605 1773076509]\n [  42443048   42448745]\n [  42435387   42446772]\n [  42430924   42430938]]\n\n\n\n\n\n\n# Create a DataFrame from the nearest edges data\nedges_df = pd.DataFrame(nearest_edges_array, columns=['u', 'v', 'key'])\n\n# Group by 'u' and 'v' and calculate the size of each group\ncrash_counts = edges_df.groupby(['u', 'v']).size().reset_index(name='crash_count')\n\n# Display the resulting DataFrame\ncrash_counts\n\n\n\n\n\n\n\n\nu\nv\ncrash_count\n\n\n\n\n0\n42421728\n42432736\n2\n\n\n1\n42421731\n42437916\n1\n\n\n2\n42421737\n42437917\n2\n\n\n3\n42421741\n42432756\n1\n\n\n4\n42421751\n42421749\n1\n\n\n...\n...\n...\n...\n\n\n5796\n12162436970\n42455357\n2\n\n\n5797\n12181309686\n4597668039\n5\n\n\n5798\n12299314857\n12299314860\n1\n\n\n5799\n12299314860\n42438476\n3\n\n\n5800\n12374690312\n42433537\n1\n\n\n\n\n5801 rows × 3 columns\n\n\n\n\n\n\n\n# Convert the projected graph to a GeoDataFrame for edges\nedges_gdf_projected = ox.graph_to_gdfs(G_projected, nodes=False)\n\n# Merge the edges GeoDataFrame with the crash counts DataFrame\nmerged_df = edges_gdf_projected.merge(crash_counts, on=['u', 'v'], how='left')\n\n# Fill missing crash count values with zero\nmerged_df['crash_count'] = merged_df['crash_count'].fillna(0)\n\n# Display the first few rows of the merged DataFrame\nmerged_df\n\n# Filter out rows where crash_count is 0.0\nfiltered_df = merged_df[merged_df['crash_count'] &gt; 0.0]\n\n# Display the first few rows of the filtered DataFrame\nfiltered_df\n\n\n\n\n\n\n\n\nu\nv\nosmid\nname\nhighway\nmaxspeed\noneway\nreversed\nlength\ngeometry\nlanes\nref\naccess\nbridge\ntunnel\nwidth\njunction\ncrash_count\n\n\n\n\n2\n42421728\n42432736\n[1271523197, 1271523198]\nCentral Park West\nsecondary\n25 mph\nFalse\nFalse\n86.275\nLINESTRING (995312.767 230030.016, 995334.152 ...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n\n\n3\n42435337\n42437916\n5670640\nWest 105th Street\nresidential\n25 mph\nTrue\nFalse\n137.996\nLINESTRING (995176.877 229785.340, 995144.253 ...\n1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n\n\n6\n42421731\n42437916\n5671485\nManhattan Avenue\nresidential\nNaN\nFalse\nTrue\n86.149\nLINESTRING (994916.519 230250.770, 994899.394 ...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n\n\n11\n42432736\n42435341\n1271523197\nCentral Park West\nsecondary\n25 mph\nFalse\nFalse\n80.116\nLINESTRING (995450.120 230277.316, 995461.822 ...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n\n\n13\n42437916\n42437917\n5670640\nWest 105th Street\nresidential\n25 mph\nTrue\nFalse\n135.012\nLINESTRING (994779.437 230003.728, 994751.078 ...\n1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n8.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n9864\n7802856372\n7802856349\n661227257\nCentral Park West\nsecondary\n25 mph\nFalse\nTrue\n80.457\nLINESTRING (990516.812 221373.627, 990505.794 ...\n4\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n\n\n9865\n7802856372\n7802856356\n[1271523171, 1271523172]\nCentral Park West\nsecondary\n25 mph\nFalse\nFalse\n79.496\nLINESTRING (990516.812 221373.627, 990527.802 ...\n4\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n4.0\n\n\n9867\n8288270047\n246580982\n5671698\nWest 16th Street\nresidential\n25 mph\nTrue\nFalse\n21.068\nLINESTRING (981879.246 210378.461, 981886.366 ...\n1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n6.0\n\n\n9869\n8840333851\n42453952\n5672377\nChurch Street\nsecondary\n25 mph\nTrue\nFalse\n83.590\nLINESTRING (981444.123 198698.940, 981458.126 ...\n3\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n\n\n9878\n11942111842\n42434962\n[658488325, 658499796, 658499797, 420872214, 6...\nNaN\nmotorway_link\nNaN\nTrue\nFalse\n290.747\nLINESTRING (991424.925 211158.515, 991364.955 ...\n[2, 1, 3]\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n\n\n\n\n5805 rows × 18 columns\n\n\n\n\n\n\n\n# Step 1: Calculate the crash index\nfiltered_df['crash_index'] = np.log10(filtered_df['crash_count'] / filtered_df['length'])\n\n# Step 2: Normalize the crash index\nmin_crash_index = filtered_df['crash_index'].min()\nmax_crash_index = filtered_df['crash_index'].max()\n\n# Normalize the crash_index to a 0-1 scale\nfiltered_df['crash_index_normalized'] = (filtered_df['crash_index'] - min_crash_index) / (max_crash_index - min_crash_index)\n\nfiltered_df\n\nC:\\Users\\txx11\\mambaforge\\envs\\musa-550-fall-2023\\lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\nC:\\Users\\txx11\\mambaforge\\envs\\musa-550-fall-2023\\lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\n\n\n\n\n\n\n\n\n\nu\nv\nosmid\nname\nhighway\nmaxspeed\noneway\nreversed\nlength\ngeometry\nlanes\nref\naccess\nbridge\ntunnel\nwidth\njunction\ncrash_count\ncrash_index\ncrash_index_normalized\n\n\n\n\n2\n42421728\n42432736\n[1271523197, 1271523198]\nCentral Park West\nsecondary\n25 mph\nFalse\nFalse\n86.275\nLINESTRING (995312.767 230030.016, 995334.152 ...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n-1.634855\n0.384469\n\n\n3\n42435337\n42437916\n5670640\nWest 105th Street\nresidential\n25 mph\nTrue\nFalse\n137.996\nLINESTRING (995176.877 229785.340, 995144.253 ...\n1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n-2.139866\n0.244838\n\n\n6\n42421731\n42437916\n5671485\nManhattan Avenue\nresidential\nNaN\nFalse\nTrue\n86.149\nLINESTRING (994916.519 230250.770, 994899.394 ...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n-1.935250\n0.301413\n\n\n11\n42432736\n42435341\n1271523197\nCentral Park West\nsecondary\n25 mph\nFalse\nFalse\n80.116\nLINESTRING (995450.120 230277.316, 995461.822 ...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n-1.602689\n0.393363\n\n\n13\n42437916\n42437917\n5670640\nWest 105th Street\nresidential\n25 mph\nTrue\nFalse\n135.012\nLINESTRING (994779.437 230003.728, 994751.078 ...\n1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n8.0\n-1.227282\n0.497160\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n9864\n7802856372\n7802856349\n661227257\nCentral Park West\nsecondary\n25 mph\nFalse\nTrue\n80.457\nLINESTRING (990516.812 221373.627, 990505.794 ...\n4\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n-1.905564\n0.309621\n\n\n9865\n7802856372\n7802856356\n[1271523171, 1271523172]\nCentral Park West\nsecondary\n25 mph\nFalse\nFalse\n79.496\nLINESTRING (990516.812 221373.627, 990527.802 ...\n4\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n4.0\n-1.298285\n0.477528\n\n\n9867\n8288270047\n246580982\n5671698\nWest 16th Street\nresidential\n25 mph\nTrue\nFalse\n21.068\nLINESTRING (981879.246 210378.461, 981886.366 ...\n1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n6.0\n-0.545472\n0.685674\n\n\n9869\n8840333851\n42453952\n5672377\nChurch Street\nsecondary\n25 mph\nTrue\nFalse\n83.590\nLINESTRING (981444.123 198698.940, 981458.126 ...\n3\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n-1.621124\n0.388266\n\n\n9878\n11942111842\n42434962\n[658488325, 658499796, 658499797, 420872214, 6...\nNaN\nmotorway_link\nNaN\nTrue\nFalse\n290.747\nLINESTRING (991424.925 211158.515, 991364.955 ...\n[2, 1, 3]\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n-2.463515\n0.155352\n\n\n\n\n5805 rows × 20 columns\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\n# Assuming filtered_df is already defined and contains 'crash_index_normalized'\n\n# Plot a histogram of the normalized crash index values\nplt.figure(figsize=(10, 6))\nplt.hist(filtered_df['crash_index_normalized'], bins=30, color='skyblue', edgecolor='black')\nplt.title('Histogram of Normalized Crash Index')\nplt.xlabel('Normalized Crash Index')\nplt.ylabel('Frequency')\nplt.grid(axis='y', alpha=0.75)\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nimport folium\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n\n# Assuming 'filtered_df' is your GeoDataFrame with the 'crash_index_normalized' column\n\n# Create a base map centered around the Central district with a dark theme\nm = folium.Map(location=[40.7826, -73.9656], zoom_start=12, tiles='CartoDB dark_matter')\n\n# Define a function to style the lines based on the crash index\ndef style_function(feature):\n    crash_index = feature['properties']['crash_index_normalized']\n    # Use the 'viridis' colormap for a color gradient\n    colormap = plt.cm.get_cmap('viridis')\n    # Get the RGBA color based on the crash index\n    color = colormap(crash_index)  # crash_index should already be normalized [0, 1]\n    # Convert RGBA to hex\n    color_hex = '#{:02x}{:02x}{:02x}'.format(int(color[0]*255), int(color[1]*255), int(color[2]*255))\n    return {\n        'color': color_hex,\n        'weight': 3 + crash_index * 2,  # Increase line weight for higher crash index\n        'opacity': 0.8\n    }\n\n# Add the GeoDataFrame to the map\nfolium.GeoJson(\n    filtered_df,\n    style_function=style_function,\n    tooltip=folium.GeoJsonTooltip(fields=['name', 'crash_index_normalized']),\n).add_to(m)\n\n\n# Display the map\nm\n\nC:\\Users\\txx11\\AppData\\Local\\Temp\\ipykernel_2124\\3546299534.py:14: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n  colormap = plt.cm.get_cmap('viridis')\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\nm.save('mahattan_crash_index_map_dark.html')\n\nC:\\Users\\txx11\\AppData\\Local\\Temp\\ipykernel_2124\\3546299534.py:14: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n  colormap = plt.cm.get_cmap('viridis')",
    "crumbs": [
      "Analysis",
      "Part 1: Street Network with OSMnx"
    ]
  },
  {
    "objectID": "analysis/Script.html#part-2-density-map-of-crashes-by-time-of-the-day",
    "href": "analysis/Script.html#part-2-density-map-of-crashes-by-time-of-the-day",
    "title": "Part 1: Street Network with OSMnx",
    "section": "Part 2: Density Map of Crashes by time of the day",
    "text": "Part 2: Density Map of Crashes by time of the day\n\n#load large data\ndat2 = pd.read_csv(\"Crash data_large.csv\")\n\n\nif 'LATITUDE' in dat2.columns and 'LONGITUDE' in data.columns:\n    # Create a geometry column using the DEC_LAT and DEC_LONG columns\n    geometry = [Point(xy) for xy in zip(data['LONGITUDE'], data['LATITUDE'])]\n    \n    # Create a GeoDataFrame\n    gdf2 = gpd.GeoDataFrame(data, geometry=geometry)\n\n    # Set the coordinate reference system (CRS) to WGS 84 (EPSG:4326)\n    gdf2.set_crs(epsg=4326, inplace=True)\n\n# Filter the crash GeoDataFrame to only include crashes within the boundary\ndat2 = gdf[gdf.geometry.within(manhattan_boundary)]\n\n# Display the number of crashes within the Center City boundary\nprint(f\"Number of crashes within manhattan: {len(manhattan_crashes)}\")\n\n# Display the first few rows of the filtered GeoDataFrame\ndat2.head()\n\nNumber of crashes within manhattan: 31042\n\n\n\n\n\n\n\n\n\nCRASH DATE\nCRASH TIME\nBOROUGH\nZIP CODE\nLATITUDE\nLONGITUDE\nLOCATION\nON STREET NAME\nCROSS STREET NAME\nOFF STREET NAME\nNUMBER OF PERSONS INJURED\nNUMBER OF PERSONS KILLED\nNUMBER OF PEDESTRIANS INJURED\nNUMBER OF PEDESTRIANS KILLED\nNUMBER OF CYCLIST INJURED\nNUMBER OF CYCLIST KILLED\nNUMBER OF MOTORIST INJURED\nNUMBER OF MOTORIST KILLED\nCONTRIBUTING FACTOR VEHICLE 1\nCONTRIBUTING FACTOR VEHICLE 2\nCONTRIBUTING FACTOR VEHICLE 3\nCONTRIBUTING FACTOR VEHICLE 4\nCONTRIBUTING FACTOR VEHICLE 5\nCOLLISION_ID\nVEHICLE TYPE CODE 1\nVEHICLE TYPE CODE 2\nVEHICLE TYPE CODE 3\nVEHICLE TYPE CODE 4\nVEHICLE TYPE CODE 5\ngeometry\n\n\n\n\n0\n05/01/2021\n13:30\nMANHATTAN\n10029.0\n40.796300\n-73.938290\n(40.7963, -73.93829)\nEAST 115 STREET\n2 AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nPassing or Lane Usage Improper\nUnspecified\nNaN\nNaN\nNaN\n4412937\nBus\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.93829 40.79630)\n\n\n1\n05/01/2021\n17:50\nMANHATTAN\n10012.0\n40.720936\n-73.993805\n(40.720936, -73.993805)\nBOWERY\nSPRING STREET\nNaN\n1\n0\n0\n0\n0\n0\n1\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4412445\nSedan\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.99380 40.72094)\n\n\n2\n05/01/2021\n13:30\nMANHATTAN\n10128.0\n40.780693\n-73.946600\n(40.780693, -73.9466)\nEAST 92 STREET\n1 AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4414390\nAMBULANCE\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.94660 40.78069)\n\n\n3\n05/01/2021\n9:40\nMANHATTAN\n10026.0\n40.800537\n-73.948360\n(40.800537, -73.94836)\nNaN\nNaN\n40 WEST 115 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nBacking Unsafely\nUnspecified\nNaN\nNaN\nNaN\n4417017\nStation Wagon/Sport Utility Vehicle\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.94836 40.80054)\n\n\n4\n05/01/2021\n23:03\nMANHATTAN\n10009.0\n40.726864\n-73.979910\n(40.726864, -73.97991)\nAVENUE B\nEAST 10 STREET\nNaN\n1\n0\n0\n0\n1\n0\n0\n0\nDriver Inattention/Distraction\nDriver Inattention/Distraction\nNaN\nNaN\nNaN\n4412243\nBike\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.97991 40.72686)\n\n\n\n\n\n\n\n\n# Convert 'CRASH TIME' to datetime format if it's not already in datetime\ndat2['CRASH TIME'] = pd.to_datetime(dat2['CRASH TIME'], format='%H:%M')\n\n# Extract the hour from 'CRASH TIME' and create a new column called 'CRASH HOUR'\ndat2['CRASH HOUR'] = dat2['CRASH TIME'].dt.hour\n\ndat2\n\nC:\\Users\\txx11\\mambaforge\\envs\\musa-550-fall-2023\\lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\nC:\\Users\\txx11\\mambaforge\\envs\\musa-550-fall-2023\\lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\n\n\n\n\n\n\n\n\n\nCRASH DATE\nCRASH TIME\nBOROUGH\nZIP CODE\nLATITUDE\nLONGITUDE\nLOCATION\nON STREET NAME\nCROSS STREET NAME\nOFF STREET NAME\nNUMBER OF PERSONS INJURED\nNUMBER OF PERSONS KILLED\nNUMBER OF PEDESTRIANS INJURED\nNUMBER OF PEDESTRIANS KILLED\nNUMBER OF CYCLIST INJURED\nNUMBER OF CYCLIST KILLED\nNUMBER OF MOTORIST INJURED\nNUMBER OF MOTORIST KILLED\nCONTRIBUTING FACTOR VEHICLE 1\nCONTRIBUTING FACTOR VEHICLE 2\nCONTRIBUTING FACTOR VEHICLE 3\nCONTRIBUTING FACTOR VEHICLE 4\nCONTRIBUTING FACTOR VEHICLE 5\nCOLLISION_ID\nVEHICLE TYPE CODE 1\nVEHICLE TYPE CODE 2\nVEHICLE TYPE CODE 3\nVEHICLE TYPE CODE 4\nVEHICLE TYPE CODE 5\ngeometry\nCRASH HOUR\n\n\n\n\n0\n05/01/2021\n1900-01-01 13:30:00\nMANHATTAN\n10029.0\n40.796300\n-73.938290\n(40.7963, -73.93829)\nEAST 115 STREET\n2 AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nPassing or Lane Usage Improper\nUnspecified\nNaN\nNaN\nNaN\n4412937\nBus\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.93829 40.79630)\n13\n\n\n1\n05/01/2021\n1900-01-01 17:50:00\nMANHATTAN\n10012.0\n40.720936\n-73.993805\n(40.720936, -73.993805)\nBOWERY\nSPRING STREET\nNaN\n1\n0\n0\n0\n0\n0\n1\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4412445\nSedan\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.99380 40.72094)\n17\n\n\n2\n05/01/2021\n1900-01-01 13:30:00\nMANHATTAN\n10128.0\n40.780693\n-73.946600\n(40.780693, -73.9466)\nEAST 92 STREET\n1 AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4414390\nAMBULANCE\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.94660 40.78069)\n13\n\n\n3\n05/01/2021\n1900-01-01 09:40:00\nMANHATTAN\n10026.0\n40.800537\n-73.948360\n(40.800537, -73.94836)\nNaN\nNaN\n40 WEST 115 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nBacking Unsafely\nUnspecified\nNaN\nNaN\nNaN\n4417017\nStation Wagon/Sport Utility Vehicle\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.94836 40.80054)\n9\n\n\n4\n05/01/2021\n1900-01-01 23:03:00\nMANHATTAN\n10009.0\n40.726864\n-73.979910\n(40.726864, -73.97991)\nAVENUE B\nEAST 10 STREET\nNaN\n1\n0\n0\n0\n1\n0\n0\n0\nDriver Inattention/Distraction\nDriver Inattention/Distraction\nNaN\nNaN\nNaN\n4412243\nBike\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.97991 40.72686)\n23\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n32364\n12/31/2023\n1900-01-01 23:18:00\nMANHATTAN\n10030.0\n40.819670\n-73.944240\n(40.81967, -73.94424)\n8 AVENUE\nWEST 140 STREET\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nDriver Inattention/Distraction\nNaN\nNaN\nNaN\nNaN\n4692572\nSedan\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.94424 40.81967)\n23\n\n\n32365\n12/31/2023\n1900-01-01 18:03:00\nMANHATTAN\n10039.0\n40.824130\n-73.940980\n(40.82413, -73.94098)\n8 AVENUE\nWEST 147 STREET\nNaN\n1\n0\n1\n0\n0\n0\n0\n0\nUnspecified\nNaN\nNaN\nNaN\nNaN\n4692571\nNaN\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.94098 40.82413)\n18\n\n\n32366\n12/31/2023\n1900-01-01 14:00:00\nMANHATTAN\n10028.0\n40.777890\n-73.955890\n(40.77789, -73.95589)\nNaN\nNaN\n160 EAST 84 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4692524\nSedan\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.95589 40.77789)\n14\n\n\n32367\n12/31/2023\n1900-01-01 21:34:00\nMANHATTAN\n10033.0\n40.849308\n-73.931920\n(40.849308, -73.93192)\nWEST 182 STREET\nAUDUBON AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nUnspecified\nUnspecified\nNaN\nNaN\nNaN\n4692192\nStation Wagon/Sport Utility Vehicle\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.93192 40.84931)\n21\n\n\n32368\n12/31/2023\n1900-01-01 00:38:00\nMANHATTAN\n10006.0\n40.709496\n-74.013900\n(40.709496, -74.0139)\nALBANY STREET\nWASHINGTON STREET\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nOther Vehicular\nUnspecified\nNaN\nNaN\nNaN\n4692585\nSedan\nPick-up Truck\nNaN\nNaN\nNaN\nPOINT (-74.01390 40.70950)\n0\n\n\n\n\n31042 rows × 31 columns\n\n\n\n\nfrom colorcet import fire\nimport hvplot.pandas\n\nimport holoviews as hv\nimport geoviews as gv\n\n\n\n\n\n\n\n\n\n\n\nplot1 = dat2.hvplot.points(\n    geo=True,  # Enables geographic plotting\n    x='LONGITUDE',  # Longitude for x-axis\n    y='LATITUDE',  # Latitude for y-axis\n    frame_width=800,  # Set frame width\n    frame_height=600,  # Set frame height\n    cmap=fire,  # Use the Fire colormap\n    datashade=True,  # Enable datashading for large datasets\n    crs=4326,\n    title='Manhattan Crashes'  # Set the plot title\n)\n\n# Add a dark background map\nbg = gv.tile_sources.CartoDark\n\n# Combine the background map and the plot\nbg * plot1\n\n\n\n\n\n  \n\n\n\n\n\nplot2 = dat2.hvplot.points(\n    geo=True,  # Enables geographic plotting\n    x='LONGITUDE',  # Longitude for x-axis\n    y='LATITUDE',  # Latitude for y-axis\n    frame_width=800,  # Set frame width\n    frame_height=600,  # Set frame height\n    cmap=fire,  # Use the Fire colormap\n    datashade=True,  # Enable datashading for large datasets\n    crs=4326,\n    groupby = \"CRASH HOUR\",\n    title='Manhattan Crashes'  # Set the plot title\n)\n\n# Add a dark background map\nbg = gv.tile_sources.CartoDark\n\n# Combine the background map and the plot\nbg * plot2",
    "crumbs": [
      "Analysis",
      "Part 1: Street Network with OSMnx"
    ]
  },
  {
    "objectID": "analysis/Script.html#part-3-density-map-of-crashes-due-to-passfollowing-too-closely",
    "href": "analysis/Script.html#part-3-density-map-of-crashes-due-to-passfollowing-too-closely",
    "title": "Part 1: Street Network with OSMnx",
    "section": "Part 3: Density Map of Crashes due to pass/following too closely",
    "text": "Part 3: Density Map of Crashes due to pass/following too closely\n\nimport altair as alt\n\n# Count the occurrences of each contributing factor\nfactor_counts = manhattan_crashes[\"CONTRIBUTING FACTOR VEHICLE 1\"].value_counts().reset_index()\nfactor_counts.columns = [\"Contributing Factor\", \"Frequency\"]\n\n# Select the top 10 contributing factors\ntop_10_factors = factor_counts.head(10)\n\n# Create a bar chart using Altair\nchart = alt.Chart(top_10_factors).mark_bar().encode(\n    x=alt.X(\"Frequency:Q\", title=\"Frequency\"),\n    y=alt.Y(\"Contributing Factor:N\", sort='-x', title=\"Contributing Factor\"),\n    color=alt.Color(\"Contributing Factor:N\", legend=None),  # Color by factor, no legend\n    tooltip=[\n        alt.Tooltip(\"Contributing Factor:N\", title=\"Factor\"),\n        alt.Tooltip(\"Frequency:Q\", title=\"Count\")\n    ]\n).properties(\n    title=\"Top 10 Contributing Factors for Vehicle Crashes in Manhattan (2021-2023)\",\n    width=600,\n    height=400\n)\n\n# Display the chart\nchart\n\n\n\n\n\n\n\n\nmanhattan_crashes_filtered = manhattan_crashes[\n    (manhattan_crashes[\"CONTRIBUTING FACTOR VEHICLE 1\"] == \"Passing Too Closely\") |\n    (manhattan_crashes[\"CONTRIBUTING FACTOR VEHICLE 1\"] == \"Following Too Closely\")\n]\n\nmanhattan_crashes_filtered\n\n\n\n\n\n\n\n\nCRASH DATE\nCRASH TIME\nBOROUGH\nZIP CODE\nLATITUDE\nLONGITUDE\nLOCATION\nON STREET NAME\nCROSS STREET NAME\nOFF STREET NAME\nNUMBER OF PERSONS INJURED\nNUMBER OF PERSONS KILLED\nNUMBER OF PEDESTRIANS INJURED\nNUMBER OF PEDESTRIANS KILLED\nNUMBER OF CYCLIST INJURED\nNUMBER OF CYCLIST KILLED\nNUMBER OF MOTORIST INJURED\nNUMBER OF MOTORIST KILLED\nCONTRIBUTING FACTOR VEHICLE 1\nCONTRIBUTING FACTOR VEHICLE 2\nCONTRIBUTING FACTOR VEHICLE 3\nCONTRIBUTING FACTOR VEHICLE 4\nCONTRIBUTING FACTOR VEHICLE 5\nCOLLISION_ID\nVEHICLE TYPE CODE 1\nVEHICLE TYPE CODE 2\nVEHICLE TYPE CODE 3\nVEHICLE TYPE CODE 4\nVEHICLE TYPE CODE 5\ngeometry\n\n\n\n\n5\n05/01/2021\n3:01\nMANHATTAN\n10032.0\n40.832886\n-73.944020\n(40.832886, -73.94402)\nNaN\nNaN\n555 WEST 156 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nPassing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4413557\nTaxi\nStation Wagon/Sport Utility Vehicle\nNaN\nNaN\nNaN\nPOINT (-73.94402 40.83289)\n\n\n20\n05/01/2021\n13:54\nMANHATTAN\n10036.0\n40.761300\n-73.999435\n(40.7613, -73.999435)\nNaN\nNaN\n635 WEST 42 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nPassing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4413013\nStation Wagon/Sport Utility Vehicle\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.99944 40.76130)\n\n\n22\n05/01/2021\n17:55\nMANHATTAN\n10029.0\n40.799984\n-73.944855\n(40.799984, -73.944855)\nEAST 116 STREET\nMADISON AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nPassing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4412865\nSedan\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.94486 40.79998)\n\n\n34\n05/01/2021\n9:45\nMANHATTAN\n10035.0\n40.802753\n-73.933580\n(40.802753, -73.93358)\nEAST 125 STREET\n2 AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nFollowing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4412859\nSedan\nBox Truck\nNaN\nNaN\nNaN\nPOINT (-73.93358 40.80275)\n\n\n46\n05/02/2021\n12:15\nMANHATTAN\n10037.0\n40.810024\n-73.937540\n(40.810024, -73.93754)\nNaN\nNaN\n2096 MADISON AVENUE\n0\n0\n0\n0\n0\n0\n0\n0\nFollowing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4412870\nSedan\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.93754 40.81002)\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n32333\n12/30/2023\n3:04\nMANHATTAN\n10029.0\n40.790817\n-73.942880\n(40.790817, -73.94288)\nNaN\nNaN\n231 EAST 106 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nPassing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4691754\nStation Wagon/Sport Utility Vehicle\nStation Wagon/Sport Utility Vehicle\nNaN\nNaN\nNaN\nPOINT (-73.94288 40.79082)\n\n\n32340\n12/30/2023\n17:40\nMANHATTAN\n10001.0\n40.747234\n-73.993370\n(40.747234, -73.99337)\nWEST 28 STREET\n7 AVENUE\nNaN\n1\n0\n0\n0\n0\n0\n1\n0\nFollowing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4692517\nTaxi\nBox Truck\nNaN\nNaN\nNaN\nPOINT (-73.99337 40.74723)\n\n\n32349\n12/31/2023\n22:40\nMANHATTAN\n10019.0\n40.767130\n-73.993730\n(40.76713, -73.99373)\n11 AVENUE\nWEST 52 STREET\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nFollowing Too Closely\nTurning Improperly\nNaN\nNaN\nNaN\n4693643\nStation Wagon/Sport Utility Vehicle\nBus\nNaN\nNaN\nNaN\nPOINT (-73.99373 40.76713)\n\n\n32351\n12/31/2023\n16:24\nMANHATTAN\n10027.0\n40.809310\n-73.949120\n(40.80931, -73.94912)\nNaN\nNaN\n215 WEST 125 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nPassing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4693991\nSedan\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.94912 40.80931)\n\n\n32359\n12/31/2023\n21:16\nMANHATTAN\n10011.0\n40.738250\n-74.001080\n(40.73825, -74.00108)\nNaN\nNaN\n237 WEST 13 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nPassing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4691995\nStation Wagon/Sport Utility Vehicle\nNaN\nNaN\nNaN\nNaN\nPOINT (-74.00108 40.73825)\n\n\n\n\n2789 rows × 30 columns\n\n\n\n\nAdd hour\n\n# Convert 'CRASH TIME' to datetime format if it's not already in datetime\nmanhattan_crashes_filtered['CRASH TIME'] = pd.to_datetime(manhattan_crashes_filtered['CRASH TIME'], format='%H:%M')\n\n# Extract the hour from 'CRASH TIME' and create a new column called 'CRASH HOUR'\nmanhattan_crashes_filtered['CRASH HOUR'] = manhattan_crashes_filtered['CRASH TIME'].dt.hour\n\nmanhattan_crashes_filtered\n\nC:\\Users\\txx11\\mambaforge\\envs\\musa-550-fall-2023\\lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\nC:\\Users\\txx11\\mambaforge\\envs\\musa-550-fall-2023\\lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\n\n\n\n\n\n\n\n\n\nCRASH DATE\nCRASH TIME\nBOROUGH\nZIP CODE\nLATITUDE\nLONGITUDE\nLOCATION\nON STREET NAME\nCROSS STREET NAME\nOFF STREET NAME\nNUMBER OF PERSONS INJURED\nNUMBER OF PERSONS KILLED\nNUMBER OF PEDESTRIANS INJURED\nNUMBER OF PEDESTRIANS KILLED\nNUMBER OF CYCLIST INJURED\nNUMBER OF CYCLIST KILLED\nNUMBER OF MOTORIST INJURED\nNUMBER OF MOTORIST KILLED\nCONTRIBUTING FACTOR VEHICLE 1\nCONTRIBUTING FACTOR VEHICLE 2\nCONTRIBUTING FACTOR VEHICLE 3\nCONTRIBUTING FACTOR VEHICLE 4\nCONTRIBUTING FACTOR VEHICLE 5\nCOLLISION_ID\nVEHICLE TYPE CODE 1\nVEHICLE TYPE CODE 2\nVEHICLE TYPE CODE 3\nVEHICLE TYPE CODE 4\nVEHICLE TYPE CODE 5\ngeometry\nCRASH HOUR\n\n\n\n\n5\n05/01/2021\n1900-01-01 03:01:00\nMANHATTAN\n10032.0\n40.832886\n-73.944020\n(40.832886, -73.94402)\nNaN\nNaN\n555 WEST 156 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nPassing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4413557\nTaxi\nStation Wagon/Sport Utility Vehicle\nNaN\nNaN\nNaN\nPOINT (-73.94402 40.83289)\n3\n\n\n20\n05/01/2021\n1900-01-01 13:54:00\nMANHATTAN\n10036.0\n40.761300\n-73.999435\n(40.7613, -73.999435)\nNaN\nNaN\n635 WEST 42 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nPassing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4413013\nStation Wagon/Sport Utility Vehicle\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.99944 40.76130)\n13\n\n\n22\n05/01/2021\n1900-01-01 17:55:00\nMANHATTAN\n10029.0\n40.799984\n-73.944855\n(40.799984, -73.944855)\nEAST 116 STREET\nMADISON AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nPassing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4412865\nSedan\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.94486 40.79998)\n17\n\n\n34\n05/01/2021\n1900-01-01 09:45:00\nMANHATTAN\n10035.0\n40.802753\n-73.933580\n(40.802753, -73.93358)\nEAST 125 STREET\n2 AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nFollowing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4412859\nSedan\nBox Truck\nNaN\nNaN\nNaN\nPOINT (-73.93358 40.80275)\n9\n\n\n46\n05/02/2021\n1900-01-01 12:15:00\nMANHATTAN\n10037.0\n40.810024\n-73.937540\n(40.810024, -73.93754)\nNaN\nNaN\n2096 MADISON AVENUE\n0\n0\n0\n0\n0\n0\n0\n0\nFollowing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4412870\nSedan\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.93754 40.81002)\n12\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n32333\n12/30/2023\n1900-01-01 03:04:00\nMANHATTAN\n10029.0\n40.790817\n-73.942880\n(40.790817, -73.94288)\nNaN\nNaN\n231 EAST 106 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nPassing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4691754\nStation Wagon/Sport Utility Vehicle\nStation Wagon/Sport Utility Vehicle\nNaN\nNaN\nNaN\nPOINT (-73.94288 40.79082)\n3\n\n\n32340\n12/30/2023\n1900-01-01 17:40:00\nMANHATTAN\n10001.0\n40.747234\n-73.993370\n(40.747234, -73.99337)\nWEST 28 STREET\n7 AVENUE\nNaN\n1\n0\n0\n0\n0\n0\n1\n0\nFollowing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4692517\nTaxi\nBox Truck\nNaN\nNaN\nNaN\nPOINT (-73.99337 40.74723)\n17\n\n\n32349\n12/31/2023\n1900-01-01 22:40:00\nMANHATTAN\n10019.0\n40.767130\n-73.993730\n(40.76713, -73.99373)\n11 AVENUE\nWEST 52 STREET\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nFollowing Too Closely\nTurning Improperly\nNaN\nNaN\nNaN\n4693643\nStation Wagon/Sport Utility Vehicle\nBus\nNaN\nNaN\nNaN\nPOINT (-73.99373 40.76713)\n22\n\n\n32351\n12/31/2023\n1900-01-01 16:24:00\nMANHATTAN\n10027.0\n40.809310\n-73.949120\n(40.80931, -73.94912)\nNaN\nNaN\n215 WEST 125 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nPassing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4693991\nSedan\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.94912 40.80931)\n16\n\n\n32359\n12/31/2023\n1900-01-01 21:16:00\nMANHATTAN\n10011.0\n40.738250\n-74.001080\n(40.73825, -74.00108)\nNaN\nNaN\n237 WEST 13 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nPassing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4691995\nStation Wagon/Sport Utility Vehicle\nNaN\nNaN\nNaN\nNaN\nPOINT (-74.00108 40.73825)\n21\n\n\n\n\n2789 rows × 31 columns\n\n\n\n\nimport folium\nfrom folium.plugins import FastMarkerCluster\n\n\n# Ensure the data contains valid longitude and latitude values\nmanhattan_crashes_filtered = manhattan_crashes_filtered.dropna(subset=['LONGITUDE', 'LATITUDE'])\n\n# Create a base map centered around Manhattan\nm = folium.Map(location=[40.7580, -73.9851], zoom_start=12, tiles='CartoDB dark_matter')\n\n# Add crash points to the map using FastMarkerCluster\nFastMarkerCluster(data=manhattan_crashes_filtered[['LATITUDE', 'LONGITUDE']].values.tolist()).add_to(m)\n\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook",
    "crumbs": [
      "Analysis",
      "Part 1: Street Network with OSMnx"
    ]
  },
  {
    "objectID": "analysis/Script.html#part2-congestion-prediction",
    "href": "analysis/Script.html#part2-congestion-prediction",
    "title": "Part 1: Street Network with OSMnx",
    "section": "Part2: Congestion Prediction",
    "text": "Part2: Congestion Prediction\n\nIntroduction\nThe purpose of this project is to design a predictive model for traffic congestion using a set of environmental and contextual features, including temperature, precipitation, wind speed, the occurrence of events, and whether it is a weekend. Traffic congestion is a significant issue in urban areas, impacting commute times, air quality, and overall productivity. By leveraging these variables, the model aims to understand the factors influencing traffic patterns and provide accurate predictions of traffic counts. Such a model could be instrumental in improving traffic management systems, informing infrastructure planning, and helping commuters make more informed decisions. The project seeks to demonstrate the feasibility of using readily available data to address real-world urban challenges.\nA traffic prediction model has significant potential applications in optimizing traffic light systems to improve traffic flow and reduce congestion. By accurately predicting traffic counts based on environmental factors, events, and time-related variables, the model could serve as a critical input for adaptive traffic light control systems. For instance, the model could help dynamically adjust traffic light timings based on anticipated traffic volumes at specific intersections. During periods of high predicted traffic, longer green light durations could be allocated to heavily congested routes, while during low-traffic periods, shorter cycles could minimize unnecessary delays. This would ensure a more efficient allocation of green time, reducing wait times, fuel consumption, and emissions caused by idling vehicles.\nAdditionally, the model could be integrated into intelligent traffic management systems that coordinate traffic lights across multiple intersections. By predicting traffic patterns in advance, the system could optimize signal synchronization to create “green waves,” allowing vehicles to travel through a series of intersections without stopping. This approach could be particularly useful in urban areas with high traffic density, where poor signal coordination often exacerbates congestion. Furthermore, during special events or adverse weather conditions, the model could help traffic authorities proactively adjust signal timings to handle anticipated surges in traffic, minimizing disruptions. Overall, the integration of traffic prediction models into traffic light optimization systems has the potential to enhance urban mobility, reduce congestion, and improve the overall efficiency of transportation networks.\n\n\nImporting The NYC Weather Data\n\nTime: 05-01-2021 to 05-10-2021\n\n\nData Source:\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Step 1: Load the Data\n# Load the dataset directly from the file\nweather_data = pd.read_csv(\"weather_Panel_NY.csv\")\n\n# Convert the 'interval60' column to datetime format\nweather_data['interval60'] = pd.to_datetime(weather_data['interval60'])\n\n# Step 2: Data Cleaning and Processing\n# Replace invalid or missing temperature values (if any)\nweather_data['Temperature'] = weather_data['Temperature'].apply(lambda x: 42 if x == 0 else x)\n\n# Step 3: Define Plot Themes\ndef plot_theme(ax):\n    \"\"\"Apply a consistent theme to plots.\"\"\"\n    ax.set_title(ax.get_title(), fontsize=14, fontweight='bold')\n    ax.set_xlabel(ax.get_xlabel(), fontsize=12)\n    ax.set_ylabel(ax.get_ylabel(), fontsize=12)\n    ax.tick_params(axis='x', labelsize=10, rotation=45)\n    ax.tick_params(axis='y', labelsize=10)\n    ax.grid(color=\"#eff3ff\", linestyle='-', linewidth=0.5)\n    ax.set_facecolor(\"white\")\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n\n# Step 4: Create Subplots\n# Create a figure with 3 subplots (one for each variable)\nfig, axs = plt.subplots(3, 1, figsize=(12, 14), constrained_layout=True)\n\n# Plot 1: Precipitation\nsns.lineplot(data=weather_data, x='interval60', y='Precipitation', ax=axs[0], color='#1f77b4')\naxs[0].set_title(\"Precipitation Over Time\")\naxs[0].set_xlabel(\"Date and Time\")\naxs[0].set_ylabel(\"Precipitation (inches)\")\nplot_theme(axs[0])\n\n# Plot 2: Wind Speed\nsns.lineplot(data=weather_data, x='interval60', y='Wind_Speed', ax=axs[1], color='#ff7f0e')\naxs[1].set_title(\"Wind Speed Over Time\")\naxs[1].set_xlabel(\"Date and Time\")\naxs[1].set_ylabel(\"Wind Speed (mph)\")\nplot_theme(axs[1])\n\n# Plot 3: Temperature\nsns.lineplot(data=weather_data, x='interval60', y='Temperature', ax=axs[2], color='#2ca02c')\naxs[2].set_title(\"Temperature Over Time\")\naxs[2].set_xlabel(\"Date and Time\")\naxs[2].set_ylabel(\"Temperature (°F)\")\nplot_theme(axs[2])\n\n# Add a main title for the entire figure\nfig.suptitle(\"Weather Data - New York City (May 2021)\", fontsize=16, fontweight='bold')\n\n# Step 5: Show and Save the Plot\n# Display the plot\nplt.show()\n\n# Optionally save the figure as an image file\nfig.savefig(\"weather_data_plot.png\", dpi=300)",
    "crumbs": [
      "Analysis",
      "Part 1: Street Network with OSMnx"
    ]
  },
  {
    "objectID": "analysis/Script.html#exploratory-data-analysis",
    "href": "analysis/Script.html#exploratory-data-analysis",
    "title": "Part 1: Street Network with OSMnx",
    "section": "Exploratory Data Analysis:",
    "text": "Exploratory Data Analysis:\nTraffic Count Across the Time:\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Step 1: Load the Data\n# Load the dataset\ndata = pd.read_csv(\"data_filtered.csv\")\n\n# Step 2: Preprocess the Data\n# Extract the columns with traffic counts (time intervals)\ntraffic_columns = data.columns[7:]  # Assuming traffic data starts from the 8th column\n\n# Add a new column for total traffic count per row\ndata['Total_Traffic'] = data[traffic_columns].sum(axis=1)\n\n# Aggregate traffic counts by date\ntraffic_by_date = data.groupby(\"Date\")['Total_Traffic'].sum().reset_index()\n\n# Convert the 'Date' column to datetime format for proper sorting\ntraffic_by_date['Date'] = pd.to_datetime(traffic_by_date['Date'])\n\n# Sort by date\ntraffic_by_date = traffic_by_date.sort_values(by='Date')\n\n# Step 3: Plot the Data\n# Set the style of the plot\nsns.set(style=\"whitegrid\")\n\n# Create the plot\nplt.figure(figsize=(12, 6))\nplt.plot(traffic_by_date['Date'], traffic_by_date['Total_Traffic'], color='black', linewidth=1)\n\n# Add labels and title\nplt.title(\"Number of Trips Over Time\", fontsize=14, fontweight='bold')\nplt.xlabel(\"Date\", fontsize=12)\nplt.ylabel(\"Number of Trips\", fontsize=12)\n\n# Rotate x-axis labels for better readability\nplt.xticks(rotation=45)\n\n# Add gridlines\nplt.grid(visible=True, linestyle='--', alpha=0.5)\n\n# Show the plot\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nTraffic Count Comparing Weekends and Weekdays:\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\n\n# Step 1: Load the Data\ndata = pd.read_csv(\"data_filtered.csv\")\n\n# Step 2: Preprocess the Data\n# Extract time interval columns\ntraffic_columns = data.columns[7:]  # Assuming traffic data starts from the 8th column\n\n# Add a column for total traffic during each hour\ndata['Total_Traffic'] = data[traffic_columns].sum(axis=1)\n\n# Convert the 'Date' column to datetime format\ndata['Date'] = pd.to_datetime(data['Date'])\n\n# Add a column for the day of the week\ndata['Day_of_Week'] = data['Date'].dt.dayofweek\n\n# Add a column to classify as 'Weekday' or 'Weekend'\ndata['Weekend'] = data['Day_of_Week'].apply(lambda x: 'Weekend' if x &gt;= 5 else 'Weekday')\n\n# Melt the time interval columns into a long format\nhourly_data = pd.melt(data, \n                      id_vars=['Date', 'Weekend'], \n                      value_vars=traffic_columns, \n                      var_name='Hour', \n                      value_name='Traffic_Count')\n\n# Clean the 'Hour' column to extract hour values\nhourly_data['Hour'] = hourly_data['Hour'].str.extract(r'X(\\d+)\\.').astype(int)\n\n# Step 3: Aggregate the Data\n# Group by hour and weekend/weekday\nhourly_traffic = hourly_data.groupby(['Hour', 'Weekend'])['Traffic_Count'].sum().reset_index()\n\n# Step 4: Plot the Data\nsns.set(style=\"whitegrid\")\n\nplt.figure(figsize=(12, 6))\n\n# Plot the data with explicit color mapping\nsns.lineplot(data=hourly_traffic, x='Hour', y='Traffic_Count', hue='Weekend', \n             palette={'Weekday': 'red', 'Weekend': 'blue'})  # Use blue for Weekend\n\n# Add labels and title\nplt.title(\"Traffic Counts by Hour: Weekday vs Weekend\", fontsize=14, fontweight='bold')\nplt.xlabel(\"Hour\", fontsize=12)\nplt.ylabel(\"Traffic Counts\", fontsize=12)\n\n# Fix the legend to correctly match the colors\nplt.legend(title=\"Traffic Type\", labels=[\"Weekday (Red)\", \"Weekend (Blue)\"], loc=\"upper right\")\n\n# Show the plot\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nTraffic Count Comparing Streets:\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Step 1: Load the Data\ndata = pd.read_csv(\"data_filtered.csv\")\n\n# Step 2: Preprocess the Data\n# Extract traffic columns\ntraffic_columns = data.columns[7:]  # Assuming traffic data starts from the 8th column\n\n# Add a column for total traffic across all time intervals\ndata['Total_Traffic'] = data[traffic_columns].sum(axis=1)\n\n# Step 3: Aggregate Traffic by Roadway Name\ntraffic_by_roadway = data.groupby('Roadway.Name')['Total_Traffic'].sum().reset_index()\n\n# Sort by total traffic in descending order for better visualization\ntraffic_by_roadway = traffic_by_roadway.sort_values(by='Total_Traffic', ascending=False)\n\n# Step 4: Plot the Data\nsns.set(style=\"whitegrid\")\n\nplt.figure(figsize=(12, 6))\nsns.barplot(data=traffic_by_roadway, x='Total_Traffic', y='Roadway.Name', palette=\"viridis\")\n\n# Add labels and title\nplt.title(\"Traffic Count by Roadway Name\", fontsize=14, fontweight='bold')\nplt.xlabel(\"Total Traffic Count\", fontsize=12)\nplt.ylabel(\"Roadway Name\", fontsize=12)\n\n# Show the plot\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nData Processing:\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\n# Step 1: Load the Datasets\n# Load traffic data\ntraffic_data = pd.read_csv(\"data_filtered.csv\")\n\n# Load weather data\nweather_data = pd.read_csv(\"weather_Panel_NY.csv\")\n\n# Step 2: Preprocess the Traffic Data\n# Convert 'Date' column to datetime\ntraffic_data['Date'] = pd.to_datetime(traffic_data['Date'])\n\n# Reshape the traffic data from wide to long format\nhourly_columns = [col for col in traffic_data.columns if 'X' in col]\ntraffic_hourly = traffic_data.melt(\n    id_vars=['Date', 'SegmentID', 'Roadway.Name', 'From', 'To', 'Direction'], \n    value_vars=hourly_columns, \n    var_name='Hour', \n    value_name='Traffic_Count'\n)\n\n# Extract the hour from the column names (e.g., \"X12.00.1.00.AM\" to \"00:00\")\ntraffic_hourly['Hour'] = traffic_hourly['Hour'].str.extract(r'X(\\d+)').astype(int) - 1\n\n# Combine Date and Hour into a single timestamp column\ntraffic_hourly['Timestamp'] = traffic_hourly['Date'] + pd.to_timedelta(traffic_hourly['Hour'], unit='h')\n\n# Drop unnecessary columns\ntraffic_hourly = traffic_hourly[['Timestamp', 'Traffic_Count']]\n\nAdd the ‘is_weekend’ Feature\n\n# Step 3: Add the 'is_weekend' Feature\n# Extract day of the week from the timestamp\ntraffic_hourly['Day_of_Week'] = traffic_hourly['Timestamp'].dt.dayofweek  # Monday=0, Sunday=6\ntraffic_hourly['is_weekend'] = traffic_hourly['Day_of_Week'].apply(lambda x: 1 if x &gt;= 5 else 0)\n\n# Step 4: Preprocess the Weather Data\n# Convert 'interval60' to datetime\nweather_data['interval60'] = pd.to_datetime(weather_data['interval60'])\n\n# Step 5: Merge the Datasets\n# Merge traffic and weather data on the timestamp\ncombined_data = pd.merge(traffic_hourly, weather_data, left_on='Timestamp', right_on='interval60', how='inner')\n\n# Drop unnecessary columns\ncombined_data = combined_data.drop(columns=['interval60', 'Day_of_Week'])\n\nAdd the Holiday/Event Dates Feature\n\n# Step 1: Define the Holiday/Event Dates\n# List of holiday or event dates\nholiday_event_dates = [\n    \"2021-05-01\",  # International Workers' Day\n    \"2021-05-05\",  # Cinco de Mayo\n    \"2021-05-09\"   # Mother's Day\n]\n\n# Step 2: Add the 'is_holiday_or_event' Variable\n# Convert the holiday_event_dates to datetime for comparison\nholiday_event_dates = pd.to_datetime(holiday_event_dates)\n\n# Add a new column to indicate whether the date is a holiday or event\ntraffic_hourly['is_holiday_or_event'] = traffic_hourly['Timestamp'].dt.date.isin(holiday_event_dates.date).astype(int)\n\nMaking the model\n\n# Step 3: Merge with Weather Data\n# (Assume weather data preprocessing and merging steps as before)\ncombined_data = pd.merge(traffic_hourly, weather_data, left_on='Timestamp', right_on='interval60', how='inner')\n\n# Step 4: Feature Selection\n# Add 'is_holiday_or_event' to the features\nX = combined_data[['Temperature', 'Precipitation', 'Wind_Speed', 'is_weekend', 'is_holiday_or_event']]\ny = combined_data['Traffic_Count']\n\n# Step 5: Train-Test Split and Model Training\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = RandomForestRegressor(random_state=42)\nmodel.fit(X_train, y_train)\n\n# Step 6: Evaluate the Model\ny_pred = model.predict(X_test)\n\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nfrom tabulate import tabulate  # Install this with `pip install tabulate`\n\n# Step 7: Create a DataFrame to Display Actual, Predicted, MAE, and MSE for Each Row\nresults_df = pd.DataFrame({\n    'Actual Value': y_test.values,\n    'Predicted Value': y_pred\n})\n\n# Calculate Absolute Error and Squared Error for each row\nresults_df['Absolute Error'] = abs(results_df['Actual Value'] - results_df['Predicted Value'])\nresults_df['Squared Error'] = (results_df['Actual Value'] - results_df['Predicted Value']) ** 2\n\n# Add columns for MAE and MSE (optional, as they are global metrics)\nresults_df['MAE'] = mae\nresults_df['MSE'] = mse\n\n# Round values for better readability\nresults_df = results_df.round({'Actual Value': 2, 'Predicted Value': 2, 'Absolute Error': 2, 'Squared Error': 2, 'MAE': 2, 'MSE': 2})\n\n# Display the table using tabulate for a clean format\ntable = tabulate(results_df.head(10), headers='keys', tablefmt='pretty')\nprint(table)\n\nprint(f\"Model Evaluation Metrics:\")\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"R-squared (R2): {r2}\")\n\n+---+--------------+-----------------+----------------+---------------+--------+---------+\n|   | Actual Value | Predicted Value | Absolute Error | Squared Error |  MAE   |   MSE   |\n+---+--------------+-----------------+----------------+---------------+--------+---------+\n| 0 |     52.0     |     212.31      |     160.31     |   25697.91    | 186.21 | 67145.7 |\n| 1 |     3.0      |     222.72      |     219.72     |   48278.99    | 186.21 | 67145.7 |\n| 2 |     23.0     |     222.72      |     199.72     |    39890.0    | 186.21 | 67145.7 |\n| 3 |    119.0     |      190.6      |      71.6      |    5127.27    | 186.21 | 67145.7 |\n| 4 |    534.0     |     212.31      |     321.69     |   103487.25   | 186.21 | 67145.7 |\n| 5 |    724.0     |     223.89      |     500.11     |   250110.57   | 186.21 | 67145.7 |\n| 6 |    192.0     |     163.73      |     28.27      |    799.45     | 186.21 | 67145.7 |\n| 7 |    343.0     |     196.71      |     146.29     |   21399.55    | 186.21 | 67145.7 |\n| 8 |     24.0     |     212.31      |     188.31     |   35459.02    | 186.21 | 67145.7 |\n| 9 |    417.0     |     203.44      |     213.56     |   45609.55    | 186.21 | 67145.7 |\n+---+--------------+-----------------+----------------+---------------+--------+---------+\nModel Evaluation Metrics:\nMean Absolute Error (MAE): 186.21046236583155\nMean Squared Error (MSE): 67145.69644950841\nR-squared (R2): 0.0006557517971068627\n\n\nThe model’s performance, as reflected by the evaluation metrics, indicates significant limitations. The Mean Absolute Error (MAE) of 186.21 suggests that, on average, predictions deviate from actual values by 186 traffic counts, which may be substantial depending on the scale of traffic. The Mean Squared Error (MSE) of 67,145 highlights large errors, particularly influenced by extreme outliers, given the quadratic nature of MSE. Most concerning is the R-squared (R²) value of 0.00065, which indicates that the model explains less than 0.1% of the variance in the data, essentially performing no better than a simple mean-based prediction. This suggests the model fails to capture meaningful patterns in the data, likely due to insufficient features, inadequate complexity, or a mismatch between the data and the model’s assumptions.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Calculate residuals\nresiduals = y_test - y_pred\n\n# Plot residuals\nplt.figure(figsize=(8, 6))\nsns.scatterplot(x=y_pred, y=residuals, alpha=0.6)\nplt.axhline(y=0, color='r', linestyle='--')\nplt.title(\"Residual Plot\")\nplt.xlabel(\"Predicted Traffic Count\")\nplt.ylabel(\"Residuals (Actual - Predicted)\")\nplt.show()\n\n\n\n\n\n\n\n\nThe residual plot indicates that the model generally performs well, with residuals centered around zero and no clear non-linear patterns, suggesting it captures the general relationship between predictors and traffic counts. However, the increasing spread of residuals with larger predicted values highlights heteroscedasticity, meaning the model’s errors grow with higher traffic counts, reducing reliability for these predictions. Additionally, the presence of significant outliers (residuals exceeding 1000) suggests that the model struggles to account for unusual traffic conditions, potentially due to missing features such as accidents or events. A slight tendency to underpredict higher traffic counts is also observed, as evidenced by the clustering of residuals below zero.\n\n# Plot actual vs predicted\nplt.figure(figsize=(8, 6))\nsns.scatterplot(x=y_test, y=y_pred, alpha=0.6)\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='r', linestyle='--')\nplt.title(\"Actual vs Predicted Traffic Counts\")\nplt.xlabel(\"Actual Traffic Count\")\nplt.ylabel(\"Predicted Traffic Count\")\nplt.show()\n\n\n\n\n\n\n\n\nThe scatter plot compares actual traffic counts (x-axis) to predicted traffic counts (y-axis) for a Random Forest model, with the red dashed line representing the ideal scenario where predictions perfectly match actual values. The plot reveals several key insights regarding the model’s performance and limitations.\nFirst, the majority of predicted values cluster within a narrow range (approximately 200–400), regardless of the actual traffic counts. This indicates that the model struggles to capture variability in traffic counts, particularly for higher values, leading to underprediction for actual traffic counts above 500. The lack of points along the diagonal line for larger actual counts highlights this systematic error. Additionally, the spread of points becomes more pronounced as actual traffic counts increase, reflecting heteroscedasticity, where prediction errors grow with larger traffic counts. This suggests that the model’s performance deteriorates for higher traffic levels, potentially due to insufficient features to explain variability at these extremes.\nThe model performs reasonably well for lower traffic counts, as many predictions fall close to the diagonal line in this range. However, the consistent over-concentration of predicted values between 200 and 400 suggests that the model may be biased toward predicting average traffic counts, a limitation likely stemming from the training process or insufficient feature diversity.\n\n# Plot distribution of residuals\nplt.figure(figsize=(8, 6))\nsns.histplot(residuals, kde=True, bins=30, color='blue')\nplt.title(\"Distribution of Residuals\")\nplt.xlabel(\"Residuals (Actual - Predicted)\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\n\n\n\n\n\n\n\nThe residual distribution is right-skewed, with most residuals concentrated between -250 and 250, indicating that the Random Forest model performs reasonably well for the majority of predictions. However, the long positive tail reveals significant underprediction for higher traffic counts, suggesting the model struggles with variability in extreme conditions. This aligns with earlier observations of heteroscedasticity, where prediction errors increase with larger traffic counts. Additionally, extreme residuals exceeding 1000 indicate outliers or unaccounted factors, such as events or anomalies. To improve, consider applying a log transformation to stabilize variance, adding relevant features (e.g., time, weather), and exploring advanced models like Gradient Boosting to better capture complex patterns.\n\nLimitations\nDespite its intent, the model faces several limitations that hinder its performance. The low R-squared value indicates that the features used explain only a negligible portion of the variance in traffic counts, suggesting that other critical factors influencing traffic, such as time of day, road capacity, historical traffic trends, or localized disruptions, are missing from the model. Additionally, the model exhibits heteroscedasticity, with residual errors increasing for higher traffic counts, indicating that it struggles to capture variability in extreme conditions. This issue is further compounded by outliers, such as unusual traffic spikes during events or accidents, which the model fails to predict accurately. Moreover, the features included may not fully capture the non-linear and complex relationships between environmental conditions and traffic patterns, limiting the model’s ability to generalize to diverse scenarios. These limitations highlight the need for more comprehensive data and advanced modeling techniques to improve predictive accuracy.\n\n\nConclusion\nIn conclusion, while the project demonstrates the potential of using environmental and contextual features to predict traffic congestion, the results indicate that the current model is insufficient for accurate and reliable predictions. The significant errors and low explanatory power suggest that the complexity of traffic patterns requires a more robust approach. Future efforts should focus on incorporating additional features, such as time of day, historical traffic data, and real-time factors like road closures or accidents. Advanced modeling techniques, such as Gradient Boosting Machines or Neural Networks, could also be explored to better capture non-linear relationships and interactions between variables. Despite its limitations, this project serves as a valuable starting point for understanding the factors influencing traffic congestion and highlights the importance of data-driven approaches in addressing urban mobility challenges.",
    "crumbs": [
      "Analysis",
      "Part 1: Street Network with OSMnx"
    ]
  },
  {
    "objectID": "hello.html",
    "href": "hello.html",
    "title": "Quarto Basics",
    "section": "",
    "text": "For a demonstration of a line plot on a polar axis, see Figure 1.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: A line plot on a polar axis"
  },
  {
    "objectID": "hello.html#polar-axis",
    "href": "hello.html#polar-axis",
    "title": "Quarto Basics",
    "section": "",
    "text": "For a demonstration of a line plot on a polar axis, see Figure 1.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: A line plot on a polar axis"
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Mapping Crash Data and Predicting Traffic Volume in New York City Using OSMnx and Machine Learning",
    "section": "",
    "text": "This webpage is dedicated to presenting our final project for class MUSA 550: Geospatial Data Science in Python (Fall 2024).\nYou can learn more information on the class website.\nThis project is the culmination of work undertaken in a course that bridges the power of data science with urban planning. The course equips students with the skills to transform raw data into actionable insights, employing the latest Python tools and a structured “pipeline” approach. Through real-world case studies, it provides hands-on experience in gathering, analyzing, and visualizing data, with a final focus on crafting compelling, interactive narratives. Key modules cover everything from exploratory data science and geospatial analysis to advanced machine learning applications, laying a strong foundation for innovative urban research.\nUrban mobility challenges are a pressing issue for cities worldwide, and Philadelphia is no exception. Like many metropolitan areas, it faces significant traffic congestion, particularly during peak hours. This congestion is exacerbated by an aging traffic signal system that relies on static timing plans, incapable of adapting to real-time conditions. The consequences are far-reaching: increased travel times, higher emissions, and frustrated commuters. Addressing these challenges requires a forward-thinking approach, combining modern technology and data-driven decision-making.\n\n\n\nImage: Traffic in University of Pennsylvania. Source: Penn Today\n\n\nOur project tackles these issues by exploring how adaptive traffic signal optimization can enhance urban mobility. Using New York City crash data as a case study, we apply machine learning tools and geospatial analysis to model traffic volume and patterns. With real-time traffic data and historical insights, we demonstrate the potential of dynamic traffic signal systems to alleviate congestion, improve safety, and reduce environmental impacts. By leveraging tools such as OSMnx and Python-based machine learning, we aim to contribute to the broader conversation on sustainable and efficient urban transportation systems.\nWe invite you to explore our findings, methodologies, and visualizations that highlight how data science can transform the way cities address traffic management and urban mobility challenges.\n\n\n\n\n\n\nImportant\n\n\n\n辣椒炒肉!",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "analysis/Script.html#part-1-street-network-with-osmnx",
    "href": "analysis/Script.html#part-1-street-network-with-osmnx",
    "title": "Part 1: Street Network with OSMnx",
    "section": "",
    "text": "# The usual imports\nimport altair as alt\nimport geopandas as gpd\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n\n# Show all columns in dataframes\npd.options.display.max_columns = 999\n\n# Hide warnings due to issue in shapely package \n# See: https://github.com/shapely/shapely/issues/1345\nnp.seterr(invalid=\"ignore\");\nimport osmnx as ox\n\nNYC = gpd.read_file(\"new-york-city-boroughs.geojson\")\nNYC_M = NYC[NYC[\"name\"] == \"Manhattan\"]\n\nNYC_M\n\n\n\n\n\n\n\n\nname\ncartodb_id\ncreated_at\nupdated_at\ngeometry\n\n\n\n\n3\nManhattan\n4\n2013-03-09 02:42:03.692000+00:00\n2013-03-09 02:42:03.989000+00:00\nMULTIPOLYGON (((-74.01093 40.68449, -74.01193 ...\n\n\n\n\n\n\n\n\n\n\n\n# Project it to Web Mercator first and plot\nax = NYC_M.to_crs(epsg=4326).plot(facecolor=\"none\", edgecolor=\"black\")\nax.set_axis_off()\n\n\n\n\n\n\n\n\n\n\n\n\n# Define your polygon boundary (replace with your actual polygon)\n# For example, if you have a GeoDataFrame with your area boundary:\npolygon = NYC_M.unary_union  \n\n# Create a street network graph\nG = ox.graph_from_polygon(polygon, network_type='drive')\n\n# Convert graph edges to a GeoDataFrame\nedges_gdf = ox.graph_to_gdfs(G, nodes=False, edges=True)\n\n# Display the first few rows of the GeoDataFrame\nprint(edges_gdf.head())\n\n# Plot the edges GeoDataFrame\nfig, ax = plt.subplots(figsize=(20, 20))\nedges_gdf.plot(ax=ax, linewidth=1, edgecolor='black')\nplt.show()\n\n                                                 osmid               name  \\\nu        v        key                                                       \n42421728 42435337 0                          195743153  Central Park West   \n         42421731 0    [420625565, 420625573, 5668966]  West 106th Street   \n         42432736 0           [1271523197, 1271523198]  Central Park West   \n42421731 42437916 0                            5671485   Manhattan Avenue   \n         42432737 0                          195743186   Manhattan Avenue   \n\n                           highway maxspeed  oneway reversed   length  \\\nu        v        key                                                   \n42421728 42435337 0      secondary   25 mph   False     True   85.345   \n         42421731 0      secondary      NaN   False    False  138.033   \n         42432736 0      secondary   25 mph   False    False   86.275   \n42421731 42437916 0    residential      NaN   False     True   86.149   \n         42432737 0    residential      NaN   False    False   85.968   \n\n                                                                geometry  \\\nu        v        key                                                      \n42421728 42435337 0    LINESTRING (-73.96004 40.79805, -73.96011 40.7...   \n         42421731 0    LINESTRING (-73.96004 40.79805, -73.96017 40.7...   \n         42432736 0    LINESTRING (-73.96004 40.79805, -73.95997 40.7...   \n42421731 42437916 0    LINESTRING (-73.96147 40.79865, -73.96154 40.7...   \n         42432737 0    LINESTRING (-73.96147 40.79865, -73.96140 40.7...   \n\n                      lanes  ref access bridge tunnel width junction  \nu        v        key                                                 \n42421728 42435337 0     NaN  NaN    NaN    NaN    NaN   NaN      NaN  \n         42421731 0     NaN  NaN    NaN    NaN    NaN   NaN      NaN  \n         42432736 0     NaN  NaN    NaN    NaN    NaN   NaN      NaN  \n42421731 42437916 0     NaN  NaN    NaN    NaN    NaN   NaN      NaN  \n         42432737 0     NaN  NaN    NaN    NaN    NaN   NaN      NaN  \n\n\n\n\n\n\n\n\n\n\n\n\n\n# Load data into a pandas DataFrame\ndata = pd.read_csv(\"Motor_Vehicle_Collisions_Crashes.csv\")\n\n\ndata\n\n\n\n\n\n\n\n\nCRASH DATE\nCRASH TIME\nBOROUGH\nZIP CODE\nLATITUDE\nLONGITUDE\nLOCATION\nON STREET NAME\nCROSS STREET NAME\nOFF STREET NAME\nNUMBER OF PERSONS INJURED\nNUMBER OF PERSONS KILLED\nNUMBER OF PEDESTRIANS INJURED\nNUMBER OF PEDESTRIANS KILLED\nNUMBER OF CYCLIST INJURED\nNUMBER OF CYCLIST KILLED\nNUMBER OF MOTORIST INJURED\nNUMBER OF MOTORIST KILLED\nCONTRIBUTING FACTOR VEHICLE 1\nCONTRIBUTING FACTOR VEHICLE 2\nCONTRIBUTING FACTOR VEHICLE 3\nCONTRIBUTING FACTOR VEHICLE 4\nCONTRIBUTING FACTOR VEHICLE 5\nCOLLISION_ID\nVEHICLE TYPE CODE 1\nVEHICLE TYPE CODE 2\nVEHICLE TYPE CODE 3\nVEHICLE TYPE CODE 4\nVEHICLE TYPE CODE 5\n\n\n\n\n0\n05/01/2021\n13:30\nMANHATTAN\n10029.0\n40.796300\n-73.938290\n(40.7963, -73.93829)\nEAST 115 STREET\n2 AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nPassing or Lane Usage Improper\nUnspecified\nNaN\nNaN\nNaN\n4412937\nBus\nSedan\nNaN\nNaN\nNaN\n\n\n1\n05/01/2021\n17:50\nMANHATTAN\n10012.0\n40.720936\n-73.993805\n(40.720936, -73.993805)\nBOWERY\nSPRING STREET\nNaN\n1\n0\n0\n0\n0\n0\n1\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4412445\nSedan\nSedan\nNaN\nNaN\nNaN\n\n\n2\n05/01/2021\n13:30\nMANHATTAN\n10128.0\n40.780693\n-73.946600\n(40.780693, -73.9466)\nEAST 92 STREET\n1 AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4414390\nAMBULANCE\nSedan\nNaN\nNaN\nNaN\n\n\n3\n05/01/2021\n9:40\nMANHATTAN\n10026.0\n40.800537\n-73.948360\n(40.800537, -73.94836)\nNaN\nNaN\n40 WEST 115 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nBacking Unsafely\nUnspecified\nNaN\nNaN\nNaN\n4417017\nStation Wagon/Sport Utility Vehicle\nNaN\nNaN\nNaN\nNaN\n\n\n4\n05/01/2021\n23:03\nMANHATTAN\n10009.0\n40.726864\n-73.979910\n(40.726864, -73.97991)\nAVENUE B\nEAST 10 STREET\nNaN\n1\n0\n0\n0\n1\n0\n0\n0\nDriver Inattention/Distraction\nDriver Inattention/Distraction\nNaN\nNaN\nNaN\n4412243\nBike\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n32364\n12/31/2023\n23:18\nMANHATTAN\n10030.0\n40.819670\n-73.944240\n(40.81967, -73.94424)\n8 AVENUE\nWEST 140 STREET\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nDriver Inattention/Distraction\nNaN\nNaN\nNaN\nNaN\n4692572\nSedan\nNaN\nNaN\nNaN\nNaN\n\n\n32365\n12/31/2023\n18:03\nMANHATTAN\n10039.0\n40.824130\n-73.940980\n(40.82413, -73.94098)\n8 AVENUE\nWEST 147 STREET\nNaN\n1\n0\n1\n0\n0\n0\n0\n0\nUnspecified\nNaN\nNaN\nNaN\nNaN\n4692571\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n32366\n12/31/2023\n14:00\nMANHATTAN\n10028.0\n40.777890\n-73.955890\n(40.77789, -73.95589)\nNaN\nNaN\n160 EAST 84 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4692524\nSedan\nSedan\nNaN\nNaN\nNaN\n\n\n32367\n12/31/2023\n21:34\nMANHATTAN\n10033.0\n40.849308\n-73.931920\n(40.849308, -73.93192)\nWEST 182 STREET\nAUDUBON AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nUnspecified\nUnspecified\nNaN\nNaN\nNaN\n4692192\nStation Wagon/Sport Utility Vehicle\nSedan\nNaN\nNaN\nNaN\n\n\n32368\n12/31/2023\n0:38\nMANHATTAN\n10006.0\n40.709496\n-74.013900\n(40.709496, -74.0139)\nALBANY STREET\nWASHINGTON STREET\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nOther Vehicular\nUnspecified\nNaN\nNaN\nNaN\n4692585\nSedan\nPick-up Truck\nNaN\nNaN\nNaN\n\n\n\n\n32369 rows × 29 columns\n\n\n\n\n\n\n\nfrom shapely.geometry import Point\n\n# Check if the necessary columns exist\nif 'LATITUDE' in data.columns and 'LONGITUDE' in data.columns:\n    # Create a geometry column using the DEC_LAT and DEC_LONG columns\n    geometry = [Point(xy) for xy in zip(data['LONGITUDE'], data['LATITUDE'])]\n    \n    # Create a GeoDataFrame\n    gdf = gpd.GeoDataFrame(data, geometry=geometry)\n\n    # Set the coordinate reference system (CRS) to WGS 84 (EPSG:4326)\n    gdf.set_crs(epsg=4326, inplace=True)\n\n    # Display the first few rows of the GeoDataFrame\n    print(gdf.head())\nelse:\n    print(\"The DataFrame does not contain 'DEC_LAT' and 'DEC_LONG' columns.\")\n\n   CRASH DATE CRASH TIME    BOROUGH  ZIP CODE   LATITUDE  LONGITUDE  \\\n0  05/01/2021      13:30  MANHATTAN   10029.0  40.796300 -73.938290   \n1  05/01/2021      17:50  MANHATTAN   10012.0  40.720936 -73.993805   \n2  05/01/2021      13:30  MANHATTAN   10128.0  40.780693 -73.946600   \n3  05/01/2021       9:40  MANHATTAN   10026.0  40.800537 -73.948360   \n4  05/01/2021      23:03  MANHATTAN   10009.0  40.726864 -73.979910   \n\n                  LOCATION   ON STREET NAME CROSS STREET NAME  \\\n0     (40.7963, -73.93829)  EAST 115 STREET          2 AVENUE   \n1  (40.720936, -73.993805)           BOWERY     SPRING STREET   \n2    (40.780693, -73.9466)   EAST 92 STREET          1 AVENUE   \n3   (40.800537, -73.94836)              NaN               NaN   \n4   (40.726864, -73.97991)         AVENUE B    EAST 10 STREET   \n\n             OFF STREET NAME  NUMBER OF PERSONS INJURED  \\\n0                        NaN                          0   \n1                        NaN                          1   \n2                        NaN                          0   \n3  40        WEST 115 STREET                          0   \n4                        NaN                          1   \n\n   NUMBER OF PERSONS KILLED  NUMBER OF PEDESTRIANS INJURED  \\\n0                         0                              0   \n1                         0                              0   \n2                         0                              0   \n3                         0                              0   \n4                         0                              0   \n\n   NUMBER OF PEDESTRIANS KILLED  NUMBER OF CYCLIST INJURED  \\\n0                             0                          0   \n1                             0                          0   \n2                             0                          0   \n3                             0                          0   \n4                             0                          1   \n\n   NUMBER OF CYCLIST KILLED  NUMBER OF MOTORIST INJURED  \\\n0                         0                           0   \n1                         0                           1   \n2                         0                           0   \n3                         0                           0   \n4                         0                           0   \n\n   NUMBER OF MOTORIST KILLED   CONTRIBUTING FACTOR VEHICLE 1  \\\n0                          0  Passing or Lane Usage Improper   \n1                          0  Driver Inattention/Distraction   \n2                          0  Driver Inattention/Distraction   \n3                          0                Backing Unsafely   \n4                          0  Driver Inattention/Distraction   \n\n    CONTRIBUTING FACTOR VEHICLE 2 CONTRIBUTING FACTOR VEHICLE 3  \\\n0                     Unspecified                           NaN   \n1                     Unspecified                           NaN   \n2                     Unspecified                           NaN   \n3                     Unspecified                           NaN   \n4  Driver Inattention/Distraction                           NaN   \n\n  CONTRIBUTING FACTOR VEHICLE 4 CONTRIBUTING FACTOR VEHICLE 5  COLLISION_ID  \\\n0                           NaN                           NaN       4412937   \n1                           NaN                           NaN       4412445   \n2                           NaN                           NaN       4414390   \n3                           NaN                           NaN       4417017   \n4                           NaN                           NaN       4412243   \n\n                   VEHICLE TYPE CODE 1 VEHICLE TYPE CODE 2  \\\n0                                  Bus               Sedan   \n1                                Sedan               Sedan   \n2                            AMBULANCE               Sedan   \n3  Station Wagon/Sport Utility Vehicle                 NaN   \n4                                 Bike                 NaN   \n\n  VEHICLE TYPE CODE 3 VEHICLE TYPE CODE 4 VEHICLE TYPE CODE 5  \\\n0                 NaN                 NaN                 NaN   \n1                 NaN                 NaN                 NaN   \n2                 NaN                 NaN                 NaN   \n3                 NaN                 NaN                 NaN   \n4                 NaN                 NaN                 NaN   \n\n                     geometry  \n0  POINT (-73.93829 40.79630)  \n1  POINT (-73.99380 40.72094)  \n2  POINT (-73.94660 40.78069)  \n3  POINT (-73.94836 40.80054)  \n4  POINT (-73.97991 40.72686)  \n\n\n\n\n\n\n# Assuming edges_gdf is your GeoDataFrame from part 1.3\nmanhattan_boundary = edges_gdf.geometry.unary_union.convex_hull\n\n# Filter the crash GeoDataFrame to only include crashes within the boundary\nmanhattan_crashes = gdf[gdf.geometry.within(manhattan_boundary)]\n\n# Display the number of crashes within the Center City boundary\nprint(f\"Number of crashes within manhattan: {len(manhattan_crashes)}\")\n\n# Display the first few rows of the filtered GeoDataFrame\nmanhattan_crashes.head()\n\nNumber of crashes within manhattan: 31042\n\n\n\n\n\n\n\n\n\nCRASH DATE\nCRASH TIME\nBOROUGH\nZIP CODE\nLATITUDE\nLONGITUDE\nLOCATION\nON STREET NAME\nCROSS STREET NAME\nOFF STREET NAME\nNUMBER OF PERSONS INJURED\nNUMBER OF PERSONS KILLED\nNUMBER OF PEDESTRIANS INJURED\nNUMBER OF PEDESTRIANS KILLED\nNUMBER OF CYCLIST INJURED\nNUMBER OF CYCLIST KILLED\nNUMBER OF MOTORIST INJURED\nNUMBER OF MOTORIST KILLED\nCONTRIBUTING FACTOR VEHICLE 1\nCONTRIBUTING FACTOR VEHICLE 2\nCONTRIBUTING FACTOR VEHICLE 3\nCONTRIBUTING FACTOR VEHICLE 4\nCONTRIBUTING FACTOR VEHICLE 5\nCOLLISION_ID\nVEHICLE TYPE CODE 1\nVEHICLE TYPE CODE 2\nVEHICLE TYPE CODE 3\nVEHICLE TYPE CODE 4\nVEHICLE TYPE CODE 5\ngeometry\n\n\n\n\n0\n05/01/2021\n13:30\nMANHATTAN\n10029.0\n40.796300\n-73.938290\n(40.7963, -73.93829)\nEAST 115 STREET\n2 AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nPassing or Lane Usage Improper\nUnspecified\nNaN\nNaN\nNaN\n4412937\nBus\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.93829 40.79630)\n\n\n1\n05/01/2021\n17:50\nMANHATTAN\n10012.0\n40.720936\n-73.993805\n(40.720936, -73.993805)\nBOWERY\nSPRING STREET\nNaN\n1\n0\n0\n0\n0\n0\n1\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4412445\nSedan\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.99380 40.72094)\n\n\n2\n05/01/2021\n13:30\nMANHATTAN\n10128.0\n40.780693\n-73.946600\n(40.780693, -73.9466)\nEAST 92 STREET\n1 AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4414390\nAMBULANCE\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.94660 40.78069)\n\n\n3\n05/01/2021\n9:40\nMANHATTAN\n10026.0\n40.800537\n-73.948360\n(40.800537, -73.94836)\nNaN\nNaN\n40 WEST 115 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nBacking Unsafely\nUnspecified\nNaN\nNaN\nNaN\n4417017\nStation Wagon/Sport Utility Vehicle\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.94836 40.80054)\n\n\n4\n05/01/2021\n23:03\nMANHATTAN\n10009.0\n40.726864\n-73.979910\n(40.726864, -73.97991)\nAVENUE B\nEAST 10 STREET\nNaN\n1\n0\n0\n0\n1\n0\n0\n0\nDriver Inattention/Distraction\nDriver Inattention/Distraction\nNaN\nNaN\nNaN\n4412243\nBike\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.97991 40.72686)\n\n\n\n\n\n\n\n\n\n\n\nimport osmnx as ox\n\n# Assuming G is your graph object\n# Project the graph to the Philadelphia state plane CRS (EPSG:2272)\nG_projected = ox.project_graph(G, to_crs='EPSG:2263')\n\n# Project the crash GeoDataFrame to the Philadelphia state plane CRS (EPSG:2272)\nmanhattan_crashes_projected = manhattan_crashes.to_crs(epsg=2263)\n\n# Display the first few rows of the projected GeoDataFrame\nmanhattan_crashes_projected.head()\n\n# Create a plot\nfig, ax = plt.subplots(figsize=(12, 12))\n\n# Plot the street network\nedges_gdf_projected = ox.graph_to_gdfs(G_projected, nodes=False)\nedges_gdf_projected.plot(ax=ax, linewidth=1, edgecolor='gray', label='Street Network')\n\n# Plot the crash locations\nmanhattan_crashes_projected.plot(ax=ax, marker='o', color='red', markersize=5, label='Crashes')\n\n# Add a title and legend\nplt.title('Crash Locations in Manhattan with Street Network')\nplt.legend()\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nSee: ox.distance.nearest_edges(). It takes three arguments:\nthe network graph the longitude of your crash data (the x attribute of the geometry column) the latitude of your crash data (the y attribute of the geometry column) You will get a numpy array with 3 columns that represent (u, v, key) where each u and v are the node IDs that the edge links together. We will ignore the key value for our analysis.\n\n# Extract x and y coordinates from the geometry column\ncrash_x = manhattan_crashes_projected.geometry.x\ncrash_y = manhattan_crashes_projected.geometry.y\n\n# Find the nearest edges for each crash\nnearest_edges = ox.distance.nearest_edges(G_projected, crash_x, crash_y)\n\n# Convert the result to a numpy array\nnearest_edges_array = np.array(nearest_edges)\n\n# Display the first few results\nprint(nearest_edges_array[:5])\n\n# Extract only the u and v columns, ignoring the key\nnearest_edges_uv = nearest_edges_array[:, :2]\n\n# Display the first few u, v pairs\nprint(nearest_edges_uv[:5])\n\n[[4207962275   42443081          0]\n [  42437605 1773076509          0]\n [  42443048   42448745          0]\n [  42435387   42446772          0]\n [  42430924   42430938          0]]\n[[4207962275   42443081]\n [  42437605 1773076509]\n [  42443048   42448745]\n [  42435387   42446772]\n [  42430924   42430938]]\n\n\n\n\n\n\n# Create a DataFrame from the nearest edges data\nedges_df = pd.DataFrame(nearest_edges_array, columns=['u', 'v', 'key'])\n\n# Group by 'u' and 'v' and calculate the size of each group\ncrash_counts = edges_df.groupby(['u', 'v']).size().reset_index(name='crash_count')\n\n# Display the resulting DataFrame\ncrash_counts\n\n\n\n\n\n\n\n\nu\nv\ncrash_count\n\n\n\n\n0\n42421728\n42432736\n2\n\n\n1\n42421731\n42437916\n1\n\n\n2\n42421737\n42437917\n2\n\n\n3\n42421741\n42432756\n1\n\n\n4\n42421751\n42421749\n1\n\n\n...\n...\n...\n...\n\n\n5796\n12162436970\n42455357\n2\n\n\n5797\n12181309686\n4597668039\n5\n\n\n5798\n12299314857\n12299314860\n1\n\n\n5799\n12299314860\n42438476\n3\n\n\n5800\n12374690312\n42433537\n1\n\n\n\n\n5801 rows × 3 columns\n\n\n\n\n\n\n\n# Convert the projected graph to a GeoDataFrame for edges\nedges_gdf_projected = ox.graph_to_gdfs(G_projected, nodes=False)\n\n# Merge the edges GeoDataFrame with the crash counts DataFrame\nmerged_df = edges_gdf_projected.merge(crash_counts, on=['u', 'v'], how='left')\n\n# Fill missing crash count values with zero\nmerged_df['crash_count'] = merged_df['crash_count'].fillna(0)\n\n# Display the first few rows of the merged DataFrame\nmerged_df\n\n# Filter out rows where crash_count is 0.0\nfiltered_df = merged_df[merged_df['crash_count'] &gt; 0.0]\n\n# Display the first few rows of the filtered DataFrame\nfiltered_df\n\n\n\n\n\n\n\n\nu\nv\nosmid\nname\nhighway\nmaxspeed\noneway\nreversed\nlength\ngeometry\nlanes\nref\naccess\nbridge\ntunnel\nwidth\njunction\ncrash_count\n\n\n\n\n2\n42421728\n42432736\n[1271523197, 1271523198]\nCentral Park West\nsecondary\n25 mph\nFalse\nFalse\n86.275\nLINESTRING (995312.767 230030.016, 995334.152 ...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n\n\n3\n42435337\n42437916\n5670640\nWest 105th Street\nresidential\n25 mph\nTrue\nFalse\n137.996\nLINESTRING (995176.877 229785.340, 995144.253 ...\n1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n\n\n6\n42421731\n42437916\n5671485\nManhattan Avenue\nresidential\nNaN\nFalse\nTrue\n86.149\nLINESTRING (994916.519 230250.770, 994899.394 ...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n\n\n11\n42432736\n42435341\n1271523197\nCentral Park West\nsecondary\n25 mph\nFalse\nFalse\n80.116\nLINESTRING (995450.120 230277.316, 995461.822 ...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n\n\n13\n42437916\n42437917\n5670640\nWest 105th Street\nresidential\n25 mph\nTrue\nFalse\n135.012\nLINESTRING (994779.437 230003.728, 994751.078 ...\n1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n8.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n9864\n7802856372\n7802856349\n661227257\nCentral Park West\nsecondary\n25 mph\nFalse\nTrue\n80.457\nLINESTRING (990516.812 221373.627, 990505.794 ...\n4\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n\n\n9865\n7802856372\n7802856356\n[1271523171, 1271523172]\nCentral Park West\nsecondary\n25 mph\nFalse\nFalse\n79.496\nLINESTRING (990516.812 221373.627, 990527.802 ...\n4\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n4.0\n\n\n9867\n8288270047\n246580982\n5671698\nWest 16th Street\nresidential\n25 mph\nTrue\nFalse\n21.068\nLINESTRING (981879.246 210378.461, 981886.366 ...\n1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n6.0\n\n\n9869\n8840333851\n42453952\n5672377\nChurch Street\nsecondary\n25 mph\nTrue\nFalse\n83.590\nLINESTRING (981444.123 198698.940, 981458.126 ...\n3\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n\n\n9878\n11942111842\n42434962\n[658488325, 658499796, 658499797, 420872214, 6...\nNaN\nmotorway_link\nNaN\nTrue\nFalse\n290.747\nLINESTRING (991424.925 211158.515, 991364.955 ...\n[2, 1, 3]\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n\n\n\n\n5805 rows × 18 columns\n\n\n\n\n\n\n\n# Step 1: Calculate the crash index\nfiltered_df['crash_index'] = np.log10(filtered_df['crash_count'] / filtered_df['length'])\n\n# Step 2: Normalize the crash index\nmin_crash_index = filtered_df['crash_index'].min()\nmax_crash_index = filtered_df['crash_index'].max()\n\n# Normalize the crash_index to a 0-1 scale\nfiltered_df['crash_index_normalized'] = (filtered_df['crash_index'] - min_crash_index) / (max_crash_index - min_crash_index)\n\nfiltered_df\n\nC:\\Users\\txx11\\mambaforge\\envs\\musa-550-fall-2023\\lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\nC:\\Users\\txx11\\mambaforge\\envs\\musa-550-fall-2023\\lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\n\n\n\n\n\n\n\n\n\nu\nv\nosmid\nname\nhighway\nmaxspeed\noneway\nreversed\nlength\ngeometry\nlanes\nref\naccess\nbridge\ntunnel\nwidth\njunction\ncrash_count\ncrash_index\ncrash_index_normalized\n\n\n\n\n2\n42421728\n42432736\n[1271523197, 1271523198]\nCentral Park West\nsecondary\n25 mph\nFalse\nFalse\n86.275\nLINESTRING (995312.767 230030.016, 995334.152 ...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n-1.634855\n0.384469\n\n\n3\n42435337\n42437916\n5670640\nWest 105th Street\nresidential\n25 mph\nTrue\nFalse\n137.996\nLINESTRING (995176.877 229785.340, 995144.253 ...\n1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n-2.139866\n0.244838\n\n\n6\n42421731\n42437916\n5671485\nManhattan Avenue\nresidential\nNaN\nFalse\nTrue\n86.149\nLINESTRING (994916.519 230250.770, 994899.394 ...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n-1.935250\n0.301413\n\n\n11\n42432736\n42435341\n1271523197\nCentral Park West\nsecondary\n25 mph\nFalse\nFalse\n80.116\nLINESTRING (995450.120 230277.316, 995461.822 ...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n-1.602689\n0.393363\n\n\n13\n42437916\n42437917\n5670640\nWest 105th Street\nresidential\n25 mph\nTrue\nFalse\n135.012\nLINESTRING (994779.437 230003.728, 994751.078 ...\n1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n8.0\n-1.227282\n0.497160\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n9864\n7802856372\n7802856349\n661227257\nCentral Park West\nsecondary\n25 mph\nFalse\nTrue\n80.457\nLINESTRING (990516.812 221373.627, 990505.794 ...\n4\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n-1.905564\n0.309621\n\n\n9865\n7802856372\n7802856356\n[1271523171, 1271523172]\nCentral Park West\nsecondary\n25 mph\nFalse\nFalse\n79.496\nLINESTRING (990516.812 221373.627, 990527.802 ...\n4\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n4.0\n-1.298285\n0.477528\n\n\n9867\n8288270047\n246580982\n5671698\nWest 16th Street\nresidential\n25 mph\nTrue\nFalse\n21.068\nLINESTRING (981879.246 210378.461, 981886.366 ...\n1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n6.0\n-0.545472\n0.685674\n\n\n9869\n8840333851\n42453952\n5672377\nChurch Street\nsecondary\n25 mph\nTrue\nFalse\n83.590\nLINESTRING (981444.123 198698.940, 981458.126 ...\n3\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n-1.621124\n0.388266\n\n\n9878\n11942111842\n42434962\n[658488325, 658499796, 658499797, 420872214, 6...\nNaN\nmotorway_link\nNaN\nTrue\nFalse\n290.747\nLINESTRING (991424.925 211158.515, 991364.955 ...\n[2, 1, 3]\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n-2.463515\n0.155352\n\n\n\n\n5805 rows × 20 columns\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\n# Assuming filtered_df is already defined and contains 'crash_index_normalized'\n\n# Plot a histogram of the normalized crash index values\nplt.figure(figsize=(10, 6))\nplt.hist(filtered_df['crash_index_normalized'], bins=30, color='skyblue', edgecolor='black')\nplt.title('Histogram of Normalized Crash Index')\nplt.xlabel('Normalized Crash Index')\nplt.ylabel('Frequency')\nplt.grid(axis='y', alpha=0.75)\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nimport folium\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n\n# Assuming 'filtered_df' is your GeoDataFrame with the 'crash_index_normalized' column\n\n# Create a base map centered around the Central district with a dark theme\nm = folium.Map(location=[40.7826, -73.9656], zoom_start=12, tiles='CartoDB dark_matter')\n\n# Define a function to style the lines based on the crash index\ndef style_function(feature):\n    crash_index = feature['properties']['crash_index_normalized']\n    # Use the 'viridis' colormap for a color gradient\n    colormap = plt.cm.get_cmap('viridis')\n    # Get the RGBA color based on the crash index\n    color = colormap(crash_index)  # crash_index should already be normalized [0, 1]\n    # Convert RGBA to hex\n    color_hex = '#{:02x}{:02x}{:02x}'.format(int(color[0]*255), int(color[1]*255), int(color[2]*255))\n    return {\n        'color': color_hex,\n        'weight': 3 + crash_index * 2,  # Increase line weight for higher crash index\n        'opacity': 0.8\n    }\n\n# Add the GeoDataFrame to the map\nfolium.GeoJson(\n    filtered_df,\n    style_function=style_function,\n    tooltip=folium.GeoJsonTooltip(fields=['name', 'crash_index_normalized']),\n).add_to(m)\n\n\n# Display the map\nm\n\nC:\\Users\\txx11\\AppData\\Local\\Temp\\ipykernel_2124\\3546299534.py:14: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n  colormap = plt.cm.get_cmap('viridis')\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\nm.save('mahattan_crash_index_map_dark.html')\n\nC:\\Users\\txx11\\AppData\\Local\\Temp\\ipykernel_2124\\3546299534.py:14: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n  colormap = plt.cm.get_cmap('viridis')",
    "crumbs": [
      "Analysis",
      "Part 1: Street Network with OSMnx"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "New York City (NYC) is one of the busiest urban centers in the world, with millions of vehicles navigating its streets daily. Understanding traffic patterns and identifying high-risk locations for crashes is crucial for improving road safety and optimizing traffic flow. Recent advancements in geospatial data science and machine learning provide powerful tools to analyze complex urban transportation systems and predict traffic behavior.\nThis project aims to use OpenStreetMap data, accessed and analyzed through the Python library OSMnx, to map crash data onto NYC’s street network. Additionally, machine learning models will be developed to predict traffic volume at intersections, leveraging traffic count data, geospatial features, and historical crash patterns. By combining geospatial analysis and predictive modeling, this project will provide actionable insights into traffic dynamics and road safety in NYC.\n\n\n\nImage: Traffic in New York City. Source: New York Times",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#background",
    "href": "intro.html#background",
    "title": "Introduction",
    "section": "",
    "text": "New York City (NYC) is one of the busiest urban centers in the world, with millions of vehicles navigating its streets daily. Understanding traffic patterns and identifying high-risk locations for crashes is crucial for improving road safety and optimizing traffic flow. Recent advancements in geospatial data science and machine learning provide powerful tools to analyze complex urban transportation systems and predict traffic behavior.\nThis project aims to use OpenStreetMap data, accessed and analyzed through the Python library OSMnx, to map crash data onto NYC’s street network. Additionally, machine learning models will be developed to predict traffic volume at intersections, leveraging traffic count data, geospatial features, and historical crash patterns. By combining geospatial analysis and predictive modeling, this project will provide actionable insights into traffic dynamics and road safety in NYC.\n\n\n\nImage: Traffic in New York City. Source: New York Times",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#research-questions",
    "href": "intro.html#research-questions",
    "title": "Introduction",
    "section": "Research Questions",
    "text": "Research Questions\n\nCrash Mapping and Analysis:\n\nHow can OSMnx be used to map crash data onto NYC’s street network?\nWhat spatial patterns and trends can be identified from crash data across NYC?\n\nTraffic Volume Prediction:\n\nCan machine learning models accurately predict traffic volume at intersections using traffic count data and geospatial features?\nWhat are the most influential factors in predicting traffic volume at intersections?\n\nSafety and Traffic Flow Insights:\n\nHow do crash patterns correlate with predicted traffic volumes at intersections?\nWhich intersections in NYC are at the highest risk of crashes based on traffic volume and historical crash data?\n\n\n\n\n\nScreenshots of Manhattan crash maps from the project.\n\n\n\n\n\n\n\n\nImportant\n\n\n\n辣椒炒肉!",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "In the End",
    "section": "",
    "text": "In conclusion, while the project demonstrates the potential of using environmental and contextual features to predict traffic congestion, the results indicate that the current model is insufficient for accurate and reliable predictions. The significant errors and low explanatory power suggest that the complexity of traffic patterns requires a more robust approach. Future efforts should focus on incorporating additional features, such as time of day, historical traffic data, and real-time factors like road closures or accidents. Advanced modeling techniques, such as Gradient Boosting Machines or Neural Networks, could also be explored to better capture non-linear relationships and interactions between variables. Despite its limitations, this project serves as a valuable starting point for understanding the factors influencing traffic congestion and highlights the importance of data-driven approaches in addressing urban mobility challenges.\n\n\n\n\nImage: More predictable future traffic. Source: AI-generated.",
    "crumbs": [
      "Conclusion"
    ]
  },
  {
    "objectID": "conclusion.html#conclusion",
    "href": "conclusion.html#conclusion",
    "title": "In the End",
    "section": "",
    "text": "In conclusion, while the project demonstrates the potential of using environmental and contextual features to predict traffic congestion, the results indicate that the current model is insufficient for accurate and reliable predictions. The significant errors and low explanatory power suggest that the complexity of traffic patterns requires a more robust approach. Future efforts should focus on incorporating additional features, such as time of day, historical traffic data, and real-time factors like road closures or accidents. Advanced modeling techniques, such as Gradient Boosting Machines or Neural Networks, could also be explored to better capture non-linear relationships and interactions between variables. Despite its limitations, this project serves as a valuable starting point for understanding the factors influencing traffic congestion and highlights the importance of data-driven approaches in addressing urban mobility challenges.\n\n\n\n\nImage: More predictable future traffic. Source: AI-generated.",
    "crumbs": [
      "Conclusion"
    ]
  },
  {
    "objectID": "conclusion.html#limitations",
    "href": "conclusion.html#limitations",
    "title": "In the End",
    "section": "Limitations",
    "text": "Limitations\nDespite its intent, the model faces several limitations that hinder its performance. The low R-squared value indicates that the features used explain only a negligible portion of the variance in traffic counts, suggesting that other critical factors influencing traffic, such as time of day, road capacity, historical traffic trends, or localized disruptions, are missing from the model. Additionally, the model exhibits heteroscedasticity, with residual errors increasing for higher traffic counts, indicating that it struggles to capture variability in extreme conditions. This issue is further compounded by outliers, such as unusual traffic spikes during events or accidents, which the model fails to predict accurately. Moreover, the features included may not fully capture the non-linear and complex relationships between environmental conditions and traffic patterns, limiting the model’s ability to generalize to diverse scenarios. These limitations highlight the need for more comprehensive data and advanced modeling techniques to improve predictive accuracy.",
    "crumbs": [
      "Conclusion"
    ]
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "New York City (NYC) is one of the busiest urban centers in the world, with millions of vehicles navigating its streets daily. Understanding traffic patterns and identifying high-risk locations for crashes is crucial for improving road safety and optimizing traffic flow. Recent advancements in geospatial data science and machine learning provide powerful tools to analyze complex urban transportation systems and predict traffic behavior.\n\n\n\nImage: Traffic in New York City. Source: New York Times\n\n\nThis project aims to use OpenStreetMap data, accessed and analyzed through the Python library OSMnx, to map crash data onto NYC’s street network. Additionally, machine learning models will be developed to predict traffic volume at intersections, leveraging traffic count data, geospatial features, and historical crash patterns. By combining geospatial analysis and predictive modeling, this project will provide actionable insights into traffic dynamics and road safety in NYC."
  },
  {
    "objectID": "introduction.html#background",
    "href": "introduction.html#background",
    "title": "Introduction",
    "section": "",
    "text": "New York City (NYC) is one of the busiest urban centers in the world, with millions of vehicles navigating its streets daily. Understanding traffic patterns and identifying high-risk locations for crashes is crucial for improving road safety and optimizing traffic flow. Recent advancements in geospatial data science and machine learning provide powerful tools to analyze complex urban transportation systems and predict traffic behavior.\n\n\n\nImage: Traffic in New York City. Source: New York Times\n\n\nThis project aims to use OpenStreetMap data, accessed and analyzed through the Python library OSMnx, to map crash data onto NYC’s street network. Additionally, machine learning models will be developed to predict traffic volume at intersections, leveraging traffic count data, geospatial features, and historical crash patterns. By combining geospatial analysis and predictive modeling, this project will provide actionable insights into traffic dynamics and road safety in NYC."
  },
  {
    "objectID": "introduction.html#research-questions",
    "href": "introduction.html#research-questions",
    "title": "Introduction",
    "section": "Research Questions",
    "text": "Research Questions\n\nCrash Mapping and Analysis:\n\nHow can OSMnx be used to map crash data onto NYC’s street network?\nWhat spatial patterns and trends can be identified from crash data across NYC?\n\nTraffic Volume Prediction:\n\nCan machine learning models accurately predict traffic volume at intersections using traffic count data and geospatial features?\nWhat are the most influential factors in predicting traffic volume at intersections?\n\nSafety and Traffic Flow Insights:\n\nHow do crash patterns correlate with predicted traffic volumes at intersections?\nWhich intersections in NYC are at the highest risk of crashes based on traffic volume and historical crash data?"
  },
  {
    "objectID": "about2.html",
    "href": "about2.html",
    "title": "About Us",
    "section": "",
    "text": "Need more information from everyone…\n\n\nXiaxin Tang:  Xiaxin (Joey) concentrates in Smart City of the Master of City Planning program. His main role: xxx.\nJiyan Wang:  Jiyan (William) concentrates in the Sustainable Transportation of the Master of City Planning program. His main role: xxx.\nYuan Ji:  Yuan is concentrates in the Urban Design of the Master of City Planning program. His main role xxx.\n\n\nYou can find more information on our github.",
    "crumbs": [
      "About us"
    ]
  },
  {
    "objectID": "analysis/1-network.html",
    "href": "analysis/1-network.html",
    "title": "I. Network Analysis",
    "section": "",
    "text": "In this section, we wish to examine the crash data through street network on Manhattan to explore spatial patterns of crashes in certain area that might cause by congestions. We used the Motor Vehicle Collisions data from NYC Open data. Each row of the data contains one crash event, with information like location, time, causes, types of vehicles etc. We filtered the time from May 2021 to Dec 2023, in accordance with the date for traffic data in machine learning section.\n\n# The usual imports\nimport altair as alt\nimport geopandas as gpd\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n\n# Show all columns in dataframes\npd.options.display.max_columns = 999\n\n# Hide warnings due to issue in shapely package \n# See: https://github.com/shapely/shapely/issues/1345\nnp.seterr(invalid=\"ignore\");\nimport osmnx as ox\n\nNYC = gpd.read_file(\"new-york-city-boroughs.geojson\")\nNYC_M = NYC[NYC[\"name\"] == \"Manhattan\"]\n\nNYC_M\n\n\n\n\n\n# Project it to Web Mercator first and plot\nax = NYC_M.to_crs(epsg=4326).plot(facecolor=\"none\", edgecolor=\"black\")\nax.set_axis_off()\n\n\n\n\n\n\n\n\n\n\n\n\n# Define your polygon boundary (replace with your actual polygon)\n# For example, if you have a GeoDataFrame with your area boundary:\npolygon = NYC_M.unary_union  \n\n# Create a street network graph\nG = ox.graph_from_polygon(polygon, network_type='drive')\n\n# Convert graph edges to a GeoDataFrame\nedges_gdf = ox.graph_to_gdfs(G, nodes=False, edges=True)\n\n# Display the first few rows of the GeoDataFrame\nprint(edges_gdf.head())\n\n# Plot the edges GeoDataFrame\nfig, ax = plt.subplots(figsize=(20, 20))\nedges_gdf.plot(ax=ax, linewidth=1, edgecolor='black')\nplt.show()\n\n                                                 osmid               name  \\\nu        v        key                                                       \n42421728 42435337 0                          195743153  Central Park West   \n         42421731 0    [420625565, 420625573, 5668966]  West 106th Street   \n         42432736 0           [1271523197, 1271523198]  Central Park West   \n42421731 42437916 0                            5671485   Manhattan Avenue   \n         42432737 0                          195743186   Manhattan Avenue   \n\n                           highway maxspeed  oneway reversed   length  \\\nu        v        key                                                   \n42421728 42435337 0      secondary   25 mph   False     True   85.345   \n         42421731 0      secondary      NaN   False    False  138.033   \n         42432736 0      secondary   25 mph   False    False   86.275   \n42421731 42437916 0    residential      NaN   False     True   86.149   \n         42432737 0    residential      NaN   False    False   85.968   \n\n                                                                geometry  \\\nu        v        key                                                      \n42421728 42435337 0    LINESTRING (-73.96004 40.79805, -73.96011 40.7...   \n         42421731 0    LINESTRING (-73.96004 40.79805, -73.96017 40.7...   \n         42432736 0    LINESTRING (-73.96004 40.79805, -73.95997 40.7...   \n42421731 42437916 0    LINESTRING (-73.96147 40.79865, -73.96154 40.7...   \n         42432737 0    LINESTRING (-73.96147 40.79865, -73.96140 40.7...   \n\n                      lanes  ref access bridge tunnel width junction  \nu        v        key                                                 \n42421728 42435337 0     NaN  NaN    NaN    NaN    NaN   NaN      NaN  \n         42421731 0     NaN  NaN    NaN    NaN    NaN   NaN      NaN  \n         42432736 0     NaN  NaN    NaN    NaN    NaN   NaN      NaN  \n42421731 42437916 0     NaN  NaN    NaN    NaN    NaN   NaN      NaN  \n         42432737 0     NaN  NaN    NaN    NaN    NaN   NaN      NaN  \n\n\n\n\n\n\n\n\n\n\n\n\n\n# Load data into a pandas DataFrame\ndata = pd.read_csv(\"Motor_Vehicle_Collisions_Crashes.csv\")\n\n\ndata\n\n\n\n\n\n\n\n\nCRASH DATE\nCRASH TIME\nBOROUGH\nZIP CODE\nLATITUDE\nLONGITUDE\nLOCATION\nON STREET NAME\nCROSS STREET NAME\nOFF STREET NAME\nNUMBER OF PERSONS INJURED\nNUMBER OF PERSONS KILLED\nNUMBER OF PEDESTRIANS INJURED\nNUMBER OF PEDESTRIANS KILLED\nNUMBER OF CYCLIST INJURED\nNUMBER OF CYCLIST KILLED\nNUMBER OF MOTORIST INJURED\nNUMBER OF MOTORIST KILLED\nCONTRIBUTING FACTOR VEHICLE 1\nCONTRIBUTING FACTOR VEHICLE 2\nCONTRIBUTING FACTOR VEHICLE 3\nCONTRIBUTING FACTOR VEHICLE 4\nCONTRIBUTING FACTOR VEHICLE 5\nCOLLISION_ID\nVEHICLE TYPE CODE 1\nVEHICLE TYPE CODE 2\nVEHICLE TYPE CODE 3\nVEHICLE TYPE CODE 4\nVEHICLE TYPE CODE 5\n\n\n\n\n0\n05/01/2021\n13:30\nMANHATTAN\n10029.0\n40.796300\n-73.938290\n(40.7963, -73.93829)\nEAST 115 STREET\n2 AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nPassing or Lane Usage Improper\nUnspecified\nNaN\nNaN\nNaN\n4412937\nBus\nSedan\nNaN\nNaN\nNaN\n\n\n1\n05/01/2021\n17:50\nMANHATTAN\n10012.0\n40.720936\n-73.993805\n(40.720936, -73.993805)\nBOWERY\nSPRING STREET\nNaN\n1\n0\n0\n0\n0\n0\n1\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4412445\nSedan\nSedan\nNaN\nNaN\nNaN\n\n\n2\n05/01/2021\n13:30\nMANHATTAN\n10128.0\n40.780693\n-73.946600\n(40.780693, -73.9466)\nEAST 92 STREET\n1 AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4414390\nAMBULANCE\nSedan\nNaN\nNaN\nNaN\n\n\n3\n05/01/2021\n9:40\nMANHATTAN\n10026.0\n40.800537\n-73.948360\n(40.800537, -73.94836)\nNaN\nNaN\n40 WEST 115 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nBacking Unsafely\nUnspecified\nNaN\nNaN\nNaN\n4417017\nStation Wagon/Sport Utility Vehicle\nNaN\nNaN\nNaN\nNaN\n\n\n4\n05/01/2021\n23:03\nMANHATTAN\n10009.0\n40.726864\n-73.979910\n(40.726864, -73.97991)\nAVENUE B\nEAST 10 STREET\nNaN\n1\n0\n0\n0\n1\n0\n0\n0\nDriver Inattention/Distraction\nDriver Inattention/Distraction\nNaN\nNaN\nNaN\n4412243\nBike\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n32364\n12/31/2023\n23:18\nMANHATTAN\n10030.0\n40.819670\n-73.944240\n(40.81967, -73.94424)\n8 AVENUE\nWEST 140 STREET\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nDriver Inattention/Distraction\nNaN\nNaN\nNaN\nNaN\n4692572\nSedan\nNaN\nNaN\nNaN\nNaN\n\n\n32365\n12/31/2023\n18:03\nMANHATTAN\n10039.0\n40.824130\n-73.940980\n(40.82413, -73.94098)\n8 AVENUE\nWEST 147 STREET\nNaN\n1\n0\n1\n0\n0\n0\n0\n0\nUnspecified\nNaN\nNaN\nNaN\nNaN\n4692571\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n32366\n12/31/2023\n14:00\nMANHATTAN\n10028.0\n40.777890\n-73.955890\n(40.77789, -73.95589)\nNaN\nNaN\n160 EAST 84 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4692524\nSedan\nSedan\nNaN\nNaN\nNaN\n\n\n32367\n12/31/2023\n21:34\nMANHATTAN\n10033.0\n40.849308\n-73.931920\n(40.849308, -73.93192)\nWEST 182 STREET\nAUDUBON AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nUnspecified\nUnspecified\nNaN\nNaN\nNaN\n4692192\nStation Wagon/Sport Utility Vehicle\nSedan\nNaN\nNaN\nNaN\n\n\n32368\n12/31/2023\n0:38\nMANHATTAN\n10006.0\n40.709496\n-74.013900\n(40.709496, -74.0139)\nALBANY STREET\nWASHINGTON STREET\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nOther Vehicular\nUnspecified\nNaN\nNaN\nNaN\n4692585\nSedan\nPick-up Truck\nNaN\nNaN\nNaN\n\n\n\n\n32369 rows × 29 columns\n\n\n\n\n\n\n\nfrom shapely.geometry import Point\n\n# Check if the necessary columns exist\nif 'LATITUDE' in data.columns and 'LONGITUDE' in data.columns:\n    # Create a geometry column using the DEC_LAT and DEC_LONG columns\n    geometry = [Point(xy) for xy in zip(data['LONGITUDE'], data['LATITUDE'])]\n    \n    # Create a GeoDataFrame\n    gdf = gpd.GeoDataFrame(data, geometry=geometry)\n\n    # Set the coordinate reference system (CRS) to WGS 84 (EPSG:4326)\n    gdf.set_crs(epsg=4326, inplace=True)\n\n    # Display the first few rows of the GeoDataFrame\n    print(gdf.head())\nelse:\n    print(\"The DataFrame does not contain 'DEC_LAT' and 'DEC_LONG' columns.\")\n\n   CRASH DATE CRASH TIME    BOROUGH  ZIP CODE   LATITUDE  LONGITUDE  \\\n0  05/01/2021      13:30  MANHATTAN   10029.0  40.796300 -73.938290   \n1  05/01/2021      17:50  MANHATTAN   10012.0  40.720936 -73.993805   \n2  05/01/2021      13:30  MANHATTAN   10128.0  40.780693 -73.946600   \n3  05/01/2021       9:40  MANHATTAN   10026.0  40.800537 -73.948360   \n4  05/01/2021      23:03  MANHATTAN   10009.0  40.726864 -73.979910   \n\n                  LOCATION   ON STREET NAME CROSS STREET NAME  \\\n0     (40.7963, -73.93829)  EAST 115 STREET          2 AVENUE   \n1  (40.720936, -73.993805)           BOWERY     SPRING STREET   \n2    (40.780693, -73.9466)   EAST 92 STREET          1 AVENUE   \n3   (40.800537, -73.94836)              NaN               NaN   \n4   (40.726864, -73.97991)         AVENUE B    EAST 10 STREET   \n\n             OFF STREET NAME  NUMBER OF PERSONS INJURED  \\\n0                        NaN                          0   \n1                        NaN                          1   \n2                        NaN                          0   \n3  40        WEST 115 STREET                          0   \n4                        NaN                          1   \n\n   NUMBER OF PERSONS KILLED  NUMBER OF PEDESTRIANS INJURED  \\\n0                         0                              0   \n1                         0                              0   \n2                         0                              0   \n3                         0                              0   \n4                         0                              0   \n\n   NUMBER OF PEDESTRIANS KILLED  NUMBER OF CYCLIST INJURED  \\\n0                             0                          0   \n1                             0                          0   \n2                             0                          0   \n3                             0                          0   \n4                             0                          1   \n\n   NUMBER OF CYCLIST KILLED  NUMBER OF MOTORIST INJURED  \\\n0                         0                           0   \n1                         0                           1   \n2                         0                           0   \n3                         0                           0   \n4                         0                           0   \n\n   NUMBER OF MOTORIST KILLED   CONTRIBUTING FACTOR VEHICLE 1  \\\n0                          0  Passing or Lane Usage Improper   \n1                          0  Driver Inattention/Distraction   \n2                          0  Driver Inattention/Distraction   \n3                          0                Backing Unsafely   \n4                          0  Driver Inattention/Distraction   \n\n    CONTRIBUTING FACTOR VEHICLE 2 CONTRIBUTING FACTOR VEHICLE 3  \\\n0                     Unspecified                           NaN   \n1                     Unspecified                           NaN   \n2                     Unspecified                           NaN   \n3                     Unspecified                           NaN   \n4  Driver Inattention/Distraction                           NaN   \n\n  CONTRIBUTING FACTOR VEHICLE 4 CONTRIBUTING FACTOR VEHICLE 5  COLLISION_ID  \\\n0                           NaN                           NaN       4412937   \n1                           NaN                           NaN       4412445   \n2                           NaN                           NaN       4414390   \n3                           NaN                           NaN       4417017   \n4                           NaN                           NaN       4412243   \n\n                   VEHICLE TYPE CODE 1 VEHICLE TYPE CODE 2  \\\n0                                  Bus               Sedan   \n1                                Sedan               Sedan   \n2                            AMBULANCE               Sedan   \n3  Station Wagon/Sport Utility Vehicle                 NaN   \n4                                 Bike                 NaN   \n\n  VEHICLE TYPE CODE 3 VEHICLE TYPE CODE 4 VEHICLE TYPE CODE 5  \\\n0                 NaN                 NaN                 NaN   \n1                 NaN                 NaN                 NaN   \n2                 NaN                 NaN                 NaN   \n3                 NaN                 NaN                 NaN   \n4                 NaN                 NaN                 NaN   \n\n                     geometry  \n0  POINT (-73.93829 40.79630)  \n1  POINT (-73.99380 40.72094)  \n2  POINT (-73.94660 40.78069)  \n3  POINT (-73.94836 40.80054)  \n4  POINT (-73.97991 40.72686)  \n\n\n\n\n\n\n# Assuming edges_gdf is your GeoDataFrame from part 1.3\nmanhattan_boundary = edges_gdf.geometry.unary_union.convex_hull\n\n# Filter the crash GeoDataFrame to only include crashes within the boundary\nmanhattan_crashes = gdf[gdf.geometry.within(manhattan_boundary)]\n\n# Display the number of crashes within the Center City boundary\nprint(f\"Number of crashes within manhattan: {len(manhattan_crashes)}\")\n\n# Display the first few rows of the filtered GeoDataFrame\nmanhattan_crashes.head()\n\nNumber of crashes within manhattan: 31042\n\n\n\n\n\n\n\n\n\nCRASH DATE\nCRASH TIME\nBOROUGH\nZIP CODE\nLATITUDE\nLONGITUDE\nLOCATION\nON STREET NAME\nCROSS STREET NAME\nOFF STREET NAME\nNUMBER OF PERSONS INJURED\nNUMBER OF PERSONS KILLED\nNUMBER OF PEDESTRIANS INJURED\nNUMBER OF PEDESTRIANS KILLED\nNUMBER OF CYCLIST INJURED\nNUMBER OF CYCLIST KILLED\nNUMBER OF MOTORIST INJURED\nNUMBER OF MOTORIST KILLED\nCONTRIBUTING FACTOR VEHICLE 1\nCONTRIBUTING FACTOR VEHICLE 2\nCONTRIBUTING FACTOR VEHICLE 3\nCONTRIBUTING FACTOR VEHICLE 4\nCONTRIBUTING FACTOR VEHICLE 5\nCOLLISION_ID\nVEHICLE TYPE CODE 1\nVEHICLE TYPE CODE 2\nVEHICLE TYPE CODE 3\nVEHICLE TYPE CODE 4\nVEHICLE TYPE CODE 5\ngeometry\n\n\n\n\n0\n05/01/2021\n13:30\nMANHATTAN\n10029.0\n40.796300\n-73.938290\n(40.7963, -73.93829)\nEAST 115 STREET\n2 AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nPassing or Lane Usage Improper\nUnspecified\nNaN\nNaN\nNaN\n4412937\nBus\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.93829 40.79630)\n\n\n1\n05/01/2021\n17:50\nMANHATTAN\n10012.0\n40.720936\n-73.993805\n(40.720936, -73.993805)\nBOWERY\nSPRING STREET\nNaN\n1\n0\n0\n0\n0\n0\n1\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4412445\nSedan\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.99380 40.72094)\n\n\n2\n05/01/2021\n13:30\nMANHATTAN\n10128.0\n40.780693\n-73.946600\n(40.780693, -73.9466)\nEAST 92 STREET\n1 AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4414390\nAMBULANCE\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.94660 40.78069)\n\n\n3\n05/01/2021\n9:40\nMANHATTAN\n10026.0\n40.800537\n-73.948360\n(40.800537, -73.94836)\nNaN\nNaN\n40 WEST 115 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nBacking Unsafely\nUnspecified\nNaN\nNaN\nNaN\n4417017\nStation Wagon/Sport Utility Vehicle\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.94836 40.80054)\n\n\n4\n05/01/2021\n23:03\nMANHATTAN\n10009.0\n40.726864\n-73.979910\n(40.726864, -73.97991)\nAVENUE B\nEAST 10 STREET\nNaN\n1\n0\n0\n0\n1\n0\n0\n0\nDriver Inattention/Distraction\nDriver Inattention/Distraction\nNaN\nNaN\nNaN\n4412243\nBike\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.97991 40.72686)\n\n\n\n\n\n\n\n\n\n\n\nimport osmnx as ox\n\n# Assuming G is your graph object\n# Project the graph to the Philadelphia state plane CRS (EPSG:2272)\nG_projected = ox.project_graph(G, to_crs='EPSG:2263')\n\n# Project the crash GeoDataFrame to the Philadelphia state plane CRS (EPSG:2272)\nmanhattan_crashes_projected = manhattan_crashes.to_crs(epsg=2263)\n\n# Display the first few rows of the projected GeoDataFrame\nmanhattan_crashes_projected.head()\n\n# Create a plot\nfig, ax = plt.subplots(figsize=(12, 12))\n\n# Plot the street network\nedges_gdf_projected = ox.graph_to_gdfs(G_projected, nodes=False)\nedges_gdf_projected.plot(ax=ax, linewidth=1, edgecolor='gray', label='Street Network')\n\n# Plot the crash locations\nmanhattan_crashes_projected.plot(ax=ax, marker='o', color='red', markersize=5, label='Crashes')\n\n# Add a title and legend\nplt.title('Crash Locations in Manhattan with Street Network')\nplt.legend()\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nSee: ox.distance.nearest_edges(). It takes three arguments:\nthe network graph the longitude of your crash data (the x attribute of the geometry column) the latitude of your crash data (the y attribute of the geometry column) You will get a numpy array with 3 columns that represent (u, v, key) where each u and v are the node IDs that the edge links together. We will ignore the key value for our analysis.\n\n# Extract x and y coordinates from the geometry column\ncrash_x = manhattan_crashes_projected.geometry.x\ncrash_y = manhattan_crashes_projected.geometry.y\n\n# Find the nearest edges for each crash\nnearest_edges = ox.distance.nearest_edges(G_projected, crash_x, crash_y)\n\n# Convert the result to a numpy array\nnearest_edges_array = np.array(nearest_edges)\n\n# Display the first few results\nprint(nearest_edges_array[:5])\n\n# Extract only the u and v columns, ignoring the key\nnearest_edges_uv = nearest_edges_array[:, :2]\n\n# Display the first few u, v pairs\nprint(nearest_edges_uv[:5])\n\n[[4207962275   42443081          0]\n [  42437605 1773076509          0]\n [  42443048   42448745          0]\n [  42435387   42446772          0]\n [  42430924   42430938          0]]\n[[4207962275   42443081]\n [  42437605 1773076509]\n [  42443048   42448745]\n [  42435387   42446772]\n [  42430924   42430938]]\n\n\n\n\n\n\n# Create a DataFrame from the nearest edges data\nedges_df = pd.DataFrame(nearest_edges_array, columns=['u', 'v', 'key'])\n\n# Group by 'u' and 'v' and calculate the size of each group\ncrash_counts = edges_df.groupby(['u', 'v']).size().reset_index(name='crash_count')\n\n# Display the resulting DataFrame\ncrash_counts\n\n\n\n\n\n\n\n\nu\nv\ncrash_count\n\n\n\n\n0\n42421728\n42432736\n2\n\n\n1\n42421731\n42437916\n1\n\n\n2\n42421737\n42437917\n2\n\n\n3\n42421741\n42432756\n1\n\n\n4\n42421751\n42421749\n1\n\n\n...\n...\n...\n...\n\n\n5796\n12162436970\n42455357\n2\n\n\n5797\n12181309686\n4597668039\n5\n\n\n5798\n12299314857\n12299314860\n1\n\n\n5799\n12299314860\n42438476\n3\n\n\n5800\n12374690312\n42433537\n1\n\n\n\n\n5801 rows × 3 columns\n\n\n\n\n\n\n\n# Convert the projected graph to a GeoDataFrame for edges\nedges_gdf_projected = ox.graph_to_gdfs(G_projected, nodes=False)\n\n# Merge the edges GeoDataFrame with the crash counts DataFrame\nmerged_df = edges_gdf_projected.merge(crash_counts, on=['u', 'v'], how='left')\n\n# Fill missing crash count values with zero\nmerged_df['crash_count'] = merged_df['crash_count'].fillna(0)\n\n# Display the first few rows of the merged DataFrame\nmerged_df\n\n# Filter out rows where crash_count is 0.0\nfiltered_df = merged_df[merged_df['crash_count'] &gt; 0.0]\n\n# Display the first few rows of the filtered DataFrame\nfiltered_df\n\n\n\n\n\n\n\n\nu\nv\nosmid\nname\nhighway\nmaxspeed\noneway\nreversed\nlength\ngeometry\nlanes\nref\naccess\nbridge\ntunnel\nwidth\njunction\ncrash_count\n\n\n\n\n2\n42421728\n42432736\n[1271523197, 1271523198]\nCentral Park West\nsecondary\n25 mph\nFalse\nFalse\n86.275\nLINESTRING (995312.767 230030.016, 995334.152 ...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n\n\n3\n42435337\n42437916\n5670640\nWest 105th Street\nresidential\n25 mph\nTrue\nFalse\n137.996\nLINESTRING (995176.877 229785.340, 995144.253 ...\n1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n\n\n6\n42421731\n42437916\n5671485\nManhattan Avenue\nresidential\nNaN\nFalse\nTrue\n86.149\nLINESTRING (994916.519 230250.770, 994899.394 ...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n\n\n11\n42432736\n42435341\n1271523197\nCentral Park West\nsecondary\n25 mph\nFalse\nFalse\n80.116\nLINESTRING (995450.120 230277.316, 995461.822 ...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n\n\n13\n42437916\n42437917\n5670640\nWest 105th Street\nresidential\n25 mph\nTrue\nFalse\n135.012\nLINESTRING (994779.437 230003.728, 994751.078 ...\n1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n8.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n9864\n7802856372\n7802856349\n661227257\nCentral Park West\nsecondary\n25 mph\nFalse\nTrue\n80.457\nLINESTRING (990516.812 221373.627, 990505.794 ...\n4\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n\n\n9865\n7802856372\n7802856356\n[1271523171, 1271523172]\nCentral Park West\nsecondary\n25 mph\nFalse\nFalse\n79.496\nLINESTRING (990516.812 221373.627, 990527.802 ...\n4\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n4.0\n\n\n9867\n8288270047\n246580982\n5671698\nWest 16th Street\nresidential\n25 mph\nTrue\nFalse\n21.068\nLINESTRING (981879.246 210378.461, 981886.366 ...\n1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n6.0\n\n\n9869\n8840333851\n42453952\n5672377\nChurch Street\nsecondary\n25 mph\nTrue\nFalse\n83.590\nLINESTRING (981444.123 198698.940, 981458.126 ...\n3\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n\n\n9878\n11942111842\n42434962\n[658488325, 658499796, 658499797, 420872214, 6...\nNaN\nmotorway_link\nNaN\nTrue\nFalse\n290.747\nLINESTRING (991424.925 211158.515, 991364.955 ...\n[2, 1, 3]\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n\n\n\n\n5805 rows × 18 columns\n\n\n\n\n\n\n\n# Step 1: Calculate the crash index\nfiltered_df['crash_index'] = np.log10(filtered_df['crash_count'] / filtered_df['length'])\n\n# Step 2: Normalize the crash index\nmin_crash_index = filtered_df['crash_index'].min()\nmax_crash_index = filtered_df['crash_index'].max()\n\n# Normalize the crash_index to a 0-1 scale\nfiltered_df['crash_index_normalized'] = (filtered_df['crash_index'] - min_crash_index) / (max_crash_index - min_crash_index)\n\nfiltered_df\n\nC:\\Users\\txx11\\mambaforge\\envs\\musa-550-fall-2023\\lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\nC:\\Users\\txx11\\mambaforge\\envs\\musa-550-fall-2023\\lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\n\n\n\n\n\n\n\n\n\nu\nv\nosmid\nname\nhighway\nmaxspeed\noneway\nreversed\nlength\ngeometry\nlanes\nref\naccess\nbridge\ntunnel\nwidth\njunction\ncrash_count\ncrash_index\ncrash_index_normalized\n\n\n\n\n2\n42421728\n42432736\n[1271523197, 1271523198]\nCentral Park West\nsecondary\n25 mph\nFalse\nFalse\n86.275\nLINESTRING (995312.767 230030.016, 995334.152 ...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n-1.634855\n0.384469\n\n\n3\n42435337\n42437916\n5670640\nWest 105th Street\nresidential\n25 mph\nTrue\nFalse\n137.996\nLINESTRING (995176.877 229785.340, 995144.253 ...\n1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n-2.139866\n0.244838\n\n\n6\n42421731\n42437916\n5671485\nManhattan Avenue\nresidential\nNaN\nFalse\nTrue\n86.149\nLINESTRING (994916.519 230250.770, 994899.394 ...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n-1.935250\n0.301413\n\n\n11\n42432736\n42435341\n1271523197\nCentral Park West\nsecondary\n25 mph\nFalse\nFalse\n80.116\nLINESTRING (995450.120 230277.316, 995461.822 ...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n-1.602689\n0.393363\n\n\n13\n42437916\n42437917\n5670640\nWest 105th Street\nresidential\n25 mph\nTrue\nFalse\n135.012\nLINESTRING (994779.437 230003.728, 994751.078 ...\n1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n8.0\n-1.227282\n0.497160\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n9864\n7802856372\n7802856349\n661227257\nCentral Park West\nsecondary\n25 mph\nFalse\nTrue\n80.457\nLINESTRING (990516.812 221373.627, 990505.794 ...\n4\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n-1.905564\n0.309621\n\n\n9865\n7802856372\n7802856356\n[1271523171, 1271523172]\nCentral Park West\nsecondary\n25 mph\nFalse\nFalse\n79.496\nLINESTRING (990516.812 221373.627, 990527.802 ...\n4\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n4.0\n-1.298285\n0.477528\n\n\n9867\n8288270047\n246580982\n5671698\nWest 16th Street\nresidential\n25 mph\nTrue\nFalse\n21.068\nLINESTRING (981879.246 210378.461, 981886.366 ...\n1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n6.0\n-0.545472\n0.685674\n\n\n9869\n8840333851\n42453952\n5672377\nChurch Street\nsecondary\n25 mph\nTrue\nFalse\n83.590\nLINESTRING (981444.123 198698.940, 981458.126 ...\n3\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n-1.621124\n0.388266\n\n\n9878\n11942111842\n42434962\n[658488325, 658499796, 658499797, 420872214, 6...\nNaN\nmotorway_link\nNaN\nTrue\nFalse\n290.747\nLINESTRING (991424.925 211158.515, 991364.955 ...\n[2, 1, 3]\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n-2.463515\n0.155352\n\n\n\n\n5805 rows × 20 columns\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\n# Assuming filtered_df is already defined and contains 'crash_index_normalized'\n\n# Plot a histogram of the normalized crash index values\nplt.figure(figsize=(10, 6))\nplt.hist(filtered_df['crash_index_normalized'], bins=30, color='skyblue', edgecolor='black')\nplt.title('Histogram of Normalized Crash Index')\nplt.xlabel('Normalized Crash Index')\nplt.ylabel('Frequency')\nplt.grid(axis='y', alpha=0.75)\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nimport folium\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n\n# Assuming 'filtered_df' is your GeoDataFrame with the 'crash_index_normalized' column\n\n# Create a base map centered around the Central district with a dark theme\nm = folium.Map(location=[40.7826, -73.9656], zoom_start=12, tiles='CartoDB dark_matter')\n\n# Define a function to style the lines based on the crash index\ndef style_function(feature):\n    crash_index = feature['properties']['crash_index_normalized']\n    # Use the 'viridis' colormap for a color gradient\n    colormap = plt.cm.get_cmap('viridis')\n    # Get the RGBA color based on the crash index\n    color = colormap(crash_index)  # crash_index should already be normalized [0, 1]\n    # Convert RGBA to hex\n    color_hex = '#{:02x}{:02x}{:02x}'.format(int(color[0]*255), int(color[1]*255), int(color[2]*255))\n    return {\n        'color': color_hex,\n        'weight': 3 + crash_index * 2,  # Increase line weight for higher crash index\n        'opacity': 0.8\n    }\n\n# Add the GeoDataFrame to the map\nfolium.GeoJson(\n    filtered_df,\n    style_function=style_function,\n    tooltip=folium.GeoJsonTooltip(fields=['name', 'crash_index_normalized']),\n).add_to(m)\n\n\n# Display the map\nm\n\nC:\\Users\\txx11\\AppData\\Local\\Temp\\ipykernel_2124\\3546299534.py:14: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n  colormap = plt.cm.get_cmap('viridis')\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\nm.save('mahattan_crash_index_map_dark.html')\n\nC:\\Users\\txx11\\AppData\\Local\\Temp\\ipykernel_2124\\3546299534.py:14: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n  colormap = plt.cm.get_cmap('viridis')",
    "crumbs": [
      "Analysis",
      "I. Network Analysis"
    ]
  },
  {
    "objectID": "analysis/1-network.html#part-1-street-network-with-osmnx",
    "href": "analysis/1-network.html#part-1-street-network-with-osmnx",
    "title": "I. Network Analysis",
    "section": "",
    "text": "In this section, we wish to examine the crash data through street network on Manhattan to explore spatial patterns of crashes in certain area that might cause by congestions. We used the Motor Vehicle Collisions data from NYC Open data. Each row of the data contains one crash event, with information like location, time, causes, types of vehicles etc. We filtered the time from May 2021 to Dec 2023, in accordance with the date for traffic data in machine learning section.\n\n# The usual imports\nimport altair as alt\nimport geopandas as gpd\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n\n# Show all columns in dataframes\npd.options.display.max_columns = 999\n\n# Hide warnings due to issue in shapely package \n# See: https://github.com/shapely/shapely/issues/1345\nnp.seterr(invalid=\"ignore\");\nimport osmnx as ox\n\nNYC = gpd.read_file(\"new-york-city-boroughs.geojson\")\nNYC_M = NYC[NYC[\"name\"] == \"Manhattan\"]\n\nNYC_M\n\n\n\n\n\n# Project it to Web Mercator first and plot\nax = NYC_M.to_crs(epsg=4326).plot(facecolor=\"none\", edgecolor=\"black\")\nax.set_axis_off()\n\n\n\n\n\n\n\n\n\n\n\n\n# Define your polygon boundary (replace with your actual polygon)\n# For example, if you have a GeoDataFrame with your area boundary:\npolygon = NYC_M.unary_union  \n\n# Create a street network graph\nG = ox.graph_from_polygon(polygon, network_type='drive')\n\n# Convert graph edges to a GeoDataFrame\nedges_gdf = ox.graph_to_gdfs(G, nodes=False, edges=True)\n\n# Display the first few rows of the GeoDataFrame\nprint(edges_gdf.head())\n\n# Plot the edges GeoDataFrame\nfig, ax = plt.subplots(figsize=(20, 20))\nedges_gdf.plot(ax=ax, linewidth=1, edgecolor='black')\nplt.show()\n\n                                                 osmid               name  \\\nu        v        key                                                       \n42421728 42435337 0                          195743153  Central Park West   \n         42421731 0    [420625565, 420625573, 5668966]  West 106th Street   \n         42432736 0           [1271523197, 1271523198]  Central Park West   \n42421731 42437916 0                            5671485   Manhattan Avenue   \n         42432737 0                          195743186   Manhattan Avenue   \n\n                           highway maxspeed  oneway reversed   length  \\\nu        v        key                                                   \n42421728 42435337 0      secondary   25 mph   False     True   85.345   \n         42421731 0      secondary      NaN   False    False  138.033   \n         42432736 0      secondary   25 mph   False    False   86.275   \n42421731 42437916 0    residential      NaN   False     True   86.149   \n         42432737 0    residential      NaN   False    False   85.968   \n\n                                                                geometry  \\\nu        v        key                                                      \n42421728 42435337 0    LINESTRING (-73.96004 40.79805, -73.96011 40.7...   \n         42421731 0    LINESTRING (-73.96004 40.79805, -73.96017 40.7...   \n         42432736 0    LINESTRING (-73.96004 40.79805, -73.95997 40.7...   \n42421731 42437916 0    LINESTRING (-73.96147 40.79865, -73.96154 40.7...   \n         42432737 0    LINESTRING (-73.96147 40.79865, -73.96140 40.7...   \n\n                      lanes  ref access bridge tunnel width junction  \nu        v        key                                                 \n42421728 42435337 0     NaN  NaN    NaN    NaN    NaN   NaN      NaN  \n         42421731 0     NaN  NaN    NaN    NaN    NaN   NaN      NaN  \n         42432736 0     NaN  NaN    NaN    NaN    NaN   NaN      NaN  \n42421731 42437916 0     NaN  NaN    NaN    NaN    NaN   NaN      NaN  \n         42432737 0     NaN  NaN    NaN    NaN    NaN   NaN      NaN  \n\n\n\n\n\n\n\n\n\n\n\n\n\n# Load data into a pandas DataFrame\ndata = pd.read_csv(\"Motor_Vehicle_Collisions_Crashes.csv\")\n\n\ndata\n\n\n\n\n\n\n\n\nCRASH DATE\nCRASH TIME\nBOROUGH\nZIP CODE\nLATITUDE\nLONGITUDE\nLOCATION\nON STREET NAME\nCROSS STREET NAME\nOFF STREET NAME\nNUMBER OF PERSONS INJURED\nNUMBER OF PERSONS KILLED\nNUMBER OF PEDESTRIANS INJURED\nNUMBER OF PEDESTRIANS KILLED\nNUMBER OF CYCLIST INJURED\nNUMBER OF CYCLIST KILLED\nNUMBER OF MOTORIST INJURED\nNUMBER OF MOTORIST KILLED\nCONTRIBUTING FACTOR VEHICLE 1\nCONTRIBUTING FACTOR VEHICLE 2\nCONTRIBUTING FACTOR VEHICLE 3\nCONTRIBUTING FACTOR VEHICLE 4\nCONTRIBUTING FACTOR VEHICLE 5\nCOLLISION_ID\nVEHICLE TYPE CODE 1\nVEHICLE TYPE CODE 2\nVEHICLE TYPE CODE 3\nVEHICLE TYPE CODE 4\nVEHICLE TYPE CODE 5\n\n\n\n\n0\n05/01/2021\n13:30\nMANHATTAN\n10029.0\n40.796300\n-73.938290\n(40.7963, -73.93829)\nEAST 115 STREET\n2 AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nPassing or Lane Usage Improper\nUnspecified\nNaN\nNaN\nNaN\n4412937\nBus\nSedan\nNaN\nNaN\nNaN\n\n\n1\n05/01/2021\n17:50\nMANHATTAN\n10012.0\n40.720936\n-73.993805\n(40.720936, -73.993805)\nBOWERY\nSPRING STREET\nNaN\n1\n0\n0\n0\n0\n0\n1\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4412445\nSedan\nSedan\nNaN\nNaN\nNaN\n\n\n2\n05/01/2021\n13:30\nMANHATTAN\n10128.0\n40.780693\n-73.946600\n(40.780693, -73.9466)\nEAST 92 STREET\n1 AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4414390\nAMBULANCE\nSedan\nNaN\nNaN\nNaN\n\n\n3\n05/01/2021\n9:40\nMANHATTAN\n10026.0\n40.800537\n-73.948360\n(40.800537, -73.94836)\nNaN\nNaN\n40 WEST 115 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nBacking Unsafely\nUnspecified\nNaN\nNaN\nNaN\n4417017\nStation Wagon/Sport Utility Vehicle\nNaN\nNaN\nNaN\nNaN\n\n\n4\n05/01/2021\n23:03\nMANHATTAN\n10009.0\n40.726864\n-73.979910\n(40.726864, -73.97991)\nAVENUE B\nEAST 10 STREET\nNaN\n1\n0\n0\n0\n1\n0\n0\n0\nDriver Inattention/Distraction\nDriver Inattention/Distraction\nNaN\nNaN\nNaN\n4412243\nBike\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n32364\n12/31/2023\n23:18\nMANHATTAN\n10030.0\n40.819670\n-73.944240\n(40.81967, -73.94424)\n8 AVENUE\nWEST 140 STREET\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nDriver Inattention/Distraction\nNaN\nNaN\nNaN\nNaN\n4692572\nSedan\nNaN\nNaN\nNaN\nNaN\n\n\n32365\n12/31/2023\n18:03\nMANHATTAN\n10039.0\n40.824130\n-73.940980\n(40.82413, -73.94098)\n8 AVENUE\nWEST 147 STREET\nNaN\n1\n0\n1\n0\n0\n0\n0\n0\nUnspecified\nNaN\nNaN\nNaN\nNaN\n4692571\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n32366\n12/31/2023\n14:00\nMANHATTAN\n10028.0\n40.777890\n-73.955890\n(40.77789, -73.95589)\nNaN\nNaN\n160 EAST 84 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4692524\nSedan\nSedan\nNaN\nNaN\nNaN\n\n\n32367\n12/31/2023\n21:34\nMANHATTAN\n10033.0\n40.849308\n-73.931920\n(40.849308, -73.93192)\nWEST 182 STREET\nAUDUBON AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nUnspecified\nUnspecified\nNaN\nNaN\nNaN\n4692192\nStation Wagon/Sport Utility Vehicle\nSedan\nNaN\nNaN\nNaN\n\n\n32368\n12/31/2023\n0:38\nMANHATTAN\n10006.0\n40.709496\n-74.013900\n(40.709496, -74.0139)\nALBANY STREET\nWASHINGTON STREET\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nOther Vehicular\nUnspecified\nNaN\nNaN\nNaN\n4692585\nSedan\nPick-up Truck\nNaN\nNaN\nNaN\n\n\n\n\n32369 rows × 29 columns\n\n\n\n\n\n\n\nfrom shapely.geometry import Point\n\n# Check if the necessary columns exist\nif 'LATITUDE' in data.columns and 'LONGITUDE' in data.columns:\n    # Create a geometry column using the DEC_LAT and DEC_LONG columns\n    geometry = [Point(xy) for xy in zip(data['LONGITUDE'], data['LATITUDE'])]\n    \n    # Create a GeoDataFrame\n    gdf = gpd.GeoDataFrame(data, geometry=geometry)\n\n    # Set the coordinate reference system (CRS) to WGS 84 (EPSG:4326)\n    gdf.set_crs(epsg=4326, inplace=True)\n\n    # Display the first few rows of the GeoDataFrame\n    print(gdf.head())\nelse:\n    print(\"The DataFrame does not contain 'DEC_LAT' and 'DEC_LONG' columns.\")\n\n   CRASH DATE CRASH TIME    BOROUGH  ZIP CODE   LATITUDE  LONGITUDE  \\\n0  05/01/2021      13:30  MANHATTAN   10029.0  40.796300 -73.938290   \n1  05/01/2021      17:50  MANHATTAN   10012.0  40.720936 -73.993805   \n2  05/01/2021      13:30  MANHATTAN   10128.0  40.780693 -73.946600   \n3  05/01/2021       9:40  MANHATTAN   10026.0  40.800537 -73.948360   \n4  05/01/2021      23:03  MANHATTAN   10009.0  40.726864 -73.979910   \n\n                  LOCATION   ON STREET NAME CROSS STREET NAME  \\\n0     (40.7963, -73.93829)  EAST 115 STREET          2 AVENUE   \n1  (40.720936, -73.993805)           BOWERY     SPRING STREET   \n2    (40.780693, -73.9466)   EAST 92 STREET          1 AVENUE   \n3   (40.800537, -73.94836)              NaN               NaN   \n4   (40.726864, -73.97991)         AVENUE B    EAST 10 STREET   \n\n             OFF STREET NAME  NUMBER OF PERSONS INJURED  \\\n0                        NaN                          0   \n1                        NaN                          1   \n2                        NaN                          0   \n3  40        WEST 115 STREET                          0   \n4                        NaN                          1   \n\n   NUMBER OF PERSONS KILLED  NUMBER OF PEDESTRIANS INJURED  \\\n0                         0                              0   \n1                         0                              0   \n2                         0                              0   \n3                         0                              0   \n4                         0                              0   \n\n   NUMBER OF PEDESTRIANS KILLED  NUMBER OF CYCLIST INJURED  \\\n0                             0                          0   \n1                             0                          0   \n2                             0                          0   \n3                             0                          0   \n4                             0                          1   \n\n   NUMBER OF CYCLIST KILLED  NUMBER OF MOTORIST INJURED  \\\n0                         0                           0   \n1                         0                           1   \n2                         0                           0   \n3                         0                           0   \n4                         0                           0   \n\n   NUMBER OF MOTORIST KILLED   CONTRIBUTING FACTOR VEHICLE 1  \\\n0                          0  Passing or Lane Usage Improper   \n1                          0  Driver Inattention/Distraction   \n2                          0  Driver Inattention/Distraction   \n3                          0                Backing Unsafely   \n4                          0  Driver Inattention/Distraction   \n\n    CONTRIBUTING FACTOR VEHICLE 2 CONTRIBUTING FACTOR VEHICLE 3  \\\n0                     Unspecified                           NaN   \n1                     Unspecified                           NaN   \n2                     Unspecified                           NaN   \n3                     Unspecified                           NaN   \n4  Driver Inattention/Distraction                           NaN   \n\n  CONTRIBUTING FACTOR VEHICLE 4 CONTRIBUTING FACTOR VEHICLE 5  COLLISION_ID  \\\n0                           NaN                           NaN       4412937   \n1                           NaN                           NaN       4412445   \n2                           NaN                           NaN       4414390   \n3                           NaN                           NaN       4417017   \n4                           NaN                           NaN       4412243   \n\n                   VEHICLE TYPE CODE 1 VEHICLE TYPE CODE 2  \\\n0                                  Bus               Sedan   \n1                                Sedan               Sedan   \n2                            AMBULANCE               Sedan   \n3  Station Wagon/Sport Utility Vehicle                 NaN   \n4                                 Bike                 NaN   \n\n  VEHICLE TYPE CODE 3 VEHICLE TYPE CODE 4 VEHICLE TYPE CODE 5  \\\n0                 NaN                 NaN                 NaN   \n1                 NaN                 NaN                 NaN   \n2                 NaN                 NaN                 NaN   \n3                 NaN                 NaN                 NaN   \n4                 NaN                 NaN                 NaN   \n\n                     geometry  \n0  POINT (-73.93829 40.79630)  \n1  POINT (-73.99380 40.72094)  \n2  POINT (-73.94660 40.78069)  \n3  POINT (-73.94836 40.80054)  \n4  POINT (-73.97991 40.72686)  \n\n\n\n\n\n\n# Assuming edges_gdf is your GeoDataFrame from part 1.3\nmanhattan_boundary = edges_gdf.geometry.unary_union.convex_hull\n\n# Filter the crash GeoDataFrame to only include crashes within the boundary\nmanhattan_crashes = gdf[gdf.geometry.within(manhattan_boundary)]\n\n# Display the number of crashes within the Center City boundary\nprint(f\"Number of crashes within manhattan: {len(manhattan_crashes)}\")\n\n# Display the first few rows of the filtered GeoDataFrame\nmanhattan_crashes.head()\n\nNumber of crashes within manhattan: 31042\n\n\n\n\n\n\n\n\n\nCRASH DATE\nCRASH TIME\nBOROUGH\nZIP CODE\nLATITUDE\nLONGITUDE\nLOCATION\nON STREET NAME\nCROSS STREET NAME\nOFF STREET NAME\nNUMBER OF PERSONS INJURED\nNUMBER OF PERSONS KILLED\nNUMBER OF PEDESTRIANS INJURED\nNUMBER OF PEDESTRIANS KILLED\nNUMBER OF CYCLIST INJURED\nNUMBER OF CYCLIST KILLED\nNUMBER OF MOTORIST INJURED\nNUMBER OF MOTORIST KILLED\nCONTRIBUTING FACTOR VEHICLE 1\nCONTRIBUTING FACTOR VEHICLE 2\nCONTRIBUTING FACTOR VEHICLE 3\nCONTRIBUTING FACTOR VEHICLE 4\nCONTRIBUTING FACTOR VEHICLE 5\nCOLLISION_ID\nVEHICLE TYPE CODE 1\nVEHICLE TYPE CODE 2\nVEHICLE TYPE CODE 3\nVEHICLE TYPE CODE 4\nVEHICLE TYPE CODE 5\ngeometry\n\n\n\n\n0\n05/01/2021\n13:30\nMANHATTAN\n10029.0\n40.796300\n-73.938290\n(40.7963, -73.93829)\nEAST 115 STREET\n2 AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nPassing or Lane Usage Improper\nUnspecified\nNaN\nNaN\nNaN\n4412937\nBus\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.93829 40.79630)\n\n\n1\n05/01/2021\n17:50\nMANHATTAN\n10012.0\n40.720936\n-73.993805\n(40.720936, -73.993805)\nBOWERY\nSPRING STREET\nNaN\n1\n0\n0\n0\n0\n0\n1\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4412445\nSedan\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.99380 40.72094)\n\n\n2\n05/01/2021\n13:30\nMANHATTAN\n10128.0\n40.780693\n-73.946600\n(40.780693, -73.9466)\nEAST 92 STREET\n1 AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4414390\nAMBULANCE\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.94660 40.78069)\n\n\n3\n05/01/2021\n9:40\nMANHATTAN\n10026.0\n40.800537\n-73.948360\n(40.800537, -73.94836)\nNaN\nNaN\n40 WEST 115 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nBacking Unsafely\nUnspecified\nNaN\nNaN\nNaN\n4417017\nStation Wagon/Sport Utility Vehicle\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.94836 40.80054)\n\n\n4\n05/01/2021\n23:03\nMANHATTAN\n10009.0\n40.726864\n-73.979910\n(40.726864, -73.97991)\nAVENUE B\nEAST 10 STREET\nNaN\n1\n0\n0\n0\n1\n0\n0\n0\nDriver Inattention/Distraction\nDriver Inattention/Distraction\nNaN\nNaN\nNaN\n4412243\nBike\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.97991 40.72686)\n\n\n\n\n\n\n\n\n\n\n\nimport osmnx as ox\n\n# Assuming G is your graph object\n# Project the graph to the Philadelphia state plane CRS (EPSG:2272)\nG_projected = ox.project_graph(G, to_crs='EPSG:2263')\n\n# Project the crash GeoDataFrame to the Philadelphia state plane CRS (EPSG:2272)\nmanhattan_crashes_projected = manhattan_crashes.to_crs(epsg=2263)\n\n# Display the first few rows of the projected GeoDataFrame\nmanhattan_crashes_projected.head()\n\n# Create a plot\nfig, ax = plt.subplots(figsize=(12, 12))\n\n# Plot the street network\nedges_gdf_projected = ox.graph_to_gdfs(G_projected, nodes=False)\nedges_gdf_projected.plot(ax=ax, linewidth=1, edgecolor='gray', label='Street Network')\n\n# Plot the crash locations\nmanhattan_crashes_projected.plot(ax=ax, marker='o', color='red', markersize=5, label='Crashes')\n\n# Add a title and legend\nplt.title('Crash Locations in Manhattan with Street Network')\nplt.legend()\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nSee: ox.distance.nearest_edges(). It takes three arguments:\nthe network graph the longitude of your crash data (the x attribute of the geometry column) the latitude of your crash data (the y attribute of the geometry column) You will get a numpy array with 3 columns that represent (u, v, key) where each u and v are the node IDs that the edge links together. We will ignore the key value for our analysis.\n\n# Extract x and y coordinates from the geometry column\ncrash_x = manhattan_crashes_projected.geometry.x\ncrash_y = manhattan_crashes_projected.geometry.y\n\n# Find the nearest edges for each crash\nnearest_edges = ox.distance.nearest_edges(G_projected, crash_x, crash_y)\n\n# Convert the result to a numpy array\nnearest_edges_array = np.array(nearest_edges)\n\n# Display the first few results\nprint(nearest_edges_array[:5])\n\n# Extract only the u and v columns, ignoring the key\nnearest_edges_uv = nearest_edges_array[:, :2]\n\n# Display the first few u, v pairs\nprint(nearest_edges_uv[:5])\n\n[[4207962275   42443081          0]\n [  42437605 1773076509          0]\n [  42443048   42448745          0]\n [  42435387   42446772          0]\n [  42430924   42430938          0]]\n[[4207962275   42443081]\n [  42437605 1773076509]\n [  42443048   42448745]\n [  42435387   42446772]\n [  42430924   42430938]]\n\n\n\n\n\n\n# Create a DataFrame from the nearest edges data\nedges_df = pd.DataFrame(nearest_edges_array, columns=['u', 'v', 'key'])\n\n# Group by 'u' and 'v' and calculate the size of each group\ncrash_counts = edges_df.groupby(['u', 'v']).size().reset_index(name='crash_count')\n\n# Display the resulting DataFrame\ncrash_counts\n\n\n\n\n\n\n\n\nu\nv\ncrash_count\n\n\n\n\n0\n42421728\n42432736\n2\n\n\n1\n42421731\n42437916\n1\n\n\n2\n42421737\n42437917\n2\n\n\n3\n42421741\n42432756\n1\n\n\n4\n42421751\n42421749\n1\n\n\n...\n...\n...\n...\n\n\n5796\n12162436970\n42455357\n2\n\n\n5797\n12181309686\n4597668039\n5\n\n\n5798\n12299314857\n12299314860\n1\n\n\n5799\n12299314860\n42438476\n3\n\n\n5800\n12374690312\n42433537\n1\n\n\n\n\n5801 rows × 3 columns\n\n\n\n\n\n\n\n# Convert the projected graph to a GeoDataFrame for edges\nedges_gdf_projected = ox.graph_to_gdfs(G_projected, nodes=False)\n\n# Merge the edges GeoDataFrame with the crash counts DataFrame\nmerged_df = edges_gdf_projected.merge(crash_counts, on=['u', 'v'], how='left')\n\n# Fill missing crash count values with zero\nmerged_df['crash_count'] = merged_df['crash_count'].fillna(0)\n\n# Display the first few rows of the merged DataFrame\nmerged_df\n\n# Filter out rows where crash_count is 0.0\nfiltered_df = merged_df[merged_df['crash_count'] &gt; 0.0]\n\n# Display the first few rows of the filtered DataFrame\nfiltered_df\n\n\n\n\n\n\n\n\nu\nv\nosmid\nname\nhighway\nmaxspeed\noneway\nreversed\nlength\ngeometry\nlanes\nref\naccess\nbridge\ntunnel\nwidth\njunction\ncrash_count\n\n\n\n\n2\n42421728\n42432736\n[1271523197, 1271523198]\nCentral Park West\nsecondary\n25 mph\nFalse\nFalse\n86.275\nLINESTRING (995312.767 230030.016, 995334.152 ...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n\n\n3\n42435337\n42437916\n5670640\nWest 105th Street\nresidential\n25 mph\nTrue\nFalse\n137.996\nLINESTRING (995176.877 229785.340, 995144.253 ...\n1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n\n\n6\n42421731\n42437916\n5671485\nManhattan Avenue\nresidential\nNaN\nFalse\nTrue\n86.149\nLINESTRING (994916.519 230250.770, 994899.394 ...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n\n\n11\n42432736\n42435341\n1271523197\nCentral Park West\nsecondary\n25 mph\nFalse\nFalse\n80.116\nLINESTRING (995450.120 230277.316, 995461.822 ...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n\n\n13\n42437916\n42437917\n5670640\nWest 105th Street\nresidential\n25 mph\nTrue\nFalse\n135.012\nLINESTRING (994779.437 230003.728, 994751.078 ...\n1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n8.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n9864\n7802856372\n7802856349\n661227257\nCentral Park West\nsecondary\n25 mph\nFalse\nTrue\n80.457\nLINESTRING (990516.812 221373.627, 990505.794 ...\n4\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n\n\n9865\n7802856372\n7802856356\n[1271523171, 1271523172]\nCentral Park West\nsecondary\n25 mph\nFalse\nFalse\n79.496\nLINESTRING (990516.812 221373.627, 990527.802 ...\n4\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n4.0\n\n\n9867\n8288270047\n246580982\n5671698\nWest 16th Street\nresidential\n25 mph\nTrue\nFalse\n21.068\nLINESTRING (981879.246 210378.461, 981886.366 ...\n1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n6.0\n\n\n9869\n8840333851\n42453952\n5672377\nChurch Street\nsecondary\n25 mph\nTrue\nFalse\n83.590\nLINESTRING (981444.123 198698.940, 981458.126 ...\n3\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n\n\n9878\n11942111842\n42434962\n[658488325, 658499796, 658499797, 420872214, 6...\nNaN\nmotorway_link\nNaN\nTrue\nFalse\n290.747\nLINESTRING (991424.925 211158.515, 991364.955 ...\n[2, 1, 3]\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n\n\n\n\n5805 rows × 18 columns\n\n\n\n\n\n\n\n# Step 1: Calculate the crash index\nfiltered_df['crash_index'] = np.log10(filtered_df['crash_count'] / filtered_df['length'])\n\n# Step 2: Normalize the crash index\nmin_crash_index = filtered_df['crash_index'].min()\nmax_crash_index = filtered_df['crash_index'].max()\n\n# Normalize the crash_index to a 0-1 scale\nfiltered_df['crash_index_normalized'] = (filtered_df['crash_index'] - min_crash_index) / (max_crash_index - min_crash_index)\n\nfiltered_df\n\nC:\\Users\\txx11\\mambaforge\\envs\\musa-550-fall-2023\\lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\nC:\\Users\\txx11\\mambaforge\\envs\\musa-550-fall-2023\\lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\n\n\n\n\n\n\n\n\n\nu\nv\nosmid\nname\nhighway\nmaxspeed\noneway\nreversed\nlength\ngeometry\nlanes\nref\naccess\nbridge\ntunnel\nwidth\njunction\ncrash_count\ncrash_index\ncrash_index_normalized\n\n\n\n\n2\n42421728\n42432736\n[1271523197, 1271523198]\nCentral Park West\nsecondary\n25 mph\nFalse\nFalse\n86.275\nLINESTRING (995312.767 230030.016, 995334.152 ...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n-1.634855\n0.384469\n\n\n3\n42435337\n42437916\n5670640\nWest 105th Street\nresidential\n25 mph\nTrue\nFalse\n137.996\nLINESTRING (995176.877 229785.340, 995144.253 ...\n1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n-2.139866\n0.244838\n\n\n6\n42421731\n42437916\n5671485\nManhattan Avenue\nresidential\nNaN\nFalse\nTrue\n86.149\nLINESTRING (994916.519 230250.770, 994899.394 ...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n-1.935250\n0.301413\n\n\n11\n42432736\n42435341\n1271523197\nCentral Park West\nsecondary\n25 mph\nFalse\nFalse\n80.116\nLINESTRING (995450.120 230277.316, 995461.822 ...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n-1.602689\n0.393363\n\n\n13\n42437916\n42437917\n5670640\nWest 105th Street\nresidential\n25 mph\nTrue\nFalse\n135.012\nLINESTRING (994779.437 230003.728, 994751.078 ...\n1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n8.0\n-1.227282\n0.497160\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n9864\n7802856372\n7802856349\n661227257\nCentral Park West\nsecondary\n25 mph\nFalse\nTrue\n80.457\nLINESTRING (990516.812 221373.627, 990505.794 ...\n4\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n-1.905564\n0.309621\n\n\n9865\n7802856372\n7802856356\n[1271523171, 1271523172]\nCentral Park West\nsecondary\n25 mph\nFalse\nFalse\n79.496\nLINESTRING (990516.812 221373.627, 990527.802 ...\n4\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n4.0\n-1.298285\n0.477528\n\n\n9867\n8288270047\n246580982\n5671698\nWest 16th Street\nresidential\n25 mph\nTrue\nFalse\n21.068\nLINESTRING (981879.246 210378.461, 981886.366 ...\n1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n6.0\n-0.545472\n0.685674\n\n\n9869\n8840333851\n42453952\n5672377\nChurch Street\nsecondary\n25 mph\nTrue\nFalse\n83.590\nLINESTRING (981444.123 198698.940, 981458.126 ...\n3\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n-1.621124\n0.388266\n\n\n9878\n11942111842\n42434962\n[658488325, 658499796, 658499797, 420872214, 6...\nNaN\nmotorway_link\nNaN\nTrue\nFalse\n290.747\nLINESTRING (991424.925 211158.515, 991364.955 ...\n[2, 1, 3]\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1.0\n-2.463515\n0.155352\n\n\n\n\n5805 rows × 20 columns\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\n# Assuming filtered_df is already defined and contains 'crash_index_normalized'\n\n# Plot a histogram of the normalized crash index values\nplt.figure(figsize=(10, 6))\nplt.hist(filtered_df['crash_index_normalized'], bins=30, color='skyblue', edgecolor='black')\nplt.title('Histogram of Normalized Crash Index')\nplt.xlabel('Normalized Crash Index')\nplt.ylabel('Frequency')\nplt.grid(axis='y', alpha=0.75)\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nimport folium\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n\n# Assuming 'filtered_df' is your GeoDataFrame with the 'crash_index_normalized' column\n\n# Create a base map centered around the Central district with a dark theme\nm = folium.Map(location=[40.7826, -73.9656], zoom_start=12, tiles='CartoDB dark_matter')\n\n# Define a function to style the lines based on the crash index\ndef style_function(feature):\n    crash_index = feature['properties']['crash_index_normalized']\n    # Use the 'viridis' colormap for a color gradient\n    colormap = plt.cm.get_cmap('viridis')\n    # Get the RGBA color based on the crash index\n    color = colormap(crash_index)  # crash_index should already be normalized [0, 1]\n    # Convert RGBA to hex\n    color_hex = '#{:02x}{:02x}{:02x}'.format(int(color[0]*255), int(color[1]*255), int(color[2]*255))\n    return {\n        'color': color_hex,\n        'weight': 3 + crash_index * 2,  # Increase line weight for higher crash index\n        'opacity': 0.8\n    }\n\n# Add the GeoDataFrame to the map\nfolium.GeoJson(\n    filtered_df,\n    style_function=style_function,\n    tooltip=folium.GeoJsonTooltip(fields=['name', 'crash_index_normalized']),\n).add_to(m)\n\n\n# Display the map\nm\n\nC:\\Users\\txx11\\AppData\\Local\\Temp\\ipykernel_2124\\3546299534.py:14: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n  colormap = plt.cm.get_cmap('viridis')\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\nm.save('mahattan_crash_index_map_dark.html')\n\nC:\\Users\\txx11\\AppData\\Local\\Temp\\ipykernel_2124\\3546299534.py:14: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n  colormap = plt.cm.get_cmap('viridis')",
    "crumbs": [
      "Analysis",
      "I. Network Analysis"
    ]
  },
  {
    "objectID": "analysis/1-network.html#part-2-density-map-of-crashes-by-time-of-the-day",
    "href": "analysis/1-network.html#part-2-density-map-of-crashes-by-time-of-the-day",
    "title": "I. Network Analysis",
    "section": "Part 2: Density Map of Crashes by time of the day",
    "text": "Part 2: Density Map of Crashes by time of the day\n\n#load large data\ndat2 = pd.read_csv(\"Crash data_large.csv\")\n\n\nif 'LATITUDE' in dat2.columns and 'LONGITUDE' in data.columns:\n    # Create a geometry column using the DEC_LAT and DEC_LONG columns\n    geometry = [Point(xy) for xy in zip(data['LONGITUDE'], data['LATITUDE'])]\n    \n    # Create a GeoDataFrame\n    gdf2 = gpd.GeoDataFrame(data, geometry=geometry)\n\n    # Set the coordinate reference system (CRS) to WGS 84 (EPSG:4326)\n    gdf2.set_crs(epsg=4326, inplace=True)\n\n# Filter the crash GeoDataFrame to only include crashes within the boundary\ndat2 = gdf[gdf.geometry.within(manhattan_boundary)]\n\n# Display the number of crashes within the Center City boundary\nprint(f\"Number of crashes within manhattan: {len(manhattan_crashes)}\")\n\n# Display the first few rows of the filtered GeoDataFrame\ndat2.head()\n\nNumber of crashes within manhattan: 31042\n\n\n\n\n\n\n\n\n\nCRASH DATE\nCRASH TIME\nBOROUGH\nZIP CODE\nLATITUDE\nLONGITUDE\nLOCATION\nON STREET NAME\nCROSS STREET NAME\nOFF STREET NAME\nNUMBER OF PERSONS INJURED\nNUMBER OF PERSONS KILLED\nNUMBER OF PEDESTRIANS INJURED\nNUMBER OF PEDESTRIANS KILLED\nNUMBER OF CYCLIST INJURED\nNUMBER OF CYCLIST KILLED\nNUMBER OF MOTORIST INJURED\nNUMBER OF MOTORIST KILLED\nCONTRIBUTING FACTOR VEHICLE 1\nCONTRIBUTING FACTOR VEHICLE 2\nCONTRIBUTING FACTOR VEHICLE 3\nCONTRIBUTING FACTOR VEHICLE 4\nCONTRIBUTING FACTOR VEHICLE 5\nCOLLISION_ID\nVEHICLE TYPE CODE 1\nVEHICLE TYPE CODE 2\nVEHICLE TYPE CODE 3\nVEHICLE TYPE CODE 4\nVEHICLE TYPE CODE 5\ngeometry\n\n\n\n\n0\n05/01/2021\n13:30\nMANHATTAN\n10029.0\n40.796300\n-73.938290\n(40.7963, -73.93829)\nEAST 115 STREET\n2 AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nPassing or Lane Usage Improper\nUnspecified\nNaN\nNaN\nNaN\n4412937\nBus\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.93829 40.79630)\n\n\n1\n05/01/2021\n17:50\nMANHATTAN\n10012.0\n40.720936\n-73.993805\n(40.720936, -73.993805)\nBOWERY\nSPRING STREET\nNaN\n1\n0\n0\n0\n0\n0\n1\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4412445\nSedan\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.99380 40.72094)\n\n\n2\n05/01/2021\n13:30\nMANHATTAN\n10128.0\n40.780693\n-73.946600\n(40.780693, -73.9466)\nEAST 92 STREET\n1 AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4414390\nAMBULANCE\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.94660 40.78069)\n\n\n3\n05/01/2021\n9:40\nMANHATTAN\n10026.0\n40.800537\n-73.948360\n(40.800537, -73.94836)\nNaN\nNaN\n40 WEST 115 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nBacking Unsafely\nUnspecified\nNaN\nNaN\nNaN\n4417017\nStation Wagon/Sport Utility Vehicle\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.94836 40.80054)\n\n\n4\n05/01/2021\n23:03\nMANHATTAN\n10009.0\n40.726864\n-73.979910\n(40.726864, -73.97991)\nAVENUE B\nEAST 10 STREET\nNaN\n1\n0\n0\n0\n1\n0\n0\n0\nDriver Inattention/Distraction\nDriver Inattention/Distraction\nNaN\nNaN\nNaN\n4412243\nBike\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.97991 40.72686)\n\n\n\n\n\n\n\n\n# Convert 'CRASH TIME' to datetime format if it's not already in datetime\ndat2['CRASH TIME'] = pd.to_datetime(dat2['CRASH TIME'], format='%H:%M')\n\n# Extract the hour from 'CRASH TIME' and create a new column called 'CRASH HOUR'\ndat2['CRASH HOUR'] = dat2['CRASH TIME'].dt.hour\n\ndat2\n\nC:\\Users\\txx11\\mambaforge\\envs\\musa-550-fall-2023\\lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\nC:\\Users\\txx11\\mambaforge\\envs\\musa-550-fall-2023\\lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\n\n\n\n\n\n\n\n\n\nCRASH DATE\nCRASH TIME\nBOROUGH\nZIP CODE\nLATITUDE\nLONGITUDE\nLOCATION\nON STREET NAME\nCROSS STREET NAME\nOFF STREET NAME\nNUMBER OF PERSONS INJURED\nNUMBER OF PERSONS KILLED\nNUMBER OF PEDESTRIANS INJURED\nNUMBER OF PEDESTRIANS KILLED\nNUMBER OF CYCLIST INJURED\nNUMBER OF CYCLIST KILLED\nNUMBER OF MOTORIST INJURED\nNUMBER OF MOTORIST KILLED\nCONTRIBUTING FACTOR VEHICLE 1\nCONTRIBUTING FACTOR VEHICLE 2\nCONTRIBUTING FACTOR VEHICLE 3\nCONTRIBUTING FACTOR VEHICLE 4\nCONTRIBUTING FACTOR VEHICLE 5\nCOLLISION_ID\nVEHICLE TYPE CODE 1\nVEHICLE TYPE CODE 2\nVEHICLE TYPE CODE 3\nVEHICLE TYPE CODE 4\nVEHICLE TYPE CODE 5\ngeometry\nCRASH HOUR\n\n\n\n\n0\n05/01/2021\n1900-01-01 13:30:00\nMANHATTAN\n10029.0\n40.796300\n-73.938290\n(40.7963, -73.93829)\nEAST 115 STREET\n2 AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nPassing or Lane Usage Improper\nUnspecified\nNaN\nNaN\nNaN\n4412937\nBus\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.93829 40.79630)\n13\n\n\n1\n05/01/2021\n1900-01-01 17:50:00\nMANHATTAN\n10012.0\n40.720936\n-73.993805\n(40.720936, -73.993805)\nBOWERY\nSPRING STREET\nNaN\n1\n0\n0\n0\n0\n0\n1\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4412445\nSedan\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.99380 40.72094)\n17\n\n\n2\n05/01/2021\n1900-01-01 13:30:00\nMANHATTAN\n10128.0\n40.780693\n-73.946600\n(40.780693, -73.9466)\nEAST 92 STREET\n1 AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4414390\nAMBULANCE\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.94660 40.78069)\n13\n\n\n3\n05/01/2021\n1900-01-01 09:40:00\nMANHATTAN\n10026.0\n40.800537\n-73.948360\n(40.800537, -73.94836)\nNaN\nNaN\n40 WEST 115 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nBacking Unsafely\nUnspecified\nNaN\nNaN\nNaN\n4417017\nStation Wagon/Sport Utility Vehicle\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.94836 40.80054)\n9\n\n\n4\n05/01/2021\n1900-01-01 23:03:00\nMANHATTAN\n10009.0\n40.726864\n-73.979910\n(40.726864, -73.97991)\nAVENUE B\nEAST 10 STREET\nNaN\n1\n0\n0\n0\n1\n0\n0\n0\nDriver Inattention/Distraction\nDriver Inattention/Distraction\nNaN\nNaN\nNaN\n4412243\nBike\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.97991 40.72686)\n23\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n32364\n12/31/2023\n1900-01-01 23:18:00\nMANHATTAN\n10030.0\n40.819670\n-73.944240\n(40.81967, -73.94424)\n8 AVENUE\nWEST 140 STREET\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nDriver Inattention/Distraction\nNaN\nNaN\nNaN\nNaN\n4692572\nSedan\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.94424 40.81967)\n23\n\n\n32365\n12/31/2023\n1900-01-01 18:03:00\nMANHATTAN\n10039.0\n40.824130\n-73.940980\n(40.82413, -73.94098)\n8 AVENUE\nWEST 147 STREET\nNaN\n1\n0\n1\n0\n0\n0\n0\n0\nUnspecified\nNaN\nNaN\nNaN\nNaN\n4692571\nNaN\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.94098 40.82413)\n18\n\n\n32366\n12/31/2023\n1900-01-01 14:00:00\nMANHATTAN\n10028.0\n40.777890\n-73.955890\n(40.77789, -73.95589)\nNaN\nNaN\n160 EAST 84 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nDriver Inattention/Distraction\nUnspecified\nNaN\nNaN\nNaN\n4692524\nSedan\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.95589 40.77789)\n14\n\n\n32367\n12/31/2023\n1900-01-01 21:34:00\nMANHATTAN\n10033.0\n40.849308\n-73.931920\n(40.849308, -73.93192)\nWEST 182 STREET\nAUDUBON AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nUnspecified\nUnspecified\nNaN\nNaN\nNaN\n4692192\nStation Wagon/Sport Utility Vehicle\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.93192 40.84931)\n21\n\n\n32368\n12/31/2023\n1900-01-01 00:38:00\nMANHATTAN\n10006.0\n40.709496\n-74.013900\n(40.709496, -74.0139)\nALBANY STREET\nWASHINGTON STREET\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nOther Vehicular\nUnspecified\nNaN\nNaN\nNaN\n4692585\nSedan\nPick-up Truck\nNaN\nNaN\nNaN\nPOINT (-74.01390 40.70950)\n0\n\n\n\n\n31042 rows × 31 columns\n\n\n\n\nfrom colorcet import fire\nimport hvplot.pandas\n\nimport holoviews as hv\nimport geoviews as gv\n\n\n\n\n\n\n\n\n\n\n\nplot1 = dat2.hvplot.points(\n    geo=True,  # Enables geographic plotting\n    x='LONGITUDE',  # Longitude for x-axis\n    y='LATITUDE',  # Latitude for y-axis\n    frame_width=800,  # Set frame width\n    frame_height=600,  # Set frame height\n    cmap=fire,  # Use the Fire colormap\n    datashade=True,  # Enable datashading for large datasets\n    crs=4326,\n    title='Manhattan Crashes'  # Set the plot title\n)\n\n# Add a dark background map\nbg = gv.tile_sources.CartoDark\n\n# Combine the background map and the plot\nbg * plot1\n\n\n\n\n\n  \n\n\n\n\n\nplot2 = dat2.hvplot.points(\n    geo=True,  # Enables geographic plotting\n    x='LONGITUDE',  # Longitude for x-axis\n    y='LATITUDE',  # Latitude for y-axis\n    frame_width=800,  # Set frame width\n    frame_height=600,  # Set frame height\n    cmap=fire,  # Use the Fire colormap\n    datashade=True,  # Enable datashading for large datasets\n    crs=4326,\n    groupby = \"CRASH HOUR\",\n    title='Manhattan Crashes'  # Set the plot title\n)\n\n# Add a dark background map\nbg = gv.tile_sources.CartoDark\n\n# Combine the background map and the plot\nbg * plot2",
    "crumbs": [
      "Analysis",
      "I. Network Analysis"
    ]
  },
  {
    "objectID": "analysis/1-network.html#part-3-density-map-of-crashes-due-to-passfollowing-too-closely",
    "href": "analysis/1-network.html#part-3-density-map-of-crashes-due-to-passfollowing-too-closely",
    "title": "I. Network Analysis",
    "section": "Part 3: Density Map of Crashes due to pass/following too closely",
    "text": "Part 3: Density Map of Crashes due to pass/following too closely\n\nimport altair as alt\n\n# Count the occurrences of each contributing factor\nfactor_counts = manhattan_crashes[\"CONTRIBUTING FACTOR VEHICLE 1\"].value_counts().reset_index()\nfactor_counts.columns = [\"Contributing Factor\", \"Frequency\"]\n\n# Select the top 10 contributing factors\ntop_10_factors = factor_counts.head(10)\n\n# Create a bar chart using Altair\nchart = alt.Chart(top_10_factors).mark_bar().encode(\n    x=alt.X(\"Frequency:Q\", title=\"Frequency\"),\n    y=alt.Y(\"Contributing Factor:N\", sort='-x', title=\"Contributing Factor\"),\n    color=alt.Color(\"Contributing Factor:N\", legend=None),  # Color by factor, no legend\n    tooltip=[\n        alt.Tooltip(\"Contributing Factor:N\", title=\"Factor\"),\n        alt.Tooltip(\"Frequency:Q\", title=\"Count\")\n    ]\n).properties(\n    title=\"Top 10 Contributing Factors for Vehicle Crashes in Manhattan (2021-2023)\",\n    width=600,\n    height=400\n)\n\n# Display the chart\nchart\n\n\n\n\n\n\n\n\nmanhattan_crashes_filtered = manhattan_crashes[\n    (manhattan_crashes[\"CONTRIBUTING FACTOR VEHICLE 1\"] == \"Passing Too Closely\") |\n    (manhattan_crashes[\"CONTRIBUTING FACTOR VEHICLE 1\"] == \"Following Too Closely\")\n]\n\nmanhattan_crashes_filtered\n\n\n\n\n\n\n\n\nCRASH DATE\nCRASH TIME\nBOROUGH\nZIP CODE\nLATITUDE\nLONGITUDE\nLOCATION\nON STREET NAME\nCROSS STREET NAME\nOFF STREET NAME\nNUMBER OF PERSONS INJURED\nNUMBER OF PERSONS KILLED\nNUMBER OF PEDESTRIANS INJURED\nNUMBER OF PEDESTRIANS KILLED\nNUMBER OF CYCLIST INJURED\nNUMBER OF CYCLIST KILLED\nNUMBER OF MOTORIST INJURED\nNUMBER OF MOTORIST KILLED\nCONTRIBUTING FACTOR VEHICLE 1\nCONTRIBUTING FACTOR VEHICLE 2\nCONTRIBUTING FACTOR VEHICLE 3\nCONTRIBUTING FACTOR VEHICLE 4\nCONTRIBUTING FACTOR VEHICLE 5\nCOLLISION_ID\nVEHICLE TYPE CODE 1\nVEHICLE TYPE CODE 2\nVEHICLE TYPE CODE 3\nVEHICLE TYPE CODE 4\nVEHICLE TYPE CODE 5\ngeometry\n\n\n\n\n5\n05/01/2021\n3:01\nMANHATTAN\n10032.0\n40.832886\n-73.944020\n(40.832886, -73.94402)\nNaN\nNaN\n555 WEST 156 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nPassing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4413557\nTaxi\nStation Wagon/Sport Utility Vehicle\nNaN\nNaN\nNaN\nPOINT (-73.94402 40.83289)\n\n\n20\n05/01/2021\n13:54\nMANHATTAN\n10036.0\n40.761300\n-73.999435\n(40.7613, -73.999435)\nNaN\nNaN\n635 WEST 42 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nPassing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4413013\nStation Wagon/Sport Utility Vehicle\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.99944 40.76130)\n\n\n22\n05/01/2021\n17:55\nMANHATTAN\n10029.0\n40.799984\n-73.944855\n(40.799984, -73.944855)\nEAST 116 STREET\nMADISON AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nPassing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4412865\nSedan\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.94486 40.79998)\n\n\n34\n05/01/2021\n9:45\nMANHATTAN\n10035.0\n40.802753\n-73.933580\n(40.802753, -73.93358)\nEAST 125 STREET\n2 AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nFollowing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4412859\nSedan\nBox Truck\nNaN\nNaN\nNaN\nPOINT (-73.93358 40.80275)\n\n\n46\n05/02/2021\n12:15\nMANHATTAN\n10037.0\n40.810024\n-73.937540\n(40.810024, -73.93754)\nNaN\nNaN\n2096 MADISON AVENUE\n0\n0\n0\n0\n0\n0\n0\n0\nFollowing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4412870\nSedan\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.93754 40.81002)\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n32333\n12/30/2023\n3:04\nMANHATTAN\n10029.0\n40.790817\n-73.942880\n(40.790817, -73.94288)\nNaN\nNaN\n231 EAST 106 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nPassing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4691754\nStation Wagon/Sport Utility Vehicle\nStation Wagon/Sport Utility Vehicle\nNaN\nNaN\nNaN\nPOINT (-73.94288 40.79082)\n\n\n32340\n12/30/2023\n17:40\nMANHATTAN\n10001.0\n40.747234\n-73.993370\n(40.747234, -73.99337)\nWEST 28 STREET\n7 AVENUE\nNaN\n1\n0\n0\n0\n0\n0\n1\n0\nFollowing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4692517\nTaxi\nBox Truck\nNaN\nNaN\nNaN\nPOINT (-73.99337 40.74723)\n\n\n32349\n12/31/2023\n22:40\nMANHATTAN\n10019.0\n40.767130\n-73.993730\n(40.76713, -73.99373)\n11 AVENUE\nWEST 52 STREET\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nFollowing Too Closely\nTurning Improperly\nNaN\nNaN\nNaN\n4693643\nStation Wagon/Sport Utility Vehicle\nBus\nNaN\nNaN\nNaN\nPOINT (-73.99373 40.76713)\n\n\n32351\n12/31/2023\n16:24\nMANHATTAN\n10027.0\n40.809310\n-73.949120\n(40.80931, -73.94912)\nNaN\nNaN\n215 WEST 125 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nPassing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4693991\nSedan\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.94912 40.80931)\n\n\n32359\n12/31/2023\n21:16\nMANHATTAN\n10011.0\n40.738250\n-74.001080\n(40.73825, -74.00108)\nNaN\nNaN\n237 WEST 13 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nPassing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4691995\nStation Wagon/Sport Utility Vehicle\nNaN\nNaN\nNaN\nNaN\nPOINT (-74.00108 40.73825)\n\n\n\n\n2789 rows × 30 columns\n\n\n\n\nAdd hour\n\n# Convert 'CRASH TIME' to datetime format if it's not already in datetime\nmanhattan_crashes_filtered['CRASH TIME'] = pd.to_datetime(manhattan_crashes_filtered['CRASH TIME'], format='%H:%M')\n\n# Extract the hour from 'CRASH TIME' and create a new column called 'CRASH HOUR'\nmanhattan_crashes_filtered['CRASH HOUR'] = manhattan_crashes_filtered['CRASH TIME'].dt.hour\n\nmanhattan_crashes_filtered\n\nC:\\Users\\txx11\\mambaforge\\envs\\musa-550-fall-2023\\lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\nC:\\Users\\txx11\\mambaforge\\envs\\musa-550-fall-2023\\lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\n\n\n\n\n\n\n\n\n\nCRASH DATE\nCRASH TIME\nBOROUGH\nZIP CODE\nLATITUDE\nLONGITUDE\nLOCATION\nON STREET NAME\nCROSS STREET NAME\nOFF STREET NAME\nNUMBER OF PERSONS INJURED\nNUMBER OF PERSONS KILLED\nNUMBER OF PEDESTRIANS INJURED\nNUMBER OF PEDESTRIANS KILLED\nNUMBER OF CYCLIST INJURED\nNUMBER OF CYCLIST KILLED\nNUMBER OF MOTORIST INJURED\nNUMBER OF MOTORIST KILLED\nCONTRIBUTING FACTOR VEHICLE 1\nCONTRIBUTING FACTOR VEHICLE 2\nCONTRIBUTING FACTOR VEHICLE 3\nCONTRIBUTING FACTOR VEHICLE 4\nCONTRIBUTING FACTOR VEHICLE 5\nCOLLISION_ID\nVEHICLE TYPE CODE 1\nVEHICLE TYPE CODE 2\nVEHICLE TYPE CODE 3\nVEHICLE TYPE CODE 4\nVEHICLE TYPE CODE 5\ngeometry\nCRASH HOUR\n\n\n\n\n5\n05/01/2021\n1900-01-01 03:01:00\nMANHATTAN\n10032.0\n40.832886\n-73.944020\n(40.832886, -73.94402)\nNaN\nNaN\n555 WEST 156 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nPassing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4413557\nTaxi\nStation Wagon/Sport Utility Vehicle\nNaN\nNaN\nNaN\nPOINT (-73.94402 40.83289)\n3\n\n\n20\n05/01/2021\n1900-01-01 13:54:00\nMANHATTAN\n10036.0\n40.761300\n-73.999435\n(40.7613, -73.999435)\nNaN\nNaN\n635 WEST 42 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nPassing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4413013\nStation Wagon/Sport Utility Vehicle\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.99944 40.76130)\n13\n\n\n22\n05/01/2021\n1900-01-01 17:55:00\nMANHATTAN\n10029.0\n40.799984\n-73.944855\n(40.799984, -73.944855)\nEAST 116 STREET\nMADISON AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nPassing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4412865\nSedan\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.94486 40.79998)\n17\n\n\n34\n05/01/2021\n1900-01-01 09:45:00\nMANHATTAN\n10035.0\n40.802753\n-73.933580\n(40.802753, -73.93358)\nEAST 125 STREET\n2 AVENUE\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nFollowing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4412859\nSedan\nBox Truck\nNaN\nNaN\nNaN\nPOINT (-73.93358 40.80275)\n9\n\n\n46\n05/02/2021\n1900-01-01 12:15:00\nMANHATTAN\n10037.0\n40.810024\n-73.937540\n(40.810024, -73.93754)\nNaN\nNaN\n2096 MADISON AVENUE\n0\n0\n0\n0\n0\n0\n0\n0\nFollowing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4412870\nSedan\nNaN\nNaN\nNaN\nNaN\nPOINT (-73.93754 40.81002)\n12\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n32333\n12/30/2023\n1900-01-01 03:04:00\nMANHATTAN\n10029.0\n40.790817\n-73.942880\n(40.790817, -73.94288)\nNaN\nNaN\n231 EAST 106 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nPassing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4691754\nStation Wagon/Sport Utility Vehicle\nStation Wagon/Sport Utility Vehicle\nNaN\nNaN\nNaN\nPOINT (-73.94288 40.79082)\n3\n\n\n32340\n12/30/2023\n1900-01-01 17:40:00\nMANHATTAN\n10001.0\n40.747234\n-73.993370\n(40.747234, -73.99337)\nWEST 28 STREET\n7 AVENUE\nNaN\n1\n0\n0\n0\n0\n0\n1\n0\nFollowing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4692517\nTaxi\nBox Truck\nNaN\nNaN\nNaN\nPOINT (-73.99337 40.74723)\n17\n\n\n32349\n12/31/2023\n1900-01-01 22:40:00\nMANHATTAN\n10019.0\n40.767130\n-73.993730\n(40.76713, -73.99373)\n11 AVENUE\nWEST 52 STREET\nNaN\n0\n0\n0\n0\n0\n0\n0\n0\nFollowing Too Closely\nTurning Improperly\nNaN\nNaN\nNaN\n4693643\nStation Wagon/Sport Utility Vehicle\nBus\nNaN\nNaN\nNaN\nPOINT (-73.99373 40.76713)\n22\n\n\n32351\n12/31/2023\n1900-01-01 16:24:00\nMANHATTAN\n10027.0\n40.809310\n-73.949120\n(40.80931, -73.94912)\nNaN\nNaN\n215 WEST 125 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nPassing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4693991\nSedan\nSedan\nNaN\nNaN\nNaN\nPOINT (-73.94912 40.80931)\n16\n\n\n32359\n12/31/2023\n1900-01-01 21:16:00\nMANHATTAN\n10011.0\n40.738250\n-74.001080\n(40.73825, -74.00108)\nNaN\nNaN\n237 WEST 13 STREET\n0\n0\n0\n0\n0\n0\n0\n0\nPassing Too Closely\nUnspecified\nNaN\nNaN\nNaN\n4691995\nStation Wagon/Sport Utility Vehicle\nNaN\nNaN\nNaN\nNaN\nPOINT (-74.00108 40.73825)\n21\n\n\n\n\n2789 rows × 31 columns\n\n\n\n\nimport folium\nfrom folium.plugins import FastMarkerCluster\n\n\n# Ensure the data contains valid longitude and latitude values\nmanhattan_crashes_filtered = manhattan_crashes_filtered.dropna(subset=['LONGITUDE', 'LATITUDE'])\n\n# Create a base map centered around Manhattan\nm = folium.Map(location=[40.7580, -73.9851], zoom_start=12, tiles='CartoDB dark_matter')\n\n# Add crash points to the map using FastMarkerCluster\nFastMarkerCluster(data=manhattan_crashes_filtered[['LATITUDE', 'LONGITUDE']].values.tolist()).add_to(m)\n\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook",
    "crumbs": [
      "Analysis",
      "I. Network Analysis"
    ]
  },
  {
    "objectID": "analysis/1-network.html#part2-congestion-prediction",
    "href": "analysis/1-network.html#part2-congestion-prediction",
    "title": "I. Network Analysis",
    "section": "Part2: Congestion Prediction",
    "text": "Part2: Congestion Prediction\n\nIntroduction\nThe purpose of this project is to design a predictive model for traffic congestion using a set of environmental and contextual features, including temperature, precipitation, wind speed, the occurrence of events, and whether it is a weekend. Traffic congestion is a significant issue in urban areas, impacting commute times, air quality, and overall productivity. By leveraging these variables, the model aims to understand the factors influencing traffic patterns and provide accurate predictions of traffic counts. Such a model could be instrumental in improving traffic management systems, informing infrastructure planning, and helping commuters make more informed decisions. The project seeks to demonstrate the feasibility of using readily available data to address real-world urban challenges.\nA traffic prediction model has significant potential applications in optimizing traffic light systems to improve traffic flow and reduce congestion. By accurately predicting traffic counts based on environmental factors, events, and time-related variables, the model could serve as a critical input for adaptive traffic light control systems. For instance, the model could help dynamically adjust traffic light timings based on anticipated traffic volumes at specific intersections. During periods of high predicted traffic, longer green light durations could be allocated to heavily congested routes, while during low-traffic periods, shorter cycles could minimize unnecessary delays. This would ensure a more efficient allocation of green time, reducing wait times, fuel consumption, and emissions caused by idling vehicles.\nAdditionally, the model could be integrated into intelligent traffic management systems that coordinate traffic lights across multiple intersections. By predicting traffic patterns in advance, the system could optimize signal synchronization to create “green waves,” allowing vehicles to travel through a series of intersections without stopping. This approach could be particularly useful in urban areas with high traffic density, where poor signal coordination often exacerbates congestion. Furthermore, during special events or adverse weather conditions, the model could help traffic authorities proactively adjust signal timings to handle anticipated surges in traffic, minimizing disruptions. Overall, the integration of traffic prediction models into traffic light optimization systems has the potential to enhance urban mobility, reduce congestion, and improve the overall efficiency of transportation networks.\n\n\nImporting The NYC Weather Data\n\nTime: 05-01-2021 to 05-10-2021\n\n\nData Source:\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Step 1: Load the Data\n# Load the dataset directly from the file\nweather_data = pd.read_csv(\"weather_Panel_NY.csv\")\n\n# Convert the 'interval60' column to datetime format\nweather_data['interval60'] = pd.to_datetime(weather_data['interval60'])\n\n# Step 2: Data Cleaning and Processing\n# Replace invalid or missing temperature values (if any)\nweather_data['Temperature'] = weather_data['Temperature'].apply(lambda x: 42 if x == 0 else x)\n\n# Step 3: Define Plot Themes\ndef plot_theme(ax):\n    \"\"\"Apply a consistent theme to plots.\"\"\"\n    ax.set_title(ax.get_title(), fontsize=14, fontweight='bold')\n    ax.set_xlabel(ax.get_xlabel(), fontsize=12)\n    ax.set_ylabel(ax.get_ylabel(), fontsize=12)\n    ax.tick_params(axis='x', labelsize=10, rotation=45)\n    ax.tick_params(axis='y', labelsize=10)\n    ax.grid(color=\"#eff3ff\", linestyle='-', linewidth=0.5)\n    ax.set_facecolor(\"white\")\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n\n# Step 4: Create Subplots\n# Create a figure with 3 subplots (one for each variable)\nfig, axs = plt.subplots(3, 1, figsize=(12, 14), constrained_layout=True)\n\n# Plot 1: Precipitation\nsns.lineplot(data=weather_data, x='interval60', y='Precipitation', ax=axs[0], color='#1f77b4')\naxs[0].set_title(\"Precipitation Over Time\")\naxs[0].set_xlabel(\"Date and Time\")\naxs[0].set_ylabel(\"Precipitation (inches)\")\nplot_theme(axs[0])\n\n# Plot 2: Wind Speed\nsns.lineplot(data=weather_data, x='interval60', y='Wind_Speed', ax=axs[1], color='#ff7f0e')\naxs[1].set_title(\"Wind Speed Over Time\")\naxs[1].set_xlabel(\"Date and Time\")\naxs[1].set_ylabel(\"Wind Speed (mph)\")\nplot_theme(axs[1])\n\n# Plot 3: Temperature\nsns.lineplot(data=weather_data, x='interval60', y='Temperature', ax=axs[2], color='#2ca02c')\naxs[2].set_title(\"Temperature Over Time\")\naxs[2].set_xlabel(\"Date and Time\")\naxs[2].set_ylabel(\"Temperature (°F)\")\nplot_theme(axs[2])\n\n# Add a main title for the entire figure\nfig.suptitle(\"Weather Data - New York City (May 2021)\", fontsize=16, fontweight='bold')\n\n# Step 5: Show and Save the Plot\n# Display the plot\nplt.show()\n\n# Optionally save the figure as an image file\nfig.savefig(\"weather_data_plot.png\", dpi=300)",
    "crumbs": [
      "Analysis",
      "I. Network Analysis"
    ]
  },
  {
    "objectID": "analysis/1-network.html#exploratory-data-analysis",
    "href": "analysis/1-network.html#exploratory-data-analysis",
    "title": "I. Network Analysis",
    "section": "Exploratory Data Analysis:",
    "text": "Exploratory Data Analysis:\nTraffic Count Across the Time:\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Step 1: Load the Data\n# Load the dataset\ndata = pd.read_csv(\"data_filtered.csv\")\n\n# Step 2: Preprocess the Data\n# Extract the columns with traffic counts (time intervals)\ntraffic_columns = data.columns[7:]  # Assuming traffic data starts from the 8th column\n\n# Add a new column for total traffic count per row\ndata['Total_Traffic'] = data[traffic_columns].sum(axis=1)\n\n# Aggregate traffic counts by date\ntraffic_by_date = data.groupby(\"Date\")['Total_Traffic'].sum().reset_index()\n\n# Convert the 'Date' column to datetime format for proper sorting\ntraffic_by_date['Date'] = pd.to_datetime(traffic_by_date['Date'])\n\n# Sort by date\ntraffic_by_date = traffic_by_date.sort_values(by='Date')\n\n# Step 3: Plot the Data\n# Set the style of the plot\nsns.set(style=\"whitegrid\")\n\n# Create the plot\nplt.figure(figsize=(12, 6))\nplt.plot(traffic_by_date['Date'], traffic_by_date['Total_Traffic'], color='black', linewidth=1)\n\n# Add labels and title\nplt.title(\"Number of Trips Over Time\", fontsize=14, fontweight='bold')\nplt.xlabel(\"Date\", fontsize=12)\nplt.ylabel(\"Number of Trips\", fontsize=12)\n\n# Rotate x-axis labels for better readability\nplt.xticks(rotation=45)\n\n# Add gridlines\nplt.grid(visible=True, linestyle='--', alpha=0.5)\n\n# Show the plot\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nTraffic Count Comparing Weekends and Weekdays:\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\n\n# Step 1: Load the Data\ndata = pd.read_csv(\"data_filtered.csv\")\n\n# Step 2: Preprocess the Data\n# Extract time interval columns\ntraffic_columns = data.columns[7:]  # Assuming traffic data starts from the 8th column\n\n# Add a column for total traffic during each hour\ndata['Total_Traffic'] = data[traffic_columns].sum(axis=1)\n\n# Convert the 'Date' column to datetime format\ndata['Date'] = pd.to_datetime(data['Date'])\n\n# Add a column for the day of the week\ndata['Day_of_Week'] = data['Date'].dt.dayofweek\n\n# Add a column to classify as 'Weekday' or 'Weekend'\ndata['Weekend'] = data['Day_of_Week'].apply(lambda x: 'Weekend' if x &gt;= 5 else 'Weekday')\n\n# Melt the time interval columns into a long format\nhourly_data = pd.melt(data, \n                      id_vars=['Date', 'Weekend'], \n                      value_vars=traffic_columns, \n                      var_name='Hour', \n                      value_name='Traffic_Count')\n\n# Clean the 'Hour' column to extract hour values\nhourly_data['Hour'] = hourly_data['Hour'].str.extract(r'X(\\d+)\\.').astype(int)\n\n# Step 3: Aggregate the Data\n# Group by hour and weekend/weekday\nhourly_traffic = hourly_data.groupby(['Hour', 'Weekend'])['Traffic_Count'].sum().reset_index()\n\n# Step 4: Plot the Data\nsns.set(style=\"whitegrid\")\n\nplt.figure(figsize=(12, 6))\n\n# Plot the data with explicit color mapping\nsns.lineplot(data=hourly_traffic, x='Hour', y='Traffic_Count', hue='Weekend', \n             palette={'Weekday': 'red', 'Weekend': 'blue'})  # Use blue for Weekend\n\n# Add labels and title\nplt.title(\"Traffic Counts by Hour: Weekday vs Weekend\", fontsize=14, fontweight='bold')\nplt.xlabel(\"Hour\", fontsize=12)\nplt.ylabel(\"Traffic Counts\", fontsize=12)\n\n# Fix the legend to correctly match the colors\nplt.legend(title=\"Traffic Type\", labels=[\"Weekday (Red)\", \"Weekend (Blue)\"], loc=\"upper right\")\n\n# Show the plot\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nTraffic Count Comparing Streets:\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Step 1: Load the Data\ndata = pd.read_csv(\"data_filtered.csv\")\n\n# Step 2: Preprocess the Data\n# Extract traffic columns\ntraffic_columns = data.columns[7:]  # Assuming traffic data starts from the 8th column\n\n# Add a column for total traffic across all time intervals\ndata['Total_Traffic'] = data[traffic_columns].sum(axis=1)\n\n# Step 3: Aggregate Traffic by Roadway Name\ntraffic_by_roadway = data.groupby('Roadway.Name')['Total_Traffic'].sum().reset_index()\n\n# Sort by total traffic in descending order for better visualization\ntraffic_by_roadway = traffic_by_roadway.sort_values(by='Total_Traffic', ascending=False)\n\n# Step 4: Plot the Data\nsns.set(style=\"whitegrid\")\n\nplt.figure(figsize=(12, 6))\nsns.barplot(data=traffic_by_roadway, x='Total_Traffic', y='Roadway.Name', palette=\"viridis\")\n\n# Add labels and title\nplt.title(\"Traffic Count by Roadway Name\", fontsize=14, fontweight='bold')\nplt.xlabel(\"Total Traffic Count\", fontsize=12)\nplt.ylabel(\"Roadway Name\", fontsize=12)\n\n# Show the plot\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nData Processing:\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\n# Step 1: Load the Datasets\n# Load traffic data\ntraffic_data = pd.read_csv(\"data_filtered.csv\")\n\n# Load weather data\nweather_data = pd.read_csv(\"weather_Panel_NY.csv\")\n\n# Step 2: Preprocess the Traffic Data\n# Convert 'Date' column to datetime\ntraffic_data['Date'] = pd.to_datetime(traffic_data['Date'])\n\n# Reshape the traffic data from wide to long format\nhourly_columns = [col for col in traffic_data.columns if 'X' in col]\ntraffic_hourly = traffic_data.melt(\n    id_vars=['Date', 'SegmentID', 'Roadway.Name', 'From', 'To', 'Direction'], \n    value_vars=hourly_columns, \n    var_name='Hour', \n    value_name='Traffic_Count'\n)\n\n# Extract the hour from the column names (e.g., \"X12.00.1.00.AM\" to \"00:00\")\ntraffic_hourly['Hour'] = traffic_hourly['Hour'].str.extract(r'X(\\d+)').astype(int) - 1\n\n# Combine Date and Hour into a single timestamp column\ntraffic_hourly['Timestamp'] = traffic_hourly['Date'] + pd.to_timedelta(traffic_hourly['Hour'], unit='h')\n\n# Drop unnecessary columns\ntraffic_hourly = traffic_hourly[['Timestamp', 'Traffic_Count']]\n\nAdd the ‘is_weekend’ Feature\n\n# Step 3: Add the 'is_weekend' Feature\n# Extract day of the week from the timestamp\ntraffic_hourly['Day_of_Week'] = traffic_hourly['Timestamp'].dt.dayofweek  # Monday=0, Sunday=6\ntraffic_hourly['is_weekend'] = traffic_hourly['Day_of_Week'].apply(lambda x: 1 if x &gt;= 5 else 0)\n\n# Step 4: Preprocess the Weather Data\n# Convert 'interval60' to datetime\nweather_data['interval60'] = pd.to_datetime(weather_data['interval60'])\n\n# Step 5: Merge the Datasets\n# Merge traffic and weather data on the timestamp\ncombined_data = pd.merge(traffic_hourly, weather_data, left_on='Timestamp', right_on='interval60', how='inner')\n\n# Drop unnecessary columns\ncombined_data = combined_data.drop(columns=['interval60', 'Day_of_Week'])\n\nAdd the Holiday/Event Dates Feature\n\n# Step 1: Define the Holiday/Event Dates\n# List of holiday or event dates\nholiday_event_dates = [\n    \"2021-05-01\",  # International Workers' Day\n    \"2021-05-05\",  # Cinco de Mayo\n    \"2021-05-09\"   # Mother's Day\n]\n\n# Step 2: Add the 'is_holiday_or_event' Variable\n# Convert the holiday_event_dates to datetime for comparison\nholiday_event_dates = pd.to_datetime(holiday_event_dates)\n\n# Add a new column to indicate whether the date is a holiday or event\ntraffic_hourly['is_holiday_or_event'] = traffic_hourly['Timestamp'].dt.date.isin(holiday_event_dates.date).astype(int)\n\nMaking the model\n\n# Step 3: Merge with Weather Data\n# (Assume weather data preprocessing and merging steps as before)\ncombined_data = pd.merge(traffic_hourly, weather_data, left_on='Timestamp', right_on='interval60', how='inner')\n\n# Step 4: Feature Selection\n# Add 'is_holiday_or_event' to the features\nX = combined_data[['Temperature', 'Precipitation', 'Wind_Speed', 'is_weekend', 'is_holiday_or_event']]\ny = combined_data['Traffic_Count']\n\n# Step 5: Train-Test Split and Model Training\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = RandomForestRegressor(random_state=42)\nmodel.fit(X_train, y_train)\n\n# Step 6: Evaluate the Model\ny_pred = model.predict(X_test)\n\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nfrom tabulate import tabulate  # Install this with `pip install tabulate`\n\n# Step 7: Create a DataFrame to Display Actual, Predicted, MAE, and MSE for Each Row\nresults_df = pd.DataFrame({\n    'Actual Value': y_test.values,\n    'Predicted Value': y_pred\n})\n\n# Calculate Absolute Error and Squared Error for each row\nresults_df['Absolute Error'] = abs(results_df['Actual Value'] - results_df['Predicted Value'])\nresults_df['Squared Error'] = (results_df['Actual Value'] - results_df['Predicted Value']) ** 2\n\n# Add columns for MAE and MSE (optional, as they are global metrics)\nresults_df['MAE'] = mae\nresults_df['MSE'] = mse\n\n# Round values for better readability\nresults_df = results_df.round({'Actual Value': 2, 'Predicted Value': 2, 'Absolute Error': 2, 'Squared Error': 2, 'MAE': 2, 'MSE': 2})\n\n# Display the table using tabulate for a clean format\ntable = tabulate(results_df.head(10), headers='keys', tablefmt='pretty')\nprint(table)\n\nprint(f\"Model Evaluation Metrics:\")\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"R-squared (R2): {r2}\")\n\n+---+--------------+-----------------+----------------+---------------+--------+---------+\n|   | Actual Value | Predicted Value | Absolute Error | Squared Error |  MAE   |   MSE   |\n+---+--------------+-----------------+----------------+---------------+--------+---------+\n| 0 |     52.0     |     212.31      |     160.31     |   25697.91    | 186.21 | 67145.7 |\n| 1 |     3.0      |     222.72      |     219.72     |   48278.99    | 186.21 | 67145.7 |\n| 2 |     23.0     |     222.72      |     199.72     |    39890.0    | 186.21 | 67145.7 |\n| 3 |    119.0     |      190.6      |      71.6      |    5127.27    | 186.21 | 67145.7 |\n| 4 |    534.0     |     212.31      |     321.69     |   103487.25   | 186.21 | 67145.7 |\n| 5 |    724.0     |     223.89      |     500.11     |   250110.57   | 186.21 | 67145.7 |\n| 6 |    192.0     |     163.73      |     28.27      |    799.45     | 186.21 | 67145.7 |\n| 7 |    343.0     |     196.71      |     146.29     |   21399.55    | 186.21 | 67145.7 |\n| 8 |     24.0     |     212.31      |     188.31     |   35459.02    | 186.21 | 67145.7 |\n| 9 |    417.0     |     203.44      |     213.56     |   45609.55    | 186.21 | 67145.7 |\n+---+--------------+-----------------+----------------+---------------+--------+---------+\nModel Evaluation Metrics:\nMean Absolute Error (MAE): 186.21046236583155\nMean Squared Error (MSE): 67145.69644950841\nR-squared (R2): 0.0006557517971068627\n\n\nThe model’s performance, as reflected by the evaluation metrics, indicates significant limitations. The Mean Absolute Error (MAE) of 186.21 suggests that, on average, predictions deviate from actual values by 186 traffic counts, which may be substantial depending on the scale of traffic. The Mean Squared Error (MSE) of 67,145 highlights large errors, particularly influenced by extreme outliers, given the quadratic nature of MSE. Most concerning is the R-squared (R²) value of 0.00065, which indicates that the model explains less than 0.1% of the variance in the data, essentially performing no better than a simple mean-based prediction. This suggests the model fails to capture meaningful patterns in the data, likely due to insufficient features, inadequate complexity, or a mismatch between the data and the model’s assumptions.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Calculate residuals\nresiduals = y_test - y_pred\n\n# Plot residuals\nplt.figure(figsize=(8, 6))\nsns.scatterplot(x=y_pred, y=residuals, alpha=0.6)\nplt.axhline(y=0, color='r', linestyle='--')\nplt.title(\"Residual Plot\")\nplt.xlabel(\"Predicted Traffic Count\")\nplt.ylabel(\"Residuals (Actual - Predicted)\")\nplt.show()\n\n\n\n\n\n\n\n\nThe residual plot indicates that the model generally performs well, with residuals centered around zero and no clear non-linear patterns, suggesting it captures the general relationship between predictors and traffic counts. However, the increasing spread of residuals with larger predicted values highlights heteroscedasticity, meaning the model’s errors grow with higher traffic counts, reducing reliability for these predictions. Additionally, the presence of significant outliers (residuals exceeding 1000) suggests that the model struggles to account for unusual traffic conditions, potentially due to missing features such as accidents or events. A slight tendency to underpredict higher traffic counts is also observed, as evidenced by the clustering of residuals below zero.\n\n# Plot actual vs predicted\nplt.figure(figsize=(8, 6))\nsns.scatterplot(x=y_test, y=y_pred, alpha=0.6)\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='r', linestyle='--')\nplt.title(\"Actual vs Predicted Traffic Counts\")\nplt.xlabel(\"Actual Traffic Count\")\nplt.ylabel(\"Predicted Traffic Count\")\nplt.show()\n\n\n\n\n\n\n\n\nThe scatter plot compares actual traffic counts (x-axis) to predicted traffic counts (y-axis) for a Random Forest model, with the red dashed line representing the ideal scenario where predictions perfectly match actual values. The plot reveals several key insights regarding the model’s performance and limitations.\nFirst, the majority of predicted values cluster within a narrow range (approximately 200–400), regardless of the actual traffic counts. This indicates that the model struggles to capture variability in traffic counts, particularly for higher values, leading to underprediction for actual traffic counts above 500. The lack of points along the diagonal line for larger actual counts highlights this systematic error. Additionally, the spread of points becomes more pronounced as actual traffic counts increase, reflecting heteroscedasticity, where prediction errors grow with larger traffic counts. This suggests that the model’s performance deteriorates for higher traffic levels, potentially due to insufficient features to explain variability at these extremes.\nThe model performs reasonably well for lower traffic counts, as many predictions fall close to the diagonal line in this range. However, the consistent over-concentration of predicted values between 200 and 400 suggests that the model may be biased toward predicting average traffic counts, a limitation likely stemming from the training process or insufficient feature diversity.\n\n# Plot distribution of residuals\nplt.figure(figsize=(8, 6))\nsns.histplot(residuals, kde=True, bins=30, color='blue')\nplt.title(\"Distribution of Residuals\")\nplt.xlabel(\"Residuals (Actual - Predicted)\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\n\n\n\n\n\n\n\nThe residual distribution is right-skewed, with most residuals concentrated between -250 and 250, indicating that the Random Forest model performs reasonably well for the majority of predictions. However, the long positive tail reveals significant underprediction for higher traffic counts, suggesting the model struggles with variability in extreme conditions. This aligns with earlier observations of heteroscedasticity, where prediction errors increase with larger traffic counts. Additionally, extreme residuals exceeding 1000 indicate outliers or unaccounted factors, such as events or anomalies. To improve, consider applying a log transformation to stabilize variance, adding relevant features (e.g., time, weather), and exploring advanced models like Gradient Boosting to better capture complex patterns.\n\nLimitations\nDespite its intent, the model faces several limitations that hinder its performance. The low R-squared value indicates that the features used explain only a negligible portion of the variance in traffic counts, suggesting that other critical factors influencing traffic, such as time of day, road capacity, historical traffic trends, or localized disruptions, are missing from the model. Additionally, the model exhibits heteroscedasticity, with residual errors increasing for higher traffic counts, indicating that it struggles to capture variability in extreme conditions. This issue is further compounded by outliers, such as unusual traffic spikes during events or accidents, which the model fails to predict accurately. Moreover, the features included may not fully capture the non-linear and complex relationships between environmental conditions and traffic patterns, limiting the model’s ability to generalize to diverse scenarios. These limitations highlight the need for more comprehensive data and advanced modeling techniques to improve predictive accuracy.\n\n\nConclusion\nIn conclusion, while the project demonstrates the potential of using environmental and contextual features to predict traffic congestion, the results indicate that the current model is insufficient for accurate and reliable predictions. The significant errors and low explanatory power suggest that the complexity of traffic patterns requires a more robust approach. Future efforts should focus on incorporating additional features, such as time of day, historical traffic data, and real-time factors like road closures or accidents. Advanced modeling techniques, such as Gradient Boosting Machines or Neural Networks, could also be explored to better capture non-linear relationships and interactions between variables. Despite its limitations, this project serves as a valuable starting point for understanding the factors influencing traffic congestion and highlights the importance of data-driven approaches in addressing urban mobility challenges.",
    "crumbs": [
      "Analysis",
      "I. Network Analysis"
    ]
  },
  {
    "objectID": "analysis/2-prediction.html",
    "href": "analysis/2-prediction.html",
    "title": "II. Congestion Prediction",
    "section": "",
    "text": "This study aims to design a predictive model for traffic congestion using environmental and contextual data, such as weather conditions, events, and time-related variables. By accurately predicting traffic patterns, the model can optimize traffic light timings, reduce congestion, and improve overall traffic flow. It could dynamically adjust signal durations to allocate green time efficiently, minimizing delays, fuel consumption, and emissions. Additionally, integrating this model into intelligent traffic management systems could enable synchronized “green waves,” reducing stops and delays across multiple intersections. This approach has the potential to enhance urban mobility, reduce disruptions during events or adverse weather, and support more efficient and sustainable transportation networks.",
    "crumbs": [
      "Analysis",
      "II. Congestion Prediction"
    ]
  },
  {
    "objectID": "analysis/2-prediction.html#exploratory-data-analysis",
    "href": "analysis/2-prediction.html#exploratory-data-analysis",
    "title": "II. Congestion Prediction",
    "section": "Exploratory Data Analysis:",
    "text": "Exploratory Data Analysis:\nTraffic Count Across the Time:\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Step 1: Load the Data\n# Load the dataset\ndata = pd.read_csv(\"data_filtered.csv\")\n\n# Step 2: Preprocess the Data\n# Extract the columns with traffic counts (time intervals)\ntraffic_columns = data.columns[7:]  # Assuming traffic data starts from the 8th column\n\n# Add a new column for total traffic count per row\ndata['Total_Traffic'] = data[traffic_columns].sum(axis=1)\n\n# Aggregate traffic counts by date\ntraffic_by_date = data.groupby(\"Date\")['Total_Traffic'].sum().reset_index()\n\n# Convert the 'Date' column to datetime format for proper sorting\ntraffic_by_date['Date'] = pd.to_datetime(traffic_by_date['Date'])\n\n# Sort by date\ntraffic_by_date = traffic_by_date.sort_values(by='Date')\n\n# Step 3: Plot the Data\n# Set the style of the plot\nsns.set(style=\"whitegrid\")\n\n# Create the plot\nplt.figure(figsize=(12, 6))\nplt.plot(traffic_by_date['Date'], traffic_by_date['Total_Traffic'], color='black', linewidth=1)\n\n# Add labels and title\nplt.title(\"Number of Trips Over Time\", fontsize=14, fontweight='bold')\nplt.xlabel(\"Date\", fontsize=12)\nplt.ylabel(\"Number of Trips\", fontsize=12)\n\n# Rotate x-axis labels for better readability\nplt.xticks(rotation=45)\n\n# Add gridlines\nplt.grid(visible=True, linestyle='--', alpha=0.5)\n\n# Show the plot\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nTraffic Count Comparing Weekends and Weekdays:\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\n\n# Step 1: Load the Data\ndata = pd.read_csv(\"data_filtered.csv\")\n\n# Step 2: Preprocess the Data\n# Extract time interval columns\ntraffic_columns = data.columns[7:]  # Assuming traffic data starts from the 8th column\n\n# Add a column for total traffic during each hour\ndata['Total_Traffic'] = data[traffic_columns].sum(axis=1)\n\n# Convert the 'Date' column to datetime format\ndata['Date'] = pd.to_datetime(data['Date'])\n\n# Add a column for the day of the week\ndata['Day_of_Week'] = data['Date'].dt.dayofweek\n\n# Add a column to classify as 'Weekday' or 'Weekend'\ndata['Weekend'] = data['Day_of_Week'].apply(lambda x: 'Weekend' if x &gt;= 5 else 'Weekday')\n\n# Melt the time interval columns into a long format\nhourly_data = pd.melt(data, \n                      id_vars=['Date', 'Weekend'], \n                      value_vars=traffic_columns, \n                      var_name='Hour', \n                      value_name='Traffic_Count')\n\n# Clean the 'Hour' column to extract hour values\nhourly_data['Hour'] = hourly_data['Hour'].str.extract(r'X(\\d+)\\.').astype(int)\n\n# Step 3: Aggregate the Data\n# Group by hour and weekend/weekday\nhourly_traffic = hourly_data.groupby(['Hour', 'Weekend'])['Traffic_Count'].sum().reset_index()\n\n# Step 4: Plot the Data\nsns.set(style=\"whitegrid\")\n\nplt.figure(figsize=(12, 6))\n\n# Plot the data with explicit color mapping\nsns.lineplot(data=hourly_traffic, x='Hour', y='Traffic_Count', hue='Weekend', \n             palette={'Weekday': 'red', 'Weekend': 'blue'})  # Use blue for Weekend\n\n# Add labels and title\nplt.title(\"Traffic Counts by Hour: Weekday vs Weekend\", fontsize=14, fontweight='bold')\nplt.xlabel(\"Hour\", fontsize=12)\nplt.ylabel(\"Traffic Counts\", fontsize=12)\n\n# Fix the legend to correctly match the colors\nplt.legend(title=\"Traffic Type\", labels=[\"Weekday (Red)\", \"Weekend (Blue)\"], loc=\"upper right\")\n\n# Show the plot\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nTraffic Count Comparing Streets:\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Step 1: Load the Data\ndata = pd.read_csv(\"data_filtered.csv\")\n\n# Step 2: Preprocess the Data\n# Extract traffic columns\ntraffic_columns = data.columns[7:]  # Assuming traffic data starts from the 8th column\n\n# Add a column for total traffic across all time intervals\ndata['Total_Traffic'] = data[traffic_columns].sum(axis=1)\n\n# Step 3: Aggregate Traffic by Roadway Name\ntraffic_by_roadway = data.groupby('Roadway.Name')['Total_Traffic'].sum().reset_index()\n\n# Sort by total traffic in descending order for better visualization\ntraffic_by_roadway = traffic_by_roadway.sort_values(by='Total_Traffic', ascending=False)\n\n# Step 4: Plot the Data\nsns.set(style=\"whitegrid\")\n\nplt.figure(figsize=(12, 6))\nsns.barplot(data=traffic_by_roadway, x='Total_Traffic', y='Roadway.Name', palette=\"viridis\")\n\n# Add labels and title\nplt.title(\"Traffic Count by Roadway Name\", fontsize=14, fontweight='bold')\nplt.xlabel(\"Total Traffic Count\", fontsize=12)\nplt.ylabel(\"Roadway Name\", fontsize=12)\n\n# Show the plot\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nData Processing:\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\n# Step 1: Load the Datasets\n# Load traffic data\ntraffic_data = pd.read_csv(\"data_filtered.csv\")\n\n# Load weather data\nweather_data = pd.read_csv(\"weather_Panel_NY.csv\")\n\n# Step 2: Preprocess the Traffic Data\n# Convert 'Date' column to datetime\ntraffic_data['Date'] = pd.to_datetime(traffic_data['Date'])\n\n# Reshape the traffic data from wide to long format\nhourly_columns = [col for col in traffic_data.columns if 'X' in col]\ntraffic_hourly = traffic_data.melt(\n    id_vars=['Date', 'SegmentID', 'Roadway.Name', 'From', 'To', 'Direction'], \n    value_vars=hourly_columns, \n    var_name='Hour', \n    value_name='Traffic_Count'\n)\n\n# Extract the hour from the column names (e.g., \"X12.00.1.00.AM\" to \"00:00\")\ntraffic_hourly['Hour'] = traffic_hourly['Hour'].str.extract(r'X(\\d+)').astype(int) - 1\n\n# Combine Date and Hour into a single timestamp column\ntraffic_hourly['Timestamp'] = traffic_hourly['Date'] + pd.to_timedelta(traffic_hourly['Hour'], unit='h')\n\n# Drop unnecessary columns\ntraffic_hourly = traffic_hourly[['Timestamp', 'Traffic_Count']]\n\nAdd the ‘is_weekend’ Feature\n\n# Step 3: Add the 'is_weekend' Feature\n# Extract day of the week from the timestamp\ntraffic_hourly['Day_of_Week'] = traffic_hourly['Timestamp'].dt.dayofweek  # Monday=0, Sunday=6\ntraffic_hourly['is_weekend'] = traffic_hourly['Day_of_Week'].apply(lambda x: 1 if x &gt;= 5 else 0)\n\n# Step 4: Preprocess the Weather Data\n# Convert 'interval60' to datetime\nweather_data['interval60'] = pd.to_datetime(weather_data['interval60'])\n\n# Step 5: Merge the Datasets\n# Merge traffic and weather data on the timestamp\ncombined_data = pd.merge(traffic_hourly, weather_data, left_on='Timestamp', right_on='interval60', how='inner')\n\n# Drop unnecessary columns\ncombined_data = combined_data.drop(columns=['interval60', 'Day_of_Week'])\n\nAdd the Holiday/Event Dates Feature\n\n# Step 1: Define the Holiday/Event Dates\n# List of holiday or event dates\nholiday_event_dates = [\n    \"2021-05-01\",  # International Workers' Day\n    \"2021-05-05\",  # Cinco de Mayo\n    \"2021-05-09\"   # Mother's Day\n]\n\n# Step 2: Add the 'is_holiday_or_event' Variable\n# Convert the holiday_event_dates to datetime for comparison\nholiday_event_dates = pd.to_datetime(holiday_event_dates)\n\n# Add a new column to indicate whether the date is a holiday or event\ntraffic_hourly['is_holiday_or_event'] = traffic_hourly['Timestamp'].dt.date.isin(holiday_event_dates.date).astype(int)\n\nMaking the model\n\n# Step 3: Merge with Weather Data\n# (Assume weather data preprocessing and merging steps as before)\ncombined_data = pd.merge(traffic_hourly, weather_data, left_on='Timestamp', right_on='interval60', how='inner')\n\n# Step 4: Feature Selection\n# Add 'is_holiday_or_event' to the features\nX = combined_data[['Temperature', 'Precipitation', 'Wind_Speed', 'is_weekend', 'is_holiday_or_event']]\ny = combined_data['Traffic_Count']\n\n# Step 5: Train-Test Split and Model Training\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = RandomForestRegressor(random_state=42)\nmodel.fit(X_train, y_train)\n\n# Step 6: Evaluate the Model\ny_pred = model.predict(X_test)\n\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nfrom tabulate import tabulate  # Install this with `pip install tabulate`\n\n# Step 7: Create a DataFrame to Display Actual, Predicted, MAE, and MSE for Each Row\nresults_df = pd.DataFrame({\n    'Actual Value': y_test.values,\n    'Predicted Value': y_pred\n})\n\n# Calculate Absolute Error and Squared Error for each row\nresults_df['Absolute Error'] = abs(results_df['Actual Value'] - results_df['Predicted Value'])\nresults_df['Squared Error'] = (results_df['Actual Value'] - results_df['Predicted Value']) ** 2\n\n# Add columns for MAE and MSE (optional, as they are global metrics)\nresults_df['MAE'] = mae\nresults_df['MSE'] = mse\n\n# Round values for better readability\nresults_df = results_df.round({'Actual Value': 2, 'Predicted Value': 2, 'Absolute Error': 2, 'Squared Error': 2, 'MAE': 2, 'MSE': 2})\n\n# Display the table using tabulate for a clean format\ntable = tabulate(results_df.head(10), headers='keys', tablefmt='pretty')\nprint(table)\n\nprint(f\"Model Evaluation Metrics:\")\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"R-squared (R2): {r2}\")\n\n+---+--------------+-----------------+----------------+---------------+--------+---------+\n|   | Actual Value | Predicted Value | Absolute Error | Squared Error |  MAE   |   MSE   |\n+---+--------------+-----------------+----------------+---------------+--------+---------+\n| 0 |     52.0     |     212.31      |     160.31     |   25697.91    | 186.21 | 67145.7 |\n| 1 |     3.0      |     222.72      |     219.72     |   48278.99    | 186.21 | 67145.7 |\n| 2 |     23.0     |     222.72      |     199.72     |    39890.0    | 186.21 | 67145.7 |\n| 3 |    119.0     |      190.6      |      71.6      |    5127.27    | 186.21 | 67145.7 |\n| 4 |    534.0     |     212.31      |     321.69     |   103487.25   | 186.21 | 67145.7 |\n| 5 |    724.0     |     223.89      |     500.11     |   250110.57   | 186.21 | 67145.7 |\n| 6 |    192.0     |     163.73      |     28.27      |    799.45     | 186.21 | 67145.7 |\n| 7 |    343.0     |     196.71      |     146.29     |   21399.55    | 186.21 | 67145.7 |\n| 8 |     24.0     |     212.31      |     188.31     |   35459.02    | 186.21 | 67145.7 |\n| 9 |    417.0     |     203.44      |     213.56     |   45609.55    | 186.21 | 67145.7 |\n+---+--------------+-----------------+----------------+---------------+--------+---------+\nModel Evaluation Metrics:\nMean Absolute Error (MAE): 186.21046236583155\nMean Squared Error (MSE): 67145.69644950841\nR-squared (R2): 0.0006557517971068627\n\n\nThe model’s performance, as reflected by the evaluation metrics, indicates significant limitations. The Mean Absolute Error (MAE) of 186.21 suggests that, on average, predictions deviate from actual values by 186 traffic counts, which may be substantial depending on the scale of traffic. The Mean Squared Error (MSE) of 67,145 highlights large errors, particularly influenced by extreme outliers, given the quadratic nature of MSE. Most concerning is the R-squared (R²) value of 0.00065, which indicates that the model explains less than 0.1% of the variance in the data, essentially performing no better than a simple mean-based prediction. This suggests the model fails to capture meaningful patterns in the data, likely due to insufficient features, inadequate complexity, or a mismatch between the data and the model’s assumptions.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Calculate residuals\nresiduals = y_test - y_pred\n\n# Plot residuals\nplt.figure(figsize=(8, 6))\nsns.scatterplot(x=y_pred, y=residuals, alpha=0.6)\nplt.axhline(y=0, color='r', linestyle='--')\nplt.title(\"Residual Plot\")\nplt.xlabel(\"Predicted Traffic Count\")\nplt.ylabel(\"Residuals (Actual - Predicted)\")\nplt.show()\n\n\n\n\n\n\n\n\nThe residual plot indicates that the model generally performs well, with residuals centered around zero and no clear non-linear patterns, suggesting it captures the general relationship between predictors and traffic counts. However, the increasing spread of residuals with larger predicted values highlights heteroscedasticity, meaning the model’s errors grow with higher traffic counts, reducing reliability for these predictions. Additionally, the presence of significant outliers (residuals exceeding 1000) suggests that the model struggles to account for unusual traffic conditions, potentially due to missing features such as accidents or events. A slight tendency to underpredict higher traffic counts is also observed, as evidenced by the clustering of residuals below zero.\n\n# Plot actual vs predicted\nplt.figure(figsize=(8, 6))\nsns.scatterplot(x=y_test, y=y_pred, alpha=0.6)\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='r', linestyle='--')\nplt.title(\"Actual vs Predicted Traffic Counts\")\nplt.xlabel(\"Actual Traffic Count\")\nplt.ylabel(\"Predicted Traffic Count\")\nplt.show()\n\n\n\n\n\n\n\n\nThe scatter plot compares actual traffic counts (x-axis) to predicted traffic counts (y-axis) for a Random Forest model, with the red dashed line representing the ideal scenario where predictions perfectly match actual values. The plot reveals several key insights regarding the model’s performance and limitations.\nFirst, the majority of predicted values cluster within a narrow range (approximately 200–400), regardless of the actual traffic counts. This indicates that the model struggles to capture variability in traffic counts, particularly for higher values, leading to underprediction for actual traffic counts above 500. The lack of points along the diagonal line for larger actual counts highlights this systematic error. Additionally, the spread of points becomes more pronounced as actual traffic counts increase, reflecting heteroscedasticity, where prediction errors grow with larger traffic counts. This suggests that the model’s performance deteriorates for higher traffic levels, potentially due to insufficient features to explain variability at these extremes.\nThe model performs reasonably well for lower traffic counts, as many predictions fall close to the diagonal line in this range. However, the consistent over-concentration of predicted values between 200 and 400 suggests that the model may be biased toward predicting average traffic counts, a limitation likely stemming from the training process or insufficient feature diversity.\n\n# Plot distribution of residuals\nplt.figure(figsize=(8, 6))\nsns.histplot(residuals, kde=True, bins=30, color='blue')\nplt.title(\"Distribution of Residuals\")\nplt.xlabel(\"Residuals (Actual - Predicted)\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\n\n\n\n\n\n\n\nThe residual distribution is right-skewed, with most residuals concentrated between -250 and 250, indicating that the Random Forest model performs reasonably well for the majority of predictions. However, the long positive tail reveals significant underprediction for higher traffic counts, suggesting the model struggles with variability in extreme conditions. This aligns with earlier observations of heteroscedasticity, where prediction errors increase with larger traffic counts. Additionally, extreme residuals exceeding 1000 indicate outliers or unaccounted factors, such as events or anomalies. To improve, consider applying a log transformation to stabilize variance, adding relevant features (e.g., time, weather), and exploring advanced models like Gradient Boosting to better capture complex patterns.",
    "crumbs": [
      "Analysis",
      "II. Congestion Prediction"
    ]
  },
  {
    "objectID": "introduction.html#intruduction",
    "href": "introduction.html#intruduction",
    "title": "Introduction",
    "section": "Intruduction",
    "text": "Intruduction\nThe purpose of this project is to design a predictive model for traffic congestion using a set of environmental and contextual features, including temperature, precipitation, wind speed, the occurrence of events, and whether it is a weekend. Traffic congestion is a significant issue in urban areas, impacting commute times, air quality, and overall productivity. By leveraging these variables, the model aims to understand the factors influencing traffic patterns and provide accurate predictions of traffic counts. Such a model could be instrumental in improving traffic management systems, informing infrastructure planning, and helping commuters make more informed decisions. The project seeks to demonstrate the feasibility of using readily available data to address real-world urban challenges.\nA traffic prediction model has significant potential applications in optimizing traffic light systems to improve traffic flow and reduce congestion. By accurately predicting traffic counts based on environmental factors, events, and time-related variables, the model could serve as a critical input for adaptive traffic light control systems. For instance, the model could help dynamically adjust traffic light timings based on anticipated traffic volumes at specific intersections. During periods of high predicted traffic, longer green light durations could be allocated to heavily congested routes, while during low-traffic periods, shorter cycles could minimize unnecessary delays. This would ensure a more efficient allocation of green time, reducing wait times, fuel consumption, and emissions caused by idling vehicles.\nAdditionally, the model could be integrated into intelligent traffic management systems that coordinate traffic lights across multiple intersections. By predicting traffic patterns in advance, the system could optimize signal synchronization to create “green waves,” allowing vehicles to travel through a series of intersections without stopping. This approach could be particularly useful in urban areas with high traffic density, where poor signal coordination often exacerbates congestion. Furthermore, during special events or adverse weather conditions, the model could help traffic authorities proactively adjust signal timings to handle anticipated surges in traffic, minimizing disruptions. Overall, the integration of traffic prediction models into traffic light optimization systems has the potential to enhance urban mobility, reduce congestion, and improve the overall efficiency of transportation networks."
  },
  {
    "objectID": "intro.html#intruduction",
    "href": "intro.html#intruduction",
    "title": "Introduction",
    "section": "Intruduction",
    "text": "Intruduction\nThe purpose of this project is to design a predictive model for traffic congestion using a set of environmental and contextual features, including temperature, precipitation, wind speed, the occurrence of events, and whether it is a weekend. Traffic congestion is a significant issue in urban areas, impacting commute times, air quality, and overall productivity. By leveraging these variables, the model aims to understand the factors influencing traffic patterns and provide accurate predictions of traffic counts. Such a model could be instrumental in improving traffic management systems, informing infrastructure planning, and helping commuters make more informed decisions. The project seeks to demonstrate the feasibility of using readily available data to address real-world urban challenges.\nA traffic prediction model has significant potential applications in optimizing traffic light systems to improve traffic flow and reduce congestion. By accurately predicting traffic counts based on environmental factors, events, and time-related variables, the model could serve as a critical input for adaptive traffic light control systems. For instance, the model could help dynamically adjust traffic light timings based on anticipated traffic volumes at specific intersections. During periods of high predicted traffic, longer green light durations could be allocated to heavily congested routes, while during low-traffic periods, shorter cycles could minimize unnecessary delays. This would ensure a more efficient allocation of green time, reducing wait times, fuel consumption, and emissions caused by idling vehicles.\nAdditionally, the model could be integrated into intelligent traffic management systems that coordinate traffic lights across multiple intersections. By predicting traffic patterns in advance, the system could optimize signal synchronization to create “green waves,” allowing vehicles to travel through a series of intersections without stopping. This approach could be particularly useful in urban areas with high traffic density, where poor signal coordination often exacerbates congestion. Furthermore, during special events or adverse weather conditions, the model could help traffic authorities proactively adjust signal timings to handle anticipated surges in traffic, minimizing disruptions. Overall, the integration of traffic prediction models into traffic light optimization systems has the potential to enhance urban mobility, reduce congestion, and improve the overall efficiency of transportation networks.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#introduction",
    "href": "intro.html#introduction",
    "title": "Introduction",
    "section": "Introduction",
    "text": "Introduction\nThe purpose of this project is to design a predictive model for traffic congestion using a set of environmental and contextual features, including temperature, precipitation, wind speed, the occurrence of events, and whether it is a weekend. Traffic congestion is a significant issue in urban areas, impacting commute times, air quality, and overall productivity. By leveraging these variables, the model aims to understand the factors influencing traffic patterns and provide accurate predictions of traffic counts. Such a model could be instrumental in improving traffic management systems, informing infrastructure planning, and helping commuters make more informed decisions. The project seeks to demonstrate the feasibility of using readily available data to address real-world urban challenges.\nA traffic prediction model has significant potential applications in optimizing traffic light systems to improve traffic flow and reduce congestion. By accurately predicting traffic counts based on environmental factors, events, and time-related variables, the model could serve as a critical input for adaptive traffic light control systems. For instance, the model could help dynamically adjust traffic light timings based on anticipated traffic volumes at specific intersections. During periods of high predicted traffic, longer green light durations could be allocated to heavily congested routes, while during low-traffic periods, shorter cycles could minimize unnecessary delays. This would ensure a more efficient allocation of green time, reducing wait times, fuel consumption, and emissions caused by idling vehicles.\nAdditionally, the model could be integrated into intelligent traffic management systems that coordinate traffic lights across multiple intersections. By predicting traffic patterns in advance, the system could optimize signal synchronization to create “green waves,” allowing vehicles to travel through a series of intersections without stopping. This approach could be particularly useful in urban areas with high traffic density, where poor signal coordination often exacerbates congestion. Furthermore, during special events or adverse weather conditions, the model could help traffic authorities proactively adjust signal timings to handle anticipated surges in traffic, minimizing disruptions. Overall, the integration of traffic prediction models into traffic light optimization systems has the potential to enhance urban mobility, reduce congestion, and improve the overall efficiency of transportation networks.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "conclusion.html#thanks",
    "href": "conclusion.html#thanks",
    "title": "In the End",
    "section": "Thanks",
    "text": "Thanks\n\n\n\n\n\n\nImportant\n\n\n\n辣椒炒肉!",
    "crumbs": [
      "Conclusion"
    ]
  },
  {
    "objectID": "conclusion.html#lastly",
    "href": "conclusion.html#lastly",
    "title": "In the End",
    "section": "Lastly",
    "text": "Lastly\nWe would like to express our heartfelt gratitude to our instructor, Eric Delmelle, and our TAs (especially Xia) for their invaluable guidance and support throughout the semester. We also extend our thanks to everyone who has taken the time to explore our project. We hope that through collective efforts, including those of dedicated scientists and researchers, we can work toward creating better and more sustainable urban environments for the future.\n\n\n\n\n\n\n\nImportant\n\n\n\n辣椒炒肉!",
    "crumbs": [
      "Conclusion"
    ]
  },
  {
    "objectID": "analysis/index.html#background",
    "href": "analysis/index.html#background",
    "title": "Analysis",
    "section": "",
    "text": "Like other big cities, Philadelphia also experiences daily traffic congestions, particularly during peak commuting hours. Congestion not only increases travel times but also contributes to higher fuel consumption, air pollution, and commuter frustration. The city’s aging traffic signal infrastructure often relies on static timing plans that fail to adapt to real-time traffic conditions, exacerbating delays at critical intersections. By leveraging real-time traffic data, machine learning, and geospatial analysis, Philadelphia can adopt adaptive traffic signal control systems to dynamically adjust signal timings based on current traffic conditions. Such a system would not only reduce congestion but also improve safety, enhance air quality, and support the city’s broader goals of sustainable and efficient urban mobility. This project aims to develop an adaptive traffic signal optimization system through machine learning tools, using real-time traffic sensor data, historical traffic patterns, and transportation data.",
    "crumbs": [
      "Analysis"
    ]
  },
  {
    "objectID": "analysis/index.html#data",
    "href": "analysis/index.html#data",
    "title": "Analysis",
    "section": "",
    "text": "First, we will use street network data from OpenStreetMap data via OSMnx to analyze traffic flow and identify key intersections for optimization. Second, we plan to collect real-time traffic sensor data via APIs such as Google Maps Traffic API, HERE Traffic API, or TomTom Traffic API. Third, we will add Historical Traffic from traffic sensor APIs or public datasets for model training and time-series analysis to predict traffic conditions. The data contains historical traffic patterns, including peak hours, seasonal trends, and congestion hotspots. Finally, we plan to add data for the machine learning model for optimizing traffic signal times. The data includes weather, Traffic Analysis Zones, household travel survey, amenity data etc. to make the model more precise.",
    "crumbs": [
      "Analysis"
    ]
  },
  {
    "objectID": "analysis/index.html#research-questions",
    "href": "analysis/index.html#research-questions",
    "title": "Analysis",
    "section": "",
    "text": "What are the traffic flow patterns across different intersections and times of day in Philadelphia? Which intersections or regions experience the highest congestion, and how can they be prioritized for optimization? How can real-time traffic data be used to optimize signal timings and reduce congestion through machine learning?",
    "crumbs": [
      "Analysis"
    ]
  },
  {
    "objectID": "analysis/index.html#analysis-methods-and-techniques",
    "href": "analysis/index.html#analysis-methods-and-techniques",
    "title": "Analysis",
    "section": "",
    "text": "In the data collection and preprocessing phase, we would collect real-time traffic data using APIs and aggregate historical data for analysis. Then, we plan to use OSMnx to model the road network and analyze traffic flow at intersections and identify critical intersections with high congestion levels. We will also analyze historical traffic data to identify trends, peak hours, and seasonal variations. Finally, we will use predictive models like scikit-learn to estimate traffic flow and adjust signal timings dynamically.",
    "crumbs": [
      "Analysis"
    ]
  },
  {
    "objectID": "analysis/index.html#requirement-satisfied",
    "href": "analysis/index.html#requirement-satisfied",
    "title": "Analysis",
    "section": "",
    "text": "First, this project will satisfy the scraping and API requirement through gathering real-time traffic data. Then, It combines data collected from 3 or more different sources. This project also involves OSMnx to perform an analysis of street network data. We also want to perform a machine learning analysis with scikit-learn as part of the analysis. Finally, The project includes multiple interactive visualizations that include a significant interactive component.",
    "crumbs": [
      "Analysis"
    ]
  }
]